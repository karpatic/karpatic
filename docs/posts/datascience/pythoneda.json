{"meta":{"filename":"pythoneda"},"content":"<h1>Welcome</h1>\n <p>This notebook has functions to help handle common tasks</p>\n <p><strong>Functions</strong></p>\n<ul>\n<li><p>FillNa DropNa Replace</p></li>\n<li><p>CustomLambda = Lambda X:(x+x%2)</p></li>\n<li><p>df.groupby().transform(customLambda):sumAgg</p></li>\n<li><p>Pd.melt()-&amp;gt;columnRows</p></li>\n<li><p>DummyEncode</p></li>\n<li><p>Df.Stack.Unstack</p></li>\n<li><p>Infer data types isfinite-inf/nan, isnan, first char is symbol, default value.</p></li>\n</ul>\n <h4>Common Python Data Manipulations</h4>\n <p><a href=\"https://datascience.stackexchange.com/questions/37878/difference-between-isna-and-isnull-in-pandas\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://datascience.stackexchange.com/questions/37878/difference-between-isna-and-isnull-in-pandas</a></p>\n<p> <strong>Common Python Data Manipulations</strong></p>\n<ul>\n<li><p>.isna(), .fillna(), .isnull()</p>\n</li>\n<li><p>.dropna(how=&#39;any&#39;),</p>\n</li>\n<li><p>.fillna(method=&#39;ffill&#39;, inplace=true), method=&#39;ffill&#39;, .fillna(value=0, inplace=true)</p>\n</li>\n<li><p>.duplicated(), .unique(), .drop_duplicates()</p>\n</li>\n<li><p>.replace()</p>\n</li>\n<li><p>groupby()</p>\n</li>\n<li><p>contains(), within() for geospatial data.\n <strong>Common Python Cleaning operations:</strong></p>\n</li>\n</ul>\n<ol>\n<li><p>Check the data types of all column in the data-frame</p></li>\n<li><p>Create a new data-frame excluding all the &#39;object&#39; types column</p></li>\n<li><p>Select elements from each column that lie within 3 units of Z score</p></li>\n</ol>\n<ul>\n<li><p>.cut() will bin your data</p></li>\n<li><p>.dtypes, -.select_dtypes(exclude=[&#39;object&#39;])</p></li>\n<li><p>stats.zscore(df)</p></li>\n</ul>\n <h4>FILTERING</h4>\n <ul>\n<li><p>DataFrame.isna()\tDetect missing values.</p></li>\n<li><p>DataFrame.any(axis=0, bool_only=None, skipna=True, level=None, **kwargs)</p></li>\n<li><p>DataFrame.all(axis=0, bool_only=None, skipna=True, level=None, **kwargs)</p></li>\n<li><p>DataFrame.filter([items, like, regex, axis])\tSubset rows or columns of dataframe according to labels in the specified index.</p></li>\n<li><p>DataFrame.dropna([axis, how, thresh, …])\tRemove missing values.</p></li>\n<li><p>DataFrame.fillna([value, method, axis, …])\tFill NA/NaN values using the specified method.</p></li>\n<li><p>DataFrame.replace([to_replace, value, …])\tReplace values given in to_replace with value.</p></li>\n<li><p>DataFrame.interpolate([method, axis, limit, …])\tInterpolate values according to different methods.</p></li>\n<li><p>DataFrame.nlargest(n, columns[, keep])\tReturn the first n rows ordered by columns in descending order.</p></li>\n<li><p>DataFrame.nsmallest(n, columns[, keep])\tReturn the first n rows ordered by columns in ascending order.</p></li>\n</ul>\n <h4>GROUPING/ Aggregating/ Manipulating</h4>\n <ul>\n<li>DataFrame.pivot([index, columns, values])\tReturn reshaped DataFrame organized by given index / column values.\n *df.agg(&quot;mean&quot;, axis=&quot;columns&quot;) # axis : {0 or ‘index’, 1 or ‘columns’}, default 0</li>\n<li><p>DataFrame.compound(axis=None, skipna=None, level=None)</p></li>\n<li><p>DataFrame.count(axis=0, level=None, numeric_only=False)[source]</p></li>\n<li><p>df.groupby([&#39;1_tpop&#39;]).mean()</p></li>\n<li><p>DataFrame.insert(loc, column, value[, …])\tInsert column into DataFrame at specified location.</p></li>\n</ul>\n <h4>Common Python Cleaning operations:</h4>\n <ul>\n<li><ol>\n<li><p>Check the data types of all column in the data-frame</p></li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li><p>Create a new data-frame excluding all the ‘object’ types column</p></li>\n</ol>\n</li>\n<li><ol start=\"3\">\n<li><p>Select elements from each column that lie within 3 units of Z score</p></li>\n</ol>\n</li>\n<li><p>.cut() will bin your data</p></li>\n<li><p>.dtypes, -.select_dtypes(exclude=[‘object’])</p></li>\n</ul>\n  <p>biggest data cleaning task, missing values</p>\n<p> Pandas will recognize both empty cells and “NA” types as missing values. Anything else should to be specified on import</p>\n   <p>In the code we’re looping through each entry in the “Owner Occupied” column. To try and change the entry to an integer, we’re using int(row).\n If the value can be changed to an integer, we change the entry to a missing value using Numpy’s np.nan.\n On the other hand, if it can’t be changed to an integer, we pass and keep going.  The .loc method is the preferred Pandas method for modifying entries in place. <a href=\"https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.loc.html\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.loc.html</a></p>\n                <h1>Read In Data</h1>\n  <h1>dashboards notes reduced</h1>\n<blockquote>\n<p>The functions that transform notebooks in a library</p>\n</blockquote>\n <p>Basic Text</p>\n <p>TODO :</p>\n<ul>\n<li><p>Provide a user of Import Options ,</p></li>\n<li><p>Ask For file, Default = False</p></li>\n<li><p>Ask For Delimiters, Default = ,</p></li>\n<li><p>Ask For String Delimiters, Default = &quot;</p></li>\n<li><p>Ask If First Column Represents Header, Default = False</p></li>\n<li><p>Ask If the Column Names are Correct</p></li>\n</ul>\n<p> FillNA = -1, avg</p>\n<p> FillNA THEN Coerce</p>\n <h3>Todo:</h3>\n<ul>\n<li><p>Interactive Inputs allow user to perform Simple Querys</p></li>\n<li><p>Fixed Dictionary [ distinct, not, like, avg, min, max, mean, median, mode ]</p></li>\n<li><p>Query Replaces the Imported Dataset</p></li>\n<li><p>Repeat until user specifies otherwise</p></li>\n<li><p>Template: Select From Where GroupBy Having</p></li>\n</ul>\n <h2>MISC</h2>\n <h3>Import</h3>\n  <h2>Parse The DataTypes</h2>\n      <h1>NOTES</h1>\n  <h3>Plot Histograms</h3>\n  <h2>Basic ops</h2>\n     <h2>Categorical Analysis:</h2>\n <p>Count, Unique, Top, Frequency</p>\n     <h2>Numeric Analysis:</h2>\n  <h1>Geo</h1>\n <p><strong>Future Self Service Tool</strong></p>\n<p> Data analytics</p>\n<ol>\n<li><p>Self Service</p></li>\n<li><p>Reccurent Reports </p></li>\n<li><p>Embedded Analytics.</p></li>\n</ol>\n<p> <strong>GisHandler</strong>() </p>\n<ul>\n<li><p>Check Columns</p></li>\n<li><p>Check If Operations will work as expected</p></li>\n<li><p>perform operations</p></li>\n<li><p>tidy up</p></li>\n<li><p>save</p></li>\n<li><p>return</p></li>\n</ul>\n<p> <strong>Main</strong>( Check For Missing Values, Perform Operation)</p>\n<p> <strong>readFile</strong>() - csv/postgis -df -reverseGeocode? ColumnToCords? -Geodf</p>\n<p> <strong>Geodataframe</strong> -toCrs, - saveGeoDataFrame</p>\n<p> <strong>MergeBounds</strong>() </p>\n<p> <strong>FilterBounds</strong>() </p>\n<p> <strong>FilterPoints</strong>() Bounds Points </p>\n<p> <strong>PoinsInPoly</strong>()</p>\n <p><strong>Applied Spatial Statistics</strong></p>\n<ul>\n<li><p>Prior Posterior Distribution</p></li>\n<li><p>Hierarchal Models</p></li>\n<li><p>Markov Chain Monte Carlo</p></li>\n<li><p>Kernal Methods</p></li>\n<li><p>Dynamic State Space Modeling</p></li>\n<li><p>Multiple linear Regressions</p></li>\n<li><p>Spatial Models (Car Sar) Kriging</p></li>\n<li><p>Time series models: ARM ARMA </p></li>\n<li><p>Dynamic linear models</p></li>\n<li><p>multi level models - causal inference - meta analysis</p></li>\n<li><p>multi agent decision making</p></li>\n<li><p>variable transformations</p></li>\n<li><p>eigenvalues</p></li>\n</ul>\n <p><strong>Applied Spatial Statistics</strong> -&amp;gt; Prior/Posteriors, MCMC, Kernel methods, dynamic state space modeling, multiple linear regression, multilevel models(causal inference, meta analysis), multi agent decision making, variable transformations, eigenvalues,\n <strong>Spatial models</strong> (Car,Sar) Kriging\n <strong>Time Series Models</strong> : ARM ARMA Dynamic linear models</p>\n <p>Exploratory spatial analysis, spatial autocorrelation, spatial regression, interpolation, grid based stats, point based stats, spatial network analysis, spatial clustering.</p>\n <p> Big-Data, Structure(Semi/Un), Time-Stamped, Spatial, Spatio-Temporal, Ordered, Stream, Dimensionality,\n  Primary Keys, Unique Values, Index, Spatial, Auto Increment, Default Values, Null Values</p>\n <p><strong>Geographic Inquery</strong>:</p>\n<ul>\n<li><p>Describe real world phenomena</p>\n</li>\n<li><p>Study of Spatial Arrangement of features</p>\n</li>\n<li><p>Patterns arise as a result of process operating within space</p>\n</li>\n<li><p>Measure compare generate</p>\n</li>\n<li><p>Size distribution pattern contiguity shape community scale orientation relation</p>\n</li>\n<li><p>How comparE? How describe analyze? How predict?</p>\n</li>\n<li><p>Entry, conversion, storage, query, manipulation, analysis, presentation,</p>\n</li>\n<li><p>Req, process, clean ,explore, model …</p>\n</li>\n<li><p>Hot spot analysis _&amp;gt; cluster points</p>\n</li>\n<li><p>Line of sight/visibility analysis -&amp;gt; network, overlay, proximity, risk</p>\n</li>\n<li><p>Heat maps</p>\n</li>\n<li><p>GeoCoding</p>\n</li>\n<li><p>Distance Decay</p>\n</li>\n<li><p>Clip Analysis</p>\n</li>\n<li><p>post analaysis</p>\n</li>\n<li><p>land use analysis</p>\n</li>\n<li><p>voronoi crop by bounds of other ds,</p>\n</li>\n<li><p>Buffering -radius around a point</p>\n</li>\n<li><p>Map coverage, \nspatial resource allocation, </p>\n</li>\n<li><p>impact assesment, </p>\n</li>\n<li><p>pollutant reduction, </p>\n</li>\n<li><p>decision support, </p>\n</li>\n<li><p>facility management (water plant mgmt), </p>\n</li>\n<li><p>operations mgmt, </p>\n</li>\n<li><p>site selection - where to do xyz, </p>\n</li>\n<li><p>business/marketing</p>\n</li>\n</ul>\n <p><a href=\"http://pysal.org/notebooks/explore/esda/Spatial_Autocorrelation_for_Areal_Unit_Data.html\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">http://pysal.org/notebooks/explore/esda/Spatial_Autocorrelation_for_Areal_Unit_Data.html</a>\t\n Python Spatial Analysis library.\t\n <a href=\"https://pysal.org/notebooks/intro\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://pysal.org/notebooks/intro</a>\tPython Spatial Analysis library.\n Shape Analysis\t\n hull: calculate the convex hull of the point pattern\t\n mbr: calculate the minimum bounding box (rectangle)\t\n The python file centrography.py contains several functions with which we can conduct centrography analysis.\t</p>\n<p> Random point patterns are the outcome of CSR. <a href=\"https://en.wikipedia.org/wiki/Complete_spatial_randomness\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://en.wikipedia.org/wiki/Complete_spatial_randomness</a> CSR has two major characteristics:\t\n Uniform: each location has equal probability of getting a point (where an event happens)\t\n Independent: location of event points are independent\t\n It usually serves as the null hypothesis in testing whether a point pattern is the outcome of a random process.\t\n There are two possible objectives in a discriminant analysis:\t</p>\n<ul>\n<li><p>finding a predictive equation for classifying new individuals\t</p></li>\n<li>interpreting the predictive equation to better understand the relationships that may exist among the variables.\t\n It was demonstrated by Clark and Evans(1954) that mean nearest neighbor distance statistics distribution is a normal distribution under null hypothesis (underlying spatial process is CSR). We can utilize the test statistics to determine whether the point pattern is the outcome of CSR.</li>\n</ul>\n<p>\t</p>\n <h1>Misc</h1>\n <p><a href=\"https://www.gnu.org/philosophy/open-source-misses-the-point.html\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://www.gnu.org/philosophy/open-source-misses-the-point.html</a></p>\n<p> It seems to me that the chief difference between the MIT license and GPL is that the MIT doesn&#39;t require modifications be open sourced whereas the GPL does. </p>\n<p> You don&#39;t have to open-source your changes if you&#39;re using GPL.\tYou could modify it and use it for your own purpose as long as you&#39;re not distributing it\t</p>\n<p> BUT... </p>\n<p> if you DO distribute it, then your entire project that is using the GPL code also becomes GPL automatically Which means, it must be open-sourced, and the recipient gets all the same rights as you - meaning, they can turn around and distribute it, modify it, sell it, etc. </p>\n<p> And that would include your proprietary code which would then no longer be proprietary - it becomes open source.</p>\n<p> with MIT is that even if you actually distribute your proprietary code that is using the MIT licensed code you do not have to make the code open source you can distribute it as a closed app where the code is encrypted or is a binary.</p>\nundefined\n  <ul>\n<li><p>File-&amp;gt;UncleanData-&amp;gt;ToCsvFormat(filename,data)</p></li>\n<li><p>ProcessCsv -&amp;gt; Unclean Data</p></li>\n<li><p>IndexDB</p></li>\n<li><p>URL-&amp;gt;browser or server? callServer(url)</p></li>\n<li><p>json/geojson/xl/csv -&amp;gt; tocsvformat -&amp;gt; iscsv-&amp;gt;stringreplace, isjson-&amp;gt;papaunparse, isxl-&amp;gt;readxlsx[0] -&amp;gt;tocsv, isgeoj-&amp;gt;json-&amp;gt;papaunparce</p></li>\n<li><p>JSN.Parse at runtime is faster than inlining the data when 10KB&amp;gt;</p></li>\n<li><p>Code Caching occurs when inlineJs &amp;gt; 1KB</p></li>\n<li><p>V8 reduced parse/compilation by 40% using workerThreads</p></li>\n<li><p>/v8RawJS parse speed is 2x since chrome60</p></li>\n</ul>\n <p>Clear indexdb -&amp;gt; readFile. Insert into IndexDB V.1.0</p>\n <ul>\n<li><p>jpl- sweet ontology</p></li>\n<li><p>Geoincubator group</p></li>\n<li><p>Rdf, qsparql, gml, kml</p></li>\n</ul>\n\n  <script src=\"https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}