{"meta":{"filename":"02_211_web_scraper","title":"211 Web Scraper","summary":"Scrape 211 Data.","toc":"true"},"content":"<p><a href=\"https://mybinder.org/v2/gh/bnia/datalabs/main?filepath=%2Fnotebooks%2F02_211_web_scraper.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Binder\"></a>\n <a href=\"https://colab.research.google.com/github/bnia/datalabs/blob/main/notebooks/02_211_web_scraper.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/colab.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/bnia/datalabs/tree/main/notebooks/02_211_web_scraper.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/github.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/ellerbrock/open-source-badges/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://badges.frapsoft.com/os/v3/open-source.svg?v=103\" alt=\"Open Source Love svg3\"></a></p>\n<p> <a href=\"https://github.com/bnia/datalabs/blob/main/LICENSE\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/npm/l/all-contributors.svg?style=flat\" alt=\"NPM License\"></a>\n <a href=\"https://bnia.github.io\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"http://img.shields.io/badge/Status-Active-green.svg\" alt=\"Active\"></a> \n <a href=\"\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/last-commit/bnia/datalabs.svg?style=flat\" alt=\"GitHub last commit\"></a>  </p>\n<p> <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/stars/bnia/datalabs.svg?style=social&label=Star\" alt=\"GitHub stars\"></a> \n <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/watchers/bnia/datalabs.svg?style=social&label=Watch\" alt=\"GitHub watchers\"></a> \n <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/forks/bnia/datalabs.svg?style=social&label=Fork\" alt=\"GitHub forks\"></a> \n <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/followers/bnia.svg?style=social&label=Follow\" alt=\"GitHub followers\"></a> </p>\n<p> <a href=\"https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/bnia/datalabs%20%F0%9F%A4%97\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/url/https/github.com/bnia/datalabs.svg?style=social\" alt=\"Tweet\"></a> \n <a href=\"https://twitter.com/bniajfi\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/follow/bniajfi.svg?style=social\" alt=\"Twitter Follow\"></a></p>\n <p>We will need these libraries</p>\n url = 'https://md-dc.211counts.org/dashBoard/barChart'\n # And these are the paramaters that get submitted to the endpoint as a POST request\n myobj = {\n 'identifierCategory': '',\n 'sourceType': '',\n 'fromMobile': False,\n 'id': {\"ids\":[14160]},\n 'timeIntervalId': 333,\n 'centerId': 43,\n 'fromDate': 0,\n 'toDate': 0,\n 'type': 'Z'\n } <h2 id=\"miner\">Miner</h2>\n<p> (Works, but html content needs to be scraped seperately, through a same-origin request)</p>\n # This needs additional scraping, but now each record has its respective html is isolated.\n def scrape(html_data):\n     soup = BeautifulSoup(html_data, \"html.parser\")\n     categories = soup.findAll(\"div\", {\"class\": \"categories\"})\n     return categories df = pd.DataFrame(data={'zipCodeId': [], 'title': [], 'value': []})\n formValues = htmlText\n # Loop through array of html containing our data\n for x in scrape(formValues):\n   soup = BeautifulSoup(str(x), \"html.parser\")\n   # get the title and value from the records html\n   title = soup.find(\"span\", {\"class\": \"toolTipSubCategory\"})\n   value = soup.find(\"span\", {\"data-value\": True})\n   # append it to our dataframe if both value and title exit\n   if(str(title) != 'None' and str(value) != 'None' ): \n     title = title.text\n     value = value['data-value']\n     df = df.append({'zipCodeId': str(14174), 'title': title, 'value': value}, ignore_index=True) htmlText = '' # This needs additional scraping, but now each record has its respective html is isolated.\n def scrape(html_data):\n     soup = BeautifulSoup(html_data, \"html.parser\")\n     categories = soup.findAll(\"div\", {\"class\": \"categories\"})\n     return categories <h2 id=\"scraper\">Scraper</h2>\n<p> (Works but doesnt give us what we want)</p>\n <p>Get the page</p>\n browser.open(\"https://md-dc.211counts.org/\")\n browser.get_url() <p>Find the form and select our options</p>\n browser['chkZ'] = '14160' response = browser.submit_selected() <p>Save the output for previewing</p>\n n = text_file.write(response.text)\n text_file.close()\n # print(response.text) <p>Unfortunately, this does not work! </p>\n<p> Our data is stored as dynamic content that is not delivered to us here.</p>\n<p> We will need to use Pupeteer to render the dynamic javascript content.</p>\n<p> What a shame...</p>\n <h2 id=\"final-solution-javascript\">Final Solution (Javascript)</h2>\n <p>This needs to be ran in a seperate js file.</p>\n  * https://stackoverflow.com/questions/48681145/set-pupeteer-window-size-when-running-not-headless-not-viewport\n https://medium.com/@aslushnikov/automating-clicks-in-chromium-a50e7f01d3fb\n * \n */\n const puppeteer = require('puppeteer');\n var zipCodes = { \n   '21201':11175, \n   '21202':11176, \n   '21203':14550, \n   '21204':11177, \n   '21205':11178, \n   '21206':11179, \n   '21207':11180, \n   '21208':11181,\n   '21209':11182, \n   '21210':11183, \n   '21211':11184, \n   '21212':11185, \n   '21213':11373, \n   '21214':11375, \n   '21215':11376, \n   '21216':11377,\n   '21217':11378, \n   '21218':11379, \n   '21219':11380, \n   '21220':11381, \n   '21221':11382, \n   '21222':11383, \n   '21223':11384, \n   '21224':11385, \n   '21225':11386, \n   '21226':11387, \n   '21227':11388, \n   '21228':11389, \n   '21229':11390, \n   '21230':11391,\n   '21231':11392, \n };\n let nomatch = [ \n   '21232', \n   '14550', \n   '11177', \n   '11178', \n   '11178', \n   '11189'\n ]\n \n var finalData = {};\n (async () => {\n   // Init url to scrape, load browser and page\n   const browser = await puppeteer.launch({\n     headless: false, // The browser is visible\n     ignoreHTTPSErrors: true,\n     args: [`--window-size=1200,1000`] // new option\n   })\n                             \n   const page = await browser.newPage()\n   await page.goto('https://md-dc.211counts.org/')\n   await page.setViewport({ width: 1200, height: 1000 })\n   await page.waitForSelector('#mainContent #identifierCategory')\n   // Click Covid-19 Checkbox\n   await page.click('#mainContent #identifierCategory') \n   await page.waitForSelector('#mainContent #displayCount')\n   // Click Radio Button\n   await page.click('#mainContent #displayCount')\n   // Click to Expand the Timestamp Dropdown\n   await page.mouse.move(713, 37);\n   await page.mouse.down({button: 'left'});\n   await page.mouse.up({button: 'left'});\n   // Click from the dropdwn '30 Days'\n   await page.mouse.move(688, 194);\n   await page.mouse.down({button: 'left'});\n   await page.mouse.up({button: 'left'}); \n   // Search for every zip code and add the result to an object\n   for (var j = 0; j < Object.keys(zipCodes).length; j++) {\n \tvar currentZipCode = Object.keys(zipCodes)[j]\n \tvar zid = zipCodes[currentZipCode]\t \n \tconsole.log(\"CurZip: \" + currentZipCode, ' ID: ', 'input[value=\"'+zid+'\"]');  \n \tawait page.evaluate((zc) => {\t\n \t  // Prepare the zip code checkbox identifier to click on\n \t  let reset = 'input[value=\"RESET\"]';\n \t  $(reset).click();\n \t  let zipCodeCheckBox = 'input[value=\"' + zc  + '\"]';\n \t  $(zipCodeCheckBox).click();\n \t  // Get search button, click\n       $(\"#submitSearch\").click();\n \t}, zid);\n \t\n \t// And wait for the results to load\n \tawait page.waitFor(1000);\n \t\n \tawait page.screenshot({path: currentZipCode+'.png'});\n \t\n \tawait page.evaluate((zc) => {\n \t\t// Click on count radio button \n \t\tlet countsBtn = document.getElementById('displayCount');\n \t\tcountsBtn.click();\n \t\t// Prepare the zip code checkbox identifier to click on\n \t\tlet zipCodeCheckBox = 'input[value=\"' + zc  + '\"]';\n \t\t$(zipCodeCheckBox).click();\n \t\t// Get search button, click\n \t\t$(\"#submitSearch\").click();\n \t}, currentZipCode);\n \t// And wait for the results to load\n \tawait page.waitFor(1000);\n \tawait page.screenshot({path: currentZipCode+'.png'});\n \t\t// Then we grab the results\n \tlet result = await page.evaluate(async () => {\n       // Get all categories div\n \t  let categories = document.querySelectorAll(\".categories\");\n \t  // Iterate through all categories and add their values to an object\n \t  let pointer = 0; \n \t  let data = {}\n \t  while (pointer < categories.length) {\n \t\t// Now we have access to two categories\n \t\tlet category = categories[pointer];\n \t\t// Making sure we have both a label and a value and category is not null\n \t\tif (category != null && category != undefined && category.children.length > 1) {\n \t\t  let label = \"\"; \n \t\t  let value = \"\";\n \t\t  let percentage = \"\";\n \t\t  for (var i = 0; i < category.children.length; i++) {\n \t\t\tlet node = category.children[i];\n \t\t\t// Make sure that the node is either a label or a paragraph, can't rely on indices alone\n \t\t\tif (node.nodeName.toLowerCase() === 'label') {\n \t\t\t  label = node.querySelector(\"span\").innerText;\n \t\t\t}\n \t\t\tif (node.nodeName.toLowerCase() === 'p') {\n \t\t\t  value = node.querySelector(\"span\").getAttribute(\"data-value\");\n \t\t\t  percentage = node.querySelector(\"span\").getAttribute(\"data-percentage\");\n \t\t    }  \n \t\t  }\n \t\t  data[label + \" Count\"] = value;\n \t\t  data[label + \" Percent\"] = percentage;\n \t\t}\n \t\tpointer += 1;\n \t  }\n \t  return data;\n \t});\n \t// Now we add this zip code's result to the final answer\n \tfinalData[currentZipCode.toString()] = result;\n   }\n   console.log(JSON.stringify(finalData));\n \n   await page.waitFor(3000); \n   \n   \n   // await browser.close()\n })() "}