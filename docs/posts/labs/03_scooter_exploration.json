{"meta":{"title":"Scooter Exploration","summary":"In this chapter Scooter data is explored ","prettify":"true","filename":"03_scooter_exploration"},"content":"<details open>\n <summary> <h2 id=\"introduction\">Introduction</h2>\n </summary> <p><a href=\"https://mybinder.org/v2/gh/karpatic/karpatic/main?filepath=src%2Fipynb%2Fdatalabs%2F01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Binder\"></a>\n <a href=\"https://colab.research.google.com/github/karpatic/karpatic/blob/main/src/ipynb/datalabs/01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/colab.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/karpatic/karpatic/blob/main/src/ipynb/datalabs/01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/github.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/ellerbrock/open-source-badges/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://badges.frapsoft.com/os/v3/open-source.svg?v=103\" alt=\"Open Source Love svg3\"></a></p>\n<p> <a href=\"https://github.com/karpatic/karpatic/blob/main/LICENSE\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/npm/l/all-contributors.svg?style=flat\" alt=\"NPM License\"></a>\n <a href=\"https://karpatic.github.io\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"http://img.shields.io/badge/Status-Active-green.svg\" alt=\"Active\"></a> \n <a href=\"\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/last-commit/karpatic/karpatic.svg?style=flat\" alt=\"GitHub last commit\"></a>  </p>\n<p> <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/stars/karpatic/karpatic.svg?style=social&label=Star\" alt=\"GitHub stars\"></a> \n <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/watchers/karpatic/karpatic.svg?style=social&label=Watch\" alt=\"GitHub watchers\"></a> \n <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/forks/karpatic/karpatic.svg?style=social&label=Fork\" alt=\"GitHub forks\"></a> \n <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/followers/karpatic.svg?style=social&label=Follow\" alt=\"GitHub followers\"></a>  </p>\n <aside class=\"info\">This notebook was made in large part by interns Brian Kelly, Michael Vandi. Read their final article [An Analysis of Baltimore City E-Scooter Distribution](https://bniajfi.org/2020/09/02/an-analysis-of-baltimore-city-e-scooter-distribution/) </aside>\n <p><strong>Dataset:</strong>\n Scooter data: </p>\n<ul>\n<li><p>Routes: 3 months (September to August 2019)</p></li>\n<li><p>Deployment/</p></li>\n<li><p>Routes</p></li>\n<li><p>Trip origins-destinations by month</p></li>\n</ul>\n <pre class='prettyprint'># do you see this? - Carlos</pre> <pre class='prettyprint'># Hello world! - Michael</pre> <pre class='prettyprint'># Checking - Brian</pre> </details>\n <details>\n <summary> <h2 id=\"local-file-access-optional\">Local File Access (Optional)</h2>\n </summary> <pre class='prettyprint'># hide_output\n # (Optional) Run this cell to gain access to Google Drive (Colabs only) \n from google.colab import drive\n \n # Colabs operates in a virtualized enviornment\n # Colabs default directory is at ~/content.\n # We mount Drive into a temporary folder at '~/content/drive' \n \n drive.mount('/content/drive')</pre> <p>File path&#39;s will vary</p>\n <pre class='prettyprint'># cd ./drive/'My Drive'/BNIA/responsive_records/Routes</pre> <pre class='prettyprint'># cd ../content/drive/My Drive/DATA/scooter</pre> <pre class='prettyprint'># Michael's Directory\n # cd ./drive/'My Drive'/BNIA/'Scooter Use Data'/BNIA</pre> <pre class='prettyprint'>cd ./Routes</pre> <pre class='prettyprint'># hide_output\n ! ls</pre> <pre class='prettyprint'># hide_output\n !cd ../ && ls</pre> </details>\n <details>\n <summary> <h2 id=\"installs\">Installs</h2>\n </summary> <pre class='prettyprint'>#show_input \n !pip install dexplot\n !pip install folium\n !pip install geopandas\n !pip install ipyleaflet\n !pip install gpdvega\n !pip install dataplay</pre> </details>\n <details>\n <summary> <h2 id=\"imports\"><strong>Imports</strong></h2>\n </summary> <pre class='prettyprint'>#show_input \n import os\n import pandas as pd\n import geopandas as gpd\n import dexplot as dxp\n import folium as fol\n import json\n import altair as alt\n import gpdvega\n import dataplay\n # These imports will handle everything\n import os\n import sys\n import csv\n from IPython.display import clear_output\n import matplotlib.pyplot as plt\n import numpy as np\n import pandas as pd\n import geopandas as gpd\n from geopandas import GeoDataFrame\n import psycopg2\n import pyproj\n from pyproj import Proj, transform\n # conda install -c conda-forge proj4\n from shapely.geometry import Point\n from shapely import wkb\n from shapely.wkt import loads\n # https://pypi.org/project/geopy/\n from geopy.geocoders import Nominatim\n import folium\n from folium import plugins\n \n from dataplay.merge import mergeDatasets \n \n import dexplot as dxp\n \n # In case file is KML, enable support\n import fiona\n fiona.drvsupport.supported_drivers['kml'] = 'rw'\n fiona.drvsupport.supported_drivers['KML'] = 'rw'\n \n #this cell is good to copy\n from shapely.geometry import LineString\n pd.plotting.register_matplotlib_converters()\n \n from dataplay.geoms import readInGeometryData\n from shapely import wkt\n from dataplay.geoms import readInGeometryData\n \n import ipywidgets as widgets\n !jupyter nbextension enable --py widgetsnbextension\n from IPython.core.interactiveshell import InteractiveShell\n InteractiveShell.ast_node_interactivity = 'all'\n import ipywidgets as widgets\n from ipywidgets import interact, interact_manual\n alt.data_transformers.enable('default', max_rows=None)</pre> </details>\n <details>\n <summary> <h2 id=\"convenience-functions\">Convenience Functions</h2>\n </summary> <pre class='prettyprint'># Return the boundaries of a Linestring \n def split(geom):\n   print( str( type(geom)) )\n   #Linestring might not be the actual type, so this may need to be fied. \n   #IF its not a linestring then dont run it and stuff 'false' and the datatype\n   if str( type(geom)) == \"<class 'shapely.geometry.linestring.LineString'>\" and not str(geom.boundary) == 'MULTIPOINT EMPTY':\n     print(geom.boundary)\n     left, right = geom.boundary\n     print('left x: ', type(left.x), left.x)\n     print('left y: ', type(left.y), left.y)\n     print('right x: ', type(right.x), right.x)\n     print('right y: ', type(right.y), right.y)\n     return left.x, left.y, right.x, right.y\n   else: return False, type(geom), False, type(geom)</pre> <pre class='prettyprint'># To 'import' a script you wrote, map its filepath into the sys\n def getPointsInPolygons(pts, polygons, ptsCoordCol, polygonsCoordCol): \n     count = 0 \n     total = pts.size / len(pts.columns)\n     # We're going to keep a list of how many points we find.\n     pts_in_polys = []\n \n     # Loop over polygons with index i.\n     for i, poly in polygons.iterrows():\n         # print('Searching for point within Geom:', poly )\n         # Keep a list of points in this poly\n         pts_in_this_poly = []\n \n         # Now loop over all points with index j.\n         for j, pt in pts.iterrows():\n           if poly[polygonsCoordCol].contains(pt[ptsCoordCol]):\n             # Then it's a hit! Add it to the list,\n             # and drop it so we have less hunting.\n             pts_in_this_poly.append(pt[ptsCoordCol])\n             pts = pts.drop([j])\n \n         # We could do all sorts, like grab a property of the\n         # points, but let's just append the number of them.\n         pts_in_polys.append(len(pts_in_this_poly))\n         print('Found this many points within the Geom:', len(pts_in_this_poly) ) \n         count = count + len(pts_in_this_poly) \n         clear_output(wait=True)\n \n     # Add the number of points for each poly to the dataframe.\n     polygons['pointsinpolygon'] = gpd.GeoSeries(pts_in_polys)\n     print( 'Total Points: ', total )\n     print( 'Total Points in Polygons: ', count )\n     print( 'Prcnt Points in Polygons: ', count / total )\n     return polygons</pre> </details>\n <details>\n <summary> <h2 id=\"file-access-convenience-functions\">File Access Convenience Functions</h2>\n </summary> <pre class='prettyprint'># Find Relative Path to Files\n def findFile(root, file):\n     for d, subD, f in os.walk(root):\n         if file in f:\n             return \"{1}/{0}\".format(file, d)\n             break \n \n # To 'import' a script you wrote, map its filepath into the sys\n def addPath(root, file): sys.path.append(os.path.abspath( findFile( './', file) ))</pre> <pre class='prettyprint'>findFile('./', 'Routing September 2019.geojson')</pre> <pre class='prettyprint'>ls</pre> </details>\n <details>\n <summary> <h2 id=\"inspect-deployment-data\">Inspect Deployment Data</h2>\n </summary> <pre class='prettyprint'>ls 'Trip origins-destinations by month'</pre> <pre class='prettyprint'>#@title Example form fields\n #@markdown Forms support many types of fields.\n fileName = \"Trip Origins by block September 2019.geojson\"  #@param ['Daily Deployment average by block August 2019.csv', 'Daily Deployment average by block December 2019.csv', 'Daily Deployment average by block November 2019.csv', 'Daily Deployment average by block October 2019.csv', 'Daily Deployment average by block September 2019.csv', 'Trip Destinations by block August 2019.geojson','Trip Destinations by block December 2019.geojson','Trip Destinations by block November 2019.geojson', 'Trip Destinations by block October 2019.geojson', 'Trip Destinations by block September 2019.geojson', 'Trip Origins by block August 2019.geojson','Trip Origins by block December 2019.geojson','Trip Origins by block November 2019.geojson','Trip Origins by block October 2019.geojson','Trip Origins by block September 2019.geojson']\n #@markdown ---</pre> <pre class='prettyprint'>gdf = gpd.read_file( findFile('./', fileName) )\n gdf.head()</pre> <pre class='prettyprint'>gdf.plot(column = 'value')</pre> <pre class='prettyprint'>point_df = gdf.copy()\n point_df['centroids'] = df.centroid\n point_df = point_df.drop(columns = 'geometry')\n point_df = point_df.set_geometry('centroids')\n point_df.head(1)\n point_df.plot(marker='o', color='red', markersize='value')</pre> <pre class='prettyprint'>point_df.value.hist()</pre> <pre class='prettyprint'>point_df[point_df.value > 1000].plot()</pre> <pre class='prettyprint'>baltimore = gpd.read_file(\"https://opendata.arcgis.com/datasets/b738a8587b6d479a8824d937892701d8_0.geojson\")</pre> <pre class='prettyprint'>from dataplay.geoms import workWithGeometryData</pre> <pre class='prettyprint'>baltimore.columns</pre> <pre class='prettyprint'>pointsInPolys = workWithGeometryData(method = 'ponp', df = point_df, polys = baltimore, ptsCoordCol ='centroids', \n                                      polygonsCoordCol = 'geometry', polygonsLabel = 'CSA2010')\n pointsInPolys.plot(column='value', legend=True, markersize = 1)</pre> <pre class='prettyprint'>ponp_copy = pointsInPolys.copy()</pre> <pre class='prettyprint'>ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int).reset_index(name='NumberMissingCount').head()</pre> <pre class='prettyprint'>ponp_copy.value.notnull().groupby([ponp_copy['CSA2010']]).sum().astype(int) / ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int)</pre> <pre class='prettyprint'>ponp_copy.value.isnull().groupby([ponp_copy['CSA2010']]).sum().astype(int) / ponp_copy.value.groupby([ponp_copy['CSA2010']]).sum().astype(int) * 100</pre> <pre class='prettyprint'>ponp_copy.fillna(-1).groupby('CSA2010')['value'].sum()</pre> <pre class='prettyprint'>gdf.value.unique()</pre> <pre class='prettyprint'>gdf.value.describe()</pre> <pre class='prettyprint'>gdf.value.var() # Return unbiased variance over requested axis.</pre> <pre class='prettyprint'>gdf.value.sem() # Return unbiased standard error of the mean over requested axis.</pre> <pre class='prettyprint'>gdf.value.nunique()\t# Count distinct observations over requested axis.</pre> <pre class='prettyprint'># DataFrame.shape\tReturn a tuple representing the dimensionality of the DataFrame.\n gdf.shape\n \n #DataFrame.size\tReturn an int representing the number of elements in this object.\n gdf.size\n \n # DataFrame.ndim\tReturn an integer representing the number of axes/array dimensions.\n gdf.ndim\n \n # Note Used : \n # DataFrame.axes\tReturn a list representing the axes of the DataFrame.\n \n gdf.dtypes\n \n # Return unbiased kurtosis over requested axis using Fisherâ€™s definition of kurtosis (kurtosis of normal == 0.0).\n gdf.kurtosis()</pre> </details>\n <details>\n <summary> <h2 id=\"load-tracts\">Load Tracts</h2>\n </summary> <pre class='prettyprint'># This will just beautify the output.\n \n pd.set_option('display.expand_frame_repr', False)\n pd.set_option('display.precision', 2)\n from IPython.core.interactiveshell import InteractiveShell\n InteractiveShell.ast_node_interactivity = \"all\"\n \n pd.set_option('max_colwidth', 20)</pre> <pre class='prettyprint'># The attributes are what we will use.\n in_crs = 2248 # The CRS we recieve our data.\n out_crs = 4326 # The CRS we would like to have our data represented as.\n geom = 'geometry' # The column where our spatial information lives.\n \n # A Url to load\n boundariesBaltimoreTractsNoWater2010 = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv\"\n \n # Read in the dataframe\n gdf = pd.read_csv(boundariesBaltimoreTractsNoWater2010)\n \n # Convert the geometry column datatype from a string of text into a coordinate datatype.\n gdf['geometry'] = gdf['geometry'].apply(lambda x: loads( str(x) ))\n \n # Process the dataframe as a geodataframe with a known CRS and geom column.\n gdf = GeoDataFrame(gdf, crs=in_crs, geometry='geometry')</pre> <pre class='prettyprint'>boundariesBaltimoreTractsNoWater2010.head()</pre> <p>Ensure merge is on consistent datatypes</p>\n <pre class='prettyprint'>gdf['GEOID10'] = gdf['GEOID10'].astype(str)\n scooterdf['nameChange2'] = scooterdf['nameChange2'].astype(str)</pre> <p>Perform the merge</p>\n <pre class='prettyprint'>scooterdfClean = gdf.merge(scooterdf, left_on='GEOID10', right_on='nameChange2').drop(['name', 'nameChange1', 'nameChange2'], axis=1)</pre> <pre class='prettyprint'>scooterdfClean.head()</pre> <pre class='prettyprint'># scooterdf.to_csv('./scooterdf.csv', index=False)\n # gdf.drop(columns='geometry').to_csv('./boundsdf.csv', index=False)</pre> <pre class='prettyprint'>ls</pre> <pre class='prettyprint'>scooterdfClean.groupby('CSA')['value'].sum()</pre> <pre class='prettyprint'>scooterdfClean.value.isna().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='notApplicable')</pre> <pre class='prettyprint'>scooterdfClean.value.notnull().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='NotMissingCount')</pre> <pre class='prettyprint'>scooterdfClean.value.isnull().groupby([scooterdfClean['CSA']]).sum().astype(int).reset_index(name='NumberMissingCount')</pre> <pre class='prettyprint'>scooterdfClean.fillna(-1).groupby('CSA')['value'].sum()</pre> <pre class='prettyprint'>scooterdfClean.groupby('CSA')['value'].mean()</pre> <pre class='prettyprint'>scooterdfClean.groupby('CSA')['value'].sum()</pre> <pre class='prettyprint'>scooterdfClean.CSA.value_counts()</pre> <pre class='prettyprint'>https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html</pre> </details>\n <details>\n <summary> <h2 id=\"inspect-routes-data\">Inspect Routes Data</h2>\n </summary> <pre class='prettyprint'>fileName = 'Routing December 2019.geojson'  #@param ['Routing August 2019.geojson', 'Routing October 2019.geojson', 'Routing December 2019.geojson', 'Routing September 2019.geojson', 'Routing November 2019.geojson']\n columnName = \"streetname\"  #@param ['id', 'color', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent']\n gdf = gpd.read_file( findFile('./', fileName) )\n gdf.head()</pre> <pre class='prettyprint'>baltimore = gpd.read_file(\"https://opendata.arcgis.com/datasets/b738a8587b6d479a8824d937892701d8_0.geojson\")</pre> <pre class='prettyprint'>tst = \"\"\"background = alt.Chart(gdf).mark_geoshape(\n     stroke='white',\n     strokeWidth=2\n ).encode(\n     color=alt.value('#eee'),\n ).properties(\n     width=700,\n     height=500\n )\"\"\"\n \n # GeoDataFrame could be passed as usual pd.DataFrame\n city = alt.Chart(baltimore).mark_geoshape(\n ).project(\n ).encode(\n     color='tpop10', # shorthand infer types as for regular pd.DataFrame\n     tooltip='CSA2010' # GeoDataFrame.index is accessible as id\n ).properties(\n     width=500,\n     height=300\n )\n \n routes = alt.Chart(gdf).mark_geoshape(\n     filled=False,\n     strokeWidth=2\n )\n \n city + routes</pre> <p>Clean the gdf of empties.</p>\n <pre class='prettyprint'>gdf = gdf[~gdf.isna()]\n gdf = gdf[~gdf.is_empty]</pre> <p>Now get the extremities; this will take a minute.</p>\n <pre class='prettyprint'># hide_output\n gdf['lefty'], gdf['leftx'],gdf['righty'], gdf['rightx'] = zip(*gdf[\"geometry\"].map(split))</pre> <p>Split the gdf into a left and right dataset</p>\n <pre class='prettyprint'>gdf_left = gdf.copy()\n gdf_left = gdf_left.drop(columns = ['geometry','rightx', 'righty'])\n \n gdf_right= gdf.copy()\n gdf_right = gdf_right.drop(columns = ['geometry','leftx', 'lefty', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent', 'color' ])</pre> <p>The coordinate variables of object type will cause problems.</p>\n <pre class='prettyprint'>gdf_right.dtypes</pre> <p>Let&#39;s go ahead and coerce a correction.</p>\n <pre class='prettyprint'>gdf_right['righty']=pd.to_numeric(gdf_right['righty'], errors='coerce')\n gdf_left['lefty']=pd.to_numeric(gdf_left['lefty'], errors='coerce')\n \n gdf_right['rightx']=pd.to_numeric(gdf_right['rightx'], errors='coerce')\n gdf_left['leftx']=pd.to_numeric(gdf_left['leftx'], errors='coerce')</pre> <p>Now we can view the results</p>\n <pre class='prettyprint'>gdf_right.dtypes</pre> <p>Save these csv&#39;s because it took a minute to get to where we are now.</p>\n <pre class='prettyprint'>gdf_right.to_csv('rightRouts.csv')\n gdf_left.to_csv('leftRouts.csv')</pre> <p>Convert the datasets to geodataframes for further exploration!</p>\n <pre class='prettyprint'># We could create a geodataframe like this\n #temp_gdf = gpd.GeoDataFrame( gdf_right, geometry=gpd.points_from_xy(gdf_right.rightx, gdf_right.righty) )\n #temp_gdf.head()\n \n # Alternately this could work.. unfinished.. but wkt.loads can make a Point from text\n # gdf_right['strCol']=gdf_right['rightx'].astype(str)\n # gdf_right['geometry'] = gdf_right['strCol'].apply(wkt.loads)</pre> <pre class='prettyprint'># hide_output\n left_csaMap = readInGeometryData(url=gdf_left, porg='p', geom= False, lat= 'leftx', lng= 'lefty', revgeocode=False, save=False, in_crs=4268, out_crs=4268)</pre> <pre class='prettyprint'># hide_output\n right_csaMap = readInGeometryData(url=gdf_right, porg='p', geom= False, lat= 'rightx', lng= 'righty', revgeocode=False, save=False, in_crs=4268, out_crs=4268)</pre> <pre class='prettyprint'>right_csaMap.head()</pre> <pre class='prettyprint'>left_csaMap.head()</pre> <pre class='prettyprint'>left_csaMap.plot(column='trip_count_sum')</pre> <pre class='prettyprint'>right_csaMap.plot()</pre> <pre class='prettyprint'>baltimore.columns</pre> <pre class='prettyprint'># hide_output\n right_points_in_poly = getPointsInPolygons(right_csaMap, baltimore, 'geometry', 'geometry')</pre> <pre class='prettyprint'>right_csaMap.head()</pre> <pre class='prettyprint'>left_points_in_poly = getPointsInPolygons(left_csaMap, baltimore, 'geometry', 'geometry')</pre> <pre class='prettyprint'>left_csaMap.head()</pre> <pre class='prettyprint'>left_points_in_poly.drop('geometry', axis=1)[['pointsinpolygon']].head(20)</pre> <pre class='prettyprint'>right_points_in_poly.drop('geometry', axis=1)[['pointsinpolygon']].head(20)</pre> <pre class='prettyprint'>left_points_in_poly.plot(column='pointsinpolygon', legend=True)</pre> <pre class='prettyprint'>right_points_in_poly.plot(column='pointsinpolygon', legend=True)</pre> <pre class='prettyprint'>right_points_in_poly</pre> <pre class='prettyprint'>scooterdfClean = left_points_in_poly.merge(right_points_in_poly, left_on='CSA2010', right_on='CSA2010', how='left')</pre> <pre class='prettyprint'>scooterdfClean.columns</pre> <pre class='prettyprint'>right_points_in_poly.columns</pre> <pre class='prettyprint'>right_points_in_poly.head()</pre> <pre class='prettyprint'>right_points_in_poly.plot('pointsinpolygon', legend=True)</pre> <pre class='prettyprint'>import altair as alt\n import geopandas as gpd\n import gpdvega\n # GeoDataFrame could be passed as usual pd.DataFrame\n chart = alt.Chart(right_points_in_poly).mark_geoshape(\n ).project(\n ).encode(\n     color='pointsinpolygon', # shorthand infer types as for regular pd.DataFrame\n     tooltip=['CSA2010','pointsinpolygon'] # GeoDataFrame.index is accessible as id\n ).properties(\n     width=500,\n     height=300\n ) \n \n routes = alt.Chart(gdf).mark_geoshape(\n     filled=False,\n     strokeWidth=2\n )\n \n chart + routes\n \n chart.save(fileName[:-8]+'.html', embed_options={'renderer':'svg'})\n chart.save(fileName[:-8]+'.json')</pre> </details>\n <details>\n <summary> <h2 id=\"inspect-origins-destinations-data\">Inspect Origins-Destinations Data</h2>\n </summary> <pre class='prettyprint'>ls 'Trip origins-destinations by month'</pre> <pre class='prettyprint'># @title Example form fields\n #@markdown Forms support many types of fields.\n fileName = 'Trip Destinations by block August 2019.geojson'  #@param ['Trip Destinations by block August 2019.geojson', 'Trip Destinations by block December 2019.geojson', 'Trip Destinations by block November 2019.geojson', 'Trip Destinations by block October 2019.geojson', 'Trip Destinations by block September 2019.geojson', 'Trip Origins by block August 2019.geojson', 'Trip Origins by block December 2019.geojson', 'Trip Origins by block November 2019.geojson', 'Trip Origins by block October 2019.geojson', 'Trip Origins by block September 2019.geojson']\n columnName = \"name\"  #@param ['name', 'value', 'color', 'radius']\n \n #@markdown ---\n \n gdf = gpd.read_file( findFile('./', fileName) )\n \n gdf.plot( column = columnName)\n gdf.columns\n gdf[['id','name', 'value', 'color', 'radius']].head(5)</pre> <pre class='prettyprint'>dxp.bar(x='color', y='value', data=gdf, aggfunc='median')</pre> <pre class='prettyprint'>dxp.scatter(x = \"color\", y = \"value\", data = gdf, aggfunc = \"median\")</pre> </details>\n  <script src=\"https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}