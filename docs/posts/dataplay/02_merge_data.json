{"meta":{"title":"Merge Data","summary":"This notebook was made to demonstrate how to merge datasets by matching a single columns values from two datasets. We add columns of data from a foreign dataset into the ACS data we downloaded in our last tutorial.","toc":"true","prettify":"true","default_exp":"merge","filename":"02_merge_data"},"content":"<p>Please read everything found on the <a href=\"https://bniajfi.org/dataplay/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">mainpage</a> before continuing; disclaimer and all.</p>\n <p><a href=\"https://mybinder.org/v2/gh/bnia/dataplay/main?filepath=%2Fnotebooks%2F01_Download_and_Load.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Binder\"></a>\n <a href=\"https://colab.research.google.com/github/bnia/dataplay/blob/main/notebooks/01_Download_and_Load.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/colab.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/bnia/dataplay/tree/main/notebooks/01_Download_and_Load.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/github.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/ellerbrock/open-source-badges/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://badges.frapsoft.com/os/v3/open-source.svg?v=103\" alt=\"Open Source Love svg3\"></a></p>\n<p> <a href=\"https://github.com/bnia/dataplay/blob/main/LICENSE\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/npm/l/all-contributors.svg?style=flat\" alt=\"NPM License\"></a>\n <a href=\"https://bnia.github.io\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"http://img.shields.io/badge/Status-Active-green.svg\" alt=\"Active\"></a> \n <a href=\"https://pypi.python.org/pypi/dataplay/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/pypi/pyversions/dataplay.svg\" alt=\"Python Versions\"></a>\n <a href=\"\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/last-commit/bnia/dataplay.svg?style=flat\" alt=\"GitHub last commit\"></a>  </p>\n<p> <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/stars/bnia/dataplay.svg?style=social&label=Star\" alt=\"GitHub stars\"></a> \n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/watchers/bnia/dataplay.svg?style=social&label=Watch\" alt=\"GitHub watchers\"></a> \n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/forks/bnia/dataplay.svg?style=social&label=Fork\" alt=\"GitHub forks\"></a> \n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/followers/bnia.svg?style=social&label=Follow\" alt=\"GitHub followers\"></a> </p>\n<p> <a href=\"https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/bnia/dataplay%20%F0%9F%A4%97\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/url/https/github.com/bnia/dataplay.svg?style=social\" alt=\"Tweet\"></a> \n <a href=\"https://twitter.com/bniajfi\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/follow/bniajfi.svg?style=social\" alt=\"Twitter Follow\"></a></p>\n <details open>\n <summary> <h2 id=\"about-this-tutorial\">About this Tutorial:</h2>\n </summary> <h3 id=\"whats-inside\">Whats Inside?</h3>\n <p>In this notebook, the basics of how to perform a merge are introduced.</p>\n<ul>\n<li><p>We will merge two datasets</p></li>\n<li><p>We will merge two datasets using a crosswalk</p></li>\n</ul>\n <h3 id=\"objectives\">Objectives</h3>\n<p> By the end of this tutorial users should have an understanding of:</p>\n<ul>\n<li><p>How dataset merges are performed</p></li>\n<li><p>The types different union approaches a merge can take</p></li>\n<li><p>The &#39;mergeData&#39; function, and how to use it in the future</p></li>\n</ul>\n </details>\n <details>\n <summary> <h2 id=\"setup\">SETUP</h2>\n </summary> <p>Install these libraries onto the virtual environment.</p>\n  <pre class='prettyprint'>t = \"\"\" \n !pip install nbdev\n from google.colab import drive\n drive.mount('/content/drive')\n %cd /content/drive/My Drive/'Software Development Documents'/dataplay/ \n \"\"\"\n # !pip install dataplay</pre> <pre class='prettyprint'>from dataplay.intaker import Intake</pre> <pre class='prettyprint'>from VitalSigns.acsDownload import retrieve_acs_data</pre> <pre class='prettyprint'>%load_ext autoreload\n %autoreload 2</pre> <pre class='prettyprint'># @title Run: Import Modules\n \n # These imports will handle everything\n import numpy as np\n import pandas as pd</pre> <pre class='prettyprint'># hide\n pd.set_option('display.max_colwidth', -1)\n pd.set_option('max_colwidth', 20)\n pd.set_option('display.expand_frame_repr', False)\n pd.set_option('display.precision', 2)</pre> </details>\n <details>\n <summary> <h2 id=\"retrieve-datasets\">Retrieve Datasets</h2>\n </summary> <p>Our example will merge two simple datasets; pulling CSA names using tract ID&#39;s.</p>\n<p> The <strong>First</strong> dataset will be obtained from the Census&#39; ACS 5-year serveys. </p>\n<p> Functions used to obtain this data were obtained from Tutorial 0) ACS: Explore and Download. </p>\n <p> The <strong>Second</strong> dataset is from a publicly accessible link</p>\n <details>\n <summary> <h3 id=\"get-the-principal-dataset\">Get the Principal dataset.</h3>\n </summary> <p>We will use the function we created in our last tutorial to download the data!</p>\n <pre class='prettyprint'># Our download function will use Baltimore City's tract, county and state as internal paramters\n # Change these values in the cell below using different geographic reference codes will change those parameters\n tract = '*'\n county = '510'\n state = '24'\n \n # Specify the download parameters the function will receieve here\n tableId = 'B19001'\n year = '17'\n saveAcs = False</pre> <pre class='prettyprint'>df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n df.head()</pre>  </details>\n <details>\n <summary> <h3 id=\"get-the-secondary-dataset\">Get the Secondary Dataset</h3>\n </summary> <p>Spatial data can be attained by using the 2010 Census Tract Shapefile Picking <a href=\"https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&layergroup=Census+Tracts\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">Tool</a> or search their website for\n Tiger/<a href=\"https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2010.html\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">Line</a> Shapefiles</p>\n<blockquote>\n<p>The core TIGER/Line Files and Shapefiles do not include demographic data, but they do contain geographic entity codes (GEOIDs) that can be linked to the Census Bureau’s demographic data, available on data.census.gov.-census.gov</p>\n</blockquote>\n <p>For this example, we will simply pull a local dataset containing columns labeling tracts within Baltimore City and their corresponding CSA (Community Statistical Area). Typically, we use this dataset internally as a &quot;crosswalk&quot; where-upon a succesfull merge using the tract column, will be merged with a 3rd dataset along it&#39;s CSA column.  </p>\n <pre class='prettyprint'># !wget https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv</pre> <p>or, Alternately</p>\n <pre class='prettyprint'># !curl https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv\t> CSA-to-Tract-2010.csv</pre> <pre class='prettyprint'>print('Boundaries Example:CSA-to-Tract-2010.csv')</pre> <pre class='prettyprint'># Get the Second dataset. \n # Our Example dataset contains Polygon Geometry information. \n # We want to merge this over to our principle dataset. \n # we will grab it by matching on either CSA or Tract\n \n # The url listed below is public.\n \n print('Tract 2 CSA Crosswalk : CSA-to-Tract-2010.csv')\n \n from dataplay.intaker import Intake\n \n crosswalk = Intake.getData( 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv' ) \n crosswalk.head()</pre> <pre class='prettyprint'>crosswalk.columns</pre> </details>\n </details>\n <details>\n <summary> <h2 id=\"perform-merge--save\">Perform Merge &amp; Save</h2>\n </summary> <p>The following picture does nothing important but serves as a friendly reminder of the 4 basic join types.</p>\n <image src=\"https://docs.trifacta.com/download/attachments/123830435/JoinVennDiagram.png\" height='200px'/>\n \n<ul>\n<li><p>Left - returns all left records, only includes the right record if it has a match</p></li>\n<li><p>Right - Returns all right records, only includes the left record if it has a match </p></li>\n<li><p>Full - Returns all records regardless of keys matching</p></li>\n<li><p>Inner - Returns only records where a key match</p></li>\n</ul>\n <p>Get Columns from both datasets to match on</p>\n<p> You can get these values from the column values above.</p>\n<p> Our Examples will work with the prompted values</p>\n <pre class='prettyprint'>print( 'Princpal Columns ' + str(df.columns) + '')\n left_on = input(\"Left on crosswalk column: ('tract') \\n\" ) or \"tract\"\n print(' \\n ');\n print( 'Crosswalk Columns ' + str(crosswalk.columns) + '')\n right_on = input(\"Right on crosswalk column: ('TRACTCE10') \\n\" ) or \"TRACTCE10\" </pre> <p>Specify how the merge will be performed</p>\n <p>We will perform a left merge in this example.</p>\n<p> It will return our Principal dataset with columns from the second dataset appended to records where their specified columns match.</p>\n <pre class='prettyprint'>how = input(\"How: (‘left’, ‘right’, ‘outer’, ‘inner’) \" ) or 'outer'</pre> <p>Actually perfrom the merge</p>\n <pre class='prettyprint'>merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)\n merged_df = merged_df.drop(left_on, axis=1)\n merged_df.head()</pre> <p>As you can see, our Census data will now have a CSA appended to it.</p>\n <pre class='prettyprint'># Save Data to User Specified File\n # outFile = input(\"Please enter the new Filename to save the data to ('acs_csa_merge_test': \" )\n # merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL) </pre> </details>\n <details>\n <summary> <h2 id=\"final-result\">Final Result</h2>\n </summary> <pre class='prettyprint'>flag = input(\"Enter a URL? If not ACS data will be used. (Y/N):  \" ) or \"N\"\n if (flag == 'y' or flag == 'Y'):\n   left_df = Intake.getData( input(\"Please enter the location of your Left file: \" ) )\n else:\n   tract = input(\"Please enter tract id (*): \" ) or \"*\"\n   county = input(\"Please enter county id (510): \" ) or \"510\"\n   state = input(\"Please enter state id (24): \" ) or \"24\"\n   tableId = input(\"Please enter acs table id (B19001): \" ) or \"B19001\"\n   year = input(\"Please enter acs year (18): \" ) or \"18\"\n   saveAcs = input(\"Save ACS? (Y/N): \" ) or \"N\"\n   left_df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n \n print('right_df Example: CSA-to-Tract-2010.csv')\n \n right_df = Intake.getData( input(\"Please enter the location of your right_df file: \" ) or 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv' )\n print( 'Left Columns ' + str(left_df.columns))\n print( '\\n ')\n print( 'right_df Columns ' + str(right_df.columns) + '\\n')\n \n left_on = input(\"Left on: \" ) or 'tract'\n right_on = input(\"Right on: \" ) or 'TRACTCE10'\n how = input(\"How: (‘left’, ‘right’, ‘outer’, ‘inner’) \" ) or 'outer'\n \n merged_df = pd.merge(left_df, right_df, left_on=left_on, right_on=right_on, how=how)\n merged_df = merged_df.drop(left_on, axis=1)\n \n # Save the data\n # Save the data\n saveFile = input(\"Save File ('Y' or 'N'): \") or 'N'\n if saveFile == 'Y' or saveFile == 'y':\n   outFile = input(\"Saved Filename (Do not include the file extension ): \")\n   merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL);</pre> <pre class='prettyprint'>merged_df.head(1)</pre> </details>\n <details>\n <summary> <h2 id=\"advanced\">Advanced</h2>\n </summary> <p>For this next example to work, we will need to import hypothetical csv files</p>\n <p><strong>Intro</strong></p>\n<p> The following Python function is a bulked out version of the previous notes. </p>\n<ul>\n<li><p>It contains everything from the tutorial plus more.</p></li>\n<li><p>It can be imported and used in future projects or stand alone.</p></li>\n</ul>\n<p> <strong>Description:</strong> add columns of data from a foreign dataset into a primary dataset along set parameters. </p>\n<p> <strong>Purpose:</strong> Makes Merging datasets simple</p>\n<p> <strong>Services</strong></p>\n<ul>\n<li><p>Merge two datasets without a crosswalk</p></li>\n<li><p>Merge two datasets with a crosswalk</p></li>\n</ul>\n <pre class='prettyprint'>#@ title Run: Create mergeDatasets()\n \n # Worried about infinit interactive-loops. not an issue atm.\n # Crosswalk needs to have exact same column names as left/right datasets\n def mergeDatasets(left_ds=False, right_ds=False, crosswalk_ds=False,\n                   left_col=False, right_col=False,\n                   crosswalk_left_col = False, crosswalk_right_col = False,\n                   merge_how=False, # left right or columnname to retrieve\n                   interactive=True):\n   # Interactive will ask if use_crosswalk unless crosswalk_ds == 'no'\n \n   # 1. Used on Right Dataset in case merge_how is a column to pull. Returns False or Col\n   def checkMergeHow(ds, how, interactive):\n     inList = how in ['left', 'right', 'outer', 'inner']\n     inDf = Intake.checkColumn(ds, how)\n     if ( inList or inDf ): return how\n     elif ( not interactive ): return False\n     else:\n       try:\n         print('\\n Invalid merge column given. \\n Please select a value from either list');\n         print(\"\\n 1) Pull A single column from the right dataset: \", ds.columns)\n         print(\"OR \\n 2) Specify a type of join operation: (‘left’, ‘right’, ‘outer’, ‘inner’, columnName) \" )\n         return checkMergeHow(ds, input(\"Column Name: \" ), interactive);\n       except: return False # User probably trying to escape interactivity\n \n   # 2i. Load data via url. Coerce Dtype needed for merge.\n   def coerceForMerge( msg, first_ds, second_ds, first_col, second_col, interactive ):\n       if (interactive):\n         print(f'\\n---Casting Datatypes from-to: {msg} Datasets---');\n         print('Before Casting: ');\n         print('-> Column One: ', first_col, first_ds[first_col].dtype)\n         print('-> Column Two: ', second_col, second_ds[second_col].dtype)\n       second_ds, second_col = Intake.getAndCheck(second_ds, second_col, interactive)\n       first_ds, second_ds, status = Intake.coerce(first_ds, second_ds, first_col, second_col, interactive);\n       if (not status and interactive): print('\\n There was a problem!');\n       if (interactive):\n         print('\\n After Casting: ');\n         print('-> Column One: ', first_col, first_ds[first_col].dtype)\n         print('-> Column Two: ', second_col, second_ds[second_col].dtypes)\n       return first_ds, second_ds, second_col, status\n   # 2ii.\n   def mergeAndFilter(msg, first_ds, second_ds, first_col, second_col, how, interactive):\n       if interactive:\n         print(f'---PERFORMING MERGE : {msg}---');\n         print('Column One : ', first_col, first_ds[first_col].dtype)\n         print('How: ', how)\n         print('Column Two : ', second_col, second_ds[second_col].dtype)\n       first_ds = mergeOrPull(first_ds, second_ds, first_col, second_col, how)\n       return filterEmpties(first_ds, second_ds, first_col, second_col, how, interactive)\n \n   # Decide to perform a merge or commit a pull\n   def mergeOrPull(df, cw, left_on, right_on, how):\n \n     def merge(df, cw, left_on, right_on, how):\n       df = pd.merge(df, cw, left_on=left_on, right_on=right_on, how=how)\n       # df.drop(left_on, axis=1)\n       df[right_on] = df[right_on].fillna(value='empty')\n       return df\n \n     def pull(df, cw, left_on, right_on, how):\n       crswlk = dict(zip(cw[right_on], cw[how]  ) )\n       dtype = df[left_on].dtype\n       if dtype =='object':  df[how] = df.apply(lambda row: crswlk.get(str(row[left_on]), \"empty\"), axis=1)\n       elif dtype == 'int64':\n         df[how] = df.apply(lambda row: crswlk.get(int(row[left_on]), \"empty\"), axis=1)\n       return df\n \n     mergeType = how in ['left', 'right', 'outer', 'inner']\n     if mergeType: return merge(df, cw, left_on, right_on, how)\n     else: return pull(df, cw, left_on, right_on, how)\n \n   # 2iiii. Filter between matched records and not.\n   def filterEmpties(df, cw, left_on, right_on, how, interactive):\n     if how in ['left', 'right', 'outer', 'inner']: how = right_on\n     nomatch = df.loc[df[how] == 'empty']\n     nomatch = nomatch.sort_values(by=left_on, ascending=True)\n \n     if nomatch.shape[0] > 0:\n       # Do the same thing with our foreign tracts\n       if(interactive):\n         print('\\n Local Column Values Not Matched ')\n         print(nomatch[left_on].unique() )\n         print(len(nomatch[left_on]))\n         print('\\n Crosswalk Unique Column Values')\n         print(cw[right_on].unique() )\n \n     # Create a new column with the tracts value mapped to its corresponding value from the crossswalk\n     df[how].replace('empty', np.nan, inplace=True)\n     df.dropna(subset=[how], inplace=True)\n     # cw = cw.sort_values(by=how, ascending=True)\n     return df\n \n   # 0. Retrieve the left and right dataset.\n   if (interactive): print('---Handling Left Dataset Options---');\n   left_ds, left_col = Intake.getAndCheck(left_ds, left_col, interactive)\n   if (interactive): print('Left column:', left_col)\n \n   if (interactive): print('\\n---Handling Right Dataset Options---');\n   right_ds, right_col  = Intake.getAndCheck(right_ds, right_col, interactive)\n   if (interactive): print('Right column:', left_col)\n \n   if (interactive): print(f\"\\n---Ensuring Compatability Between merge_how (val: '{merge_how}') and the Right Dataset---\");\n   merge_how = checkMergeHow(right_ds, merge_how, interactive)\n   if (interactive): print(\"Column or ['inner','left','right','outer'] value: \", merge_how)\n \n   # 1. Retrieve the crosswalk dataset: check left-cw, right-cw. try coercing.\n   if (interactive): print(f'\\n---Checking Crosswalk Dataset Options---')\n   # if its a df\n   if (not Intake.isPandas(crosswalk_ds)):\n     default = str(crosswalk_ds).lower() == 'false'\n     # If the user used the the default crosswalk value 'False' as them if they want to use one.\n     if (default and interactive ): crosswalk_ds = input(\"\\nProvide a Crosswalk? ( URL/ PATH or  'NO'/ <Empty>/ 'FALSE' ) \") or  False\n     # Check if user opted to not use a crosswalk\n     use_crosswalk = not ((str(crosswalk_ds).lower() in [\"no\", '', 'none', 'false']))\n     if (use_crosswalk):\n       crosswalk_ds, crosswalk_left_col = Intake.getAndCheck(crosswalk_ds, crosswalk_left_col, interactive)\n       crosswalk_ds, crosswalk_right_col = Intake.getAndCheck(crosswalk_ds, crosswalk_right_col, interactive)\n \n   # 3. Coerce all datasets for Merge.\n   if ( Intake.isPandas(crosswalk_ds) ):\n     print('crosswalk_left_col',crosswalk_left_col)\n     left_ds, crosswalk_ds, crosswalk_left_col, status = coerceForMerge( 'Left->Crosswalk', left_ds, crosswalk_ds, left_col, crosswalk_left_col, interactive )\n     right_ds, crosswalk_ds, crosswalk_right_col, status = coerceForMerge( 'Right->Crosswalk',right_ds, crosswalk_ds, right_col, crosswalk_right_col, interactive )\n   else:\n     left_ds, right_ds, right_col, status = coerceForMerge('Left->Right', left_ds, right_ds, left_col, right_col, interactive )\n \n   if (interactive): print('\\n---All checks complete. Status: ', status, '---\\n');\n   if ( not status ):\n     if (interactive):print('Merge Incomplete. Thank you!');\n     return False;\n   else:\n     if (Intake.isPandas(crosswalk_ds)):\n       left_ds = mergeAndFilter('LEFT->CROSSWALK', left_ds, crosswalk_ds, left_col, crosswalk_left_col, crosswalk_right_col, interactive)\n       left_col = crosswalk_right_col\n     left_ds = mergeAndFilter('LEFT->RIGHT', left_ds, right_ds, left_col, right_col, merge_how, interactive)\n   return left_ds</pre> <details>\n <summary> <h3 id=\"function-explanation\">Function Explanation</h3>\n </summary> <p><strong>Input(s):</strong> </p>\n<ul>\n<li><p>Dataset url</p></li>\n<li><p>Crosswalk Url </p></li>\n<li><p>Right On </p></li>\n<li><p>Left On </p></li>\n<li><p>How </p></li>\n<li><p>New Filename</p></li>\n</ul>\n<p> <strong>Output:</strong> File</p>\n<p> <strong>How it works:</strong></p>\n<ul>\n<li><p>Read in datasets</p>\n</li>\n<li><p>Perform Merge</p>\n</li>\n<li><p>If the &#39;how&#39; parameter is equal to [&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;]</p>\n</li>\n<li><ul>\n<li><p>then a merge will be performed.</p></li>\n</ul>\n</li>\n<li><p>If a column name is provided in the &#39;how&#39; parameter</p>\n</li>\n<li><ul>\n<li><p>then that single column will be pulled from the right dataset as a new column in the left_ds.</p></li>\n</ul>\n</li>\n</ul>\n </details>\n <details>\n <summary> <h3 id=\"function-diagrams\">Function Diagrams</h3>\n </summary> <p>Diagram the mergeDatasets()</p>\n  <img src=\"https://bniajfi.org/images/mermaid/class_diagram_merge_datasets.PNG\">\n <p>mergeDatasets Flow Chart</p>\n  <img src=\"https://bniajfi.org/images/mermaid/flow_chart_merge_datasets.PNG\">\n <p>Gannt Chart  mergeDatasets()</p>\n  <img src=\"https://bniajfi.org/images/mermaid/gannt_chart_merge_datasets.PNG\">\n <p>Sequence Diagram  mergeDatasets()</p>\n  <img src=\"https://bniajfi.org/images/mermaid/sequence_diagram_merge_datasets.PNG\">\n </details>\n <details>\n <summary> <h3 id=\"function-examples\">Function Examples</h3>\n </summary> <pre class='prettyprint'># from VitalSigns.acsDownload import retrieve_acs_data\n # from dataplay.geoms import readInGeometryData </pre> <h4 id=\"interactive-example-1-merge-esri-data\">Interactive Example 1. Merge Esri Data</h4>\n <pre class='prettyprint'># Table: Household Childhood Poverty \n # Hhchpov = Intake.getData(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\", interactive=True)\n # Hhchpov = Hhchpov[['CSA2010', 'hhchpov15',\t'hhchpov16',\t'hhchpov17',\t'hhchpov18']] \n left_ds = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n left_col = 'CSA2010'\n \n # Table: Household Poverty \n # Hhpov = Intake.getData(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\", interactive=True)\n # Hhpov = Hhpov[['CSA2010', 'hhpov15',\t'hhpov16',\t'hhpov17',\t'hhpov18']] \n right_ds = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n right_col='CSA2010'\n \n merge_how = 'outer'\n interactive = False\n \n merged_df = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds='no',\n                   left_col=left_col, right_col=right_col,\n                   crosswalk_left_col = False, crosswalk_right_col = False,\n                   merge_how=merge_how, # left right or columnname to retrieve\n                   interactive=interactive)\n merged_df.head()</pre> <h4 id=\"example-2--get-csa-and-geometry-with-a-crosswalk-using-3-links\">Example 2 ) Get CSA and Geometry with a Crosswalk using 3 links</h4>\n <pre class='prettyprint'># Our download function will use Baltimore City's tract, county and state as internal paramters\n # Change these values in the cell below using different geographic reference codes will change those parameters\n tract = '*'\n county = '510' # '059' # 153 '510'\n state = '24' #51\n  \n # Specify the download parameters the function will receieve here\n tableId = 'B19049' # 'B19001'\n year = '17'\n saveAcs = False </pre> <pre class='prettyprint'>import pandas as pd \n import IPython \n # from IPython.core.display import HTML\n IPython.core.display.HTML(\"<style>.rendered_html th {max-width: 200px; overflow:auto;}</style>\")\n # state, county, tract, tableId, year, saveOriginal, save \n left_df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n left_df.head(1) </pre> <pre class='prettyprint'># Table: \n # Columns: Address(es), Census Tract\n left_ds = left_df\n left_col = 'tract'\n \n # Table: Crosswalk Census Communities\n # 'TRACT2010', 'GEOID2010', 'CSA2010'\n crosswalk_ds = 'https://raw.githubusercontent.com/bniajfi/bniajfi/main/CSA-to-Tract-2010.csv'\n crosswalk_left_col = 'TRACTCE10'\n crosswalk_right_col = 'CSA2010'\n \n # Table: \n right_ds = 'https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson'\n right_col = 'CSA2010'\n \n interactive = False\n merge_how = 'outer'\n \n merged_df_geom = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds=crosswalk_ds,\n                   left_col=left_col, right_col=right_col,\n                   crosswalk_left_col = crosswalk_left_col, crosswalk_right_col = crosswalk_right_col,\n                   merge_how=merge_how, # left right or columnname to retrieve\n                   interactive=interactive)\n \n merged_df_geom.head()</pre> <p>Here we can save the data so that it may be used in later tutorials. </p>\n <pre class='prettyprint'># string = 'test_save_data_with_geom_and_csa'\n # merged_df.to_csv(string+'.csv', encoding=\"utf-8\", index=False, quoting=csv.QUOTE_ALL)</pre> <h4 id=\"example-3-ran-alone\">Example 3: Ran Alone</h4>\n <pre class='prettyprint'>mergeDatasets( ).head(1)</pre> <pre class='prettyprint'>mergeDatasets().head(1)</pre> </details>\n  <script src=\"https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}