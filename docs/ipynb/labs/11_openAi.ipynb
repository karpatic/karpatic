{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAi\n",
    "> Experiments using the openAI library\n",
    "\n",
    "- hide: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://platform.openai.com/docs/guides/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    response_format={ type: \"json_object\" },\n",
    ")\n",
    "\n",
    "To use JSON mode, your system message must instruct the model to produce JSON. \n",
    "To help ensure you don't forget, the API will throw an error if the string \"JSON\" does not appear in your system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "speech_file_path = \"speech.mp3\"\n",
    "response = client.audio.speech.create(\n",
    "  model=\"tts-1\",\n",
    "  voice=\"echo\",\n",
    "  input=\"\"\"This is where I leave my notes (((I made this place for myself but it's open to the public.)))\n",
    "\n",
    "Employer? README. \n",
    " \"\"\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "openai.api_key = \"sk- ...\"\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"10\", \"unit\": \"celsius\"})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"72\", \"unit\": \"fahrenheit\"})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"22\", \"unit\": \"celsius\"})\n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "// console.log(OpenAI.Audio.Speech);  // Audio Speech // Assistant // Completions + Functions\n",
    "  \n",
    "  // thread Id =  \n",
    "  // run Id =  \n",
    "  \n",
    "  /*\n",
    "  const thread = await openai.beta.threads.create();\n",
    "  console.log('thread', thread.id);\n",
    "  \n",
    "  // Add a Comment to a Thread\n",
    "  const message = await openai.beta.threads.messages.create( thread.id, { role: \"user\", content: \"I need to solve the equation `3x + 11 = 14`. Can you help me?\" } );\n",
    "  \n",
    "  // Add Chatbot with Thread\n",
    "  const run = await openai.beta.threads.runs.create( thread.id, { assistant_id: \"asst_md7rq9HME4C3uUnmrMwRqiDi\", instructions: \"Please address the user as Jane Doe. The user has a premium account.\" } );\n",
    "  console.log('run', run.id);\n",
    "  */\n",
    "  /*\n",
    "  const run = await openai.beta.threads.runs.retrieve(\n",
    "      \"thread_YkCHeyvt4cpTx3dsRCAXamji\",\n",
    "      \"run_dXteBI7ldfWlJ27tlaQXygVQ\"\n",
    "  );\n",
    "  const messages = await openai.beta.threads.messages.list( \"thread_YkCHeyvt4cpTx3dsRCAXamji\" );\n",
    "  console.log(messages);\n",
    "  */"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
