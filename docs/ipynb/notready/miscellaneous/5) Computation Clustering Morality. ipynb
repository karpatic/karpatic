{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5) Computation Clustering Morality. ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3Ms0KDwgmDL5","colab_type":"text"},"source":["Pixmob Our LED objects have a unique pre-programmed code to trigger effects, which are controlled with a grandMA2 lighting console. For wireless object control, we use an infrared signal (like a TV remote). It’s fast (20 FPS), affordable, and avoids any interference with existing radio communications. Our transmitters are rugged, waterproof and encased in a standard LED PAR wash casing, connected to daisy-chained DMX and drawing under 3 amps of power. They can be installed on your existing rig or catwalk.\n","\n","https://towardsdatascience.com/from-tda-to-dl-d06f234f51d \n","https://github.com/robgibbons/youParse\n","https://github.com/rg3/youtube-dl\n","https://github.com/JMPerez/beats-audio-api\n","https://slideplayer.com/slide/8307659/\n","is-death-an-illusion-evidence-suggests-death-isnt-the-end \n","famous-laws-of-software-development \n","Immersivemath.com\n","https://mermaidjs.github.io/\n","https://mermaidjs.github.io/mermaid-live-editor/#/edit/eyJjb2RlIjoiZ3JhcGggVERcbkFbQXBwbGljYXRpb25dIC0tPnxBcnJvd0NhcHRpb258IEIoR28gc2hvcHBpbmcpXG5CIC0tPiBDe0Z1bmN0aW9ufVxuQiAtLT58QXJyb3dDYXB0aW9ufCBGdW5jdGlvbktleXtGdW5jdGlvbkxhYmVsfVxuQyAtLT58T3V0cHV0T25lfCBEW0xhcHRvcF1cbkMgLS0-fFR3b3wgRVtpUGhvbmVdXG5DIC0tPnxUaHJlZXwgRltmYTpmYS1jYXIgQ2FyXVxuRnVuY3Rpb25LZXkgLS0-IHxhcnJvd0NhcHRpb258IGtleSh2YWx1ZSlcblxuIiwibWVybWFpZCI6eyJ0aGVtZSI6ImRlZmF1bHQifX0\n","https://en.wikipedia.org/wiki/Basil_Bernstein\n","https://en.wikipedia.org/wiki/Semiotics\n","https://en.wiktionary.org/wiki/exocentric#English\n","https://www.slideshare.net/sanjabozicevic5/ad-polysemy-16009217\n","https://gitlab.com/painlessMesh/painlessMesh\n","Vae Victis\n","Compare Everything to ML JS\n","Jstat.github.io\n","S.tensorflow.org\n","BrainJS\n","Mljs\n","pca\n","Is-polynomial-regression-the-same-as-multiple-regression-i-e-values-are-only-raised-to-powers\n","https://github.com/wangzuo/react-medium-editor\n","http://square.github.io/crossfilter/https://github.com/vega/datalib\n","https://github.com/fredrick/gauss\n","https://github.com/Gmousse/dataframe-js\n","https://github.com/jstat/jstat\n","https://github.com/Tom-Alexander/regression-js\n","https://github.com/jstat/jstat\n","https://github.com/26medias/timeseries-analysis\n","http://app.rawgraphs.io/\n","https://github.com/nadbm/react-datasheet\n","https://datamatic.io/\n","https://gephi.org/\n","https://semiotic.nteract.io/guides/bar-chart\n","https://github.com/d3/d3/wiki/Gallery\n","https://www.npmjs.com/package/markovchain\n","https://public.tableau.com/s/\n","https://app.datawrapper.de/chart/J92KZ/visualize?tpl=rjRUb#refine-the-chart\n","https://www.cs.ubc.ca/~tmm/vadbook/furtherreading.html\n","https://www.cs.ubc.ca/~tmm/vadbook/figures.html\n","https://learn.sparkfun.com/tutorials/transistors/all\n","https://www.python-course.eu/expectation_maximization_and_gaussian_mixture_models.php\n","https://www.python-course.eu/tensor_flow_introduction.php\n","https://www.python-course.eu/principal_component_analysis.php\n","https://www.python-course.eu/Boosting.php\n","https://www.python-course.eu/Random_Forests.php\n","https://www.python-course.eu/Regression_Trees.php\n","https://www.python-course.eu/Decision_Trees.php\n","https://www.python-course.eu/neural_networks.php\n","https://www.python-course.eu/k_nearest_neighbor_classifier.php\n","https://www.python-course.eu/polynomial_class_in_python.php\n","https://www.python-course.eu/graphs_python.php\n","\n","https://github.com/sabbirahm3d/courses \n","https://github.com/RobRoseKnows/umbc-cs202/tree/master/Projects \n","https://github.com/justinUMBC/UMBC \n","https://github.com/klau616/UMBC-CMSC331-1-/tree/master/CMSC331/Project1 \n","https://github.com/bseipp/UMBC \n","https://github.com/mailmaldi/UMBC \n","https://www.csee.umbc.edu/courses/331/ \n","https://global.oup.com/us/companion.websites/9780195377927/student/chapter9/summary/\n","https://books.google.com/books?id=CicvkPZhohEC&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false\n","https://en.wikipedia.org/wiki/Swarm_intelligence\n","https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence\n","https://en.wikipedia.org/wiki/Machine_learning\n","https://en.wikipedia.org/wiki/Outline_of_machine_learning\n","https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research\n","https://en.wikipedia.org/wiki/Association_rule_learning\n","https://towardsdatascience.com/graph-algorithms-part-2-dce0b2734a1d\n"]},{"cell_type":"markdown","metadata":{"id":"VNn6xRNzlVr3","colab_type":"text"},"source":["consequences of inextricable complexity \n","\n","is it worth to simulate or emulate?\n","\n","consequences of ^ and       ^\n","\n","cost/benefit/challenges\n","\n","it would be impossible to know what models were used to develop your psyche\n","an imprint of the state is possible to observe; \n","\n","this imprint could then be extruded"]},{"cell_type":"markdown","metadata":{"id":"DSOIDL5ukytl","colab_type":"text"},"source":["Hierarchical temporal memory (HTM) is a biologically constrained theory (or model) of intelligence\n","\n","https://en.wikipedia.org/wiki/Hierarchical_temporal_memory\n","\n","Dynamics is a branch of mathematics that studies how systems change over time. Up until the 18th century, people believed that the future could be perfectly predicted given that one knows “all forces that set nature in motion, and all positions of all items of which nature is composed” (that one being is referred to as a Laplace Demon).\n","Now, provided that we believe that the world is fully deterministic, then the statement makes sense. The problem is that in reality, measured values (e.g. of forces and positions) are often approximated. What we didn’t realise back then is that even if one knows of all variables’ values, a slightly inaccurate approximation could result in a totally different future. This is rather disheartening as it suggests that in reality, even if we can build a supercomputer that resembles a Laplace Demon, in order for it to make any meaningful prediction of the future, all variables’ values must be perfectly obtained; not even a tiny deviation is allowed. This phenomenon where “small differences in initial conditions produce very great ones in the final phenomena” (Poincare) is studied by the theory of chaos.\n","In the next section, we will explore a simple dynamic system and show how it could produce chaos.\n"]},{"cell_type":"markdown","metadata":{"id":"Mc11e02Jkl2y","colab_type":"text"},"source":["14 Characteristics of Intelligent Behavior\n","- persistence\n","- decreasing impulsivity\n","- listening to others - with understanding and empathy\n","- cooperative thinking - social intelligence\n","- flexibility in thinking\n","- metacognition - awareness of one's own thinking\n","- striving for accuracy and precision\n","- a sense of humor\n","- questioning and problem posing\n","- drawing on past knowledge and applying it to new situations\n","- risk taking\n","- using all the senses\n","- ingenuity, originality, insightfulness: creativity\n","- wonderment, inquisitiveness, curiosity, and the enjoyment of problem solving\n","- a sense of efficacy as a thinker\n"]},{"cell_type":"markdown","metadata":{"id":"nLkce9lhkjxo","colab_type":"text"},"source":["Multiview learning"]},{"cell_type":"markdown","metadata":{"id":"OB_dtEpPkbXL","colab_type":"text"},"source":["https://en.wikipedia.org/wiki/Channel_capacity\n","\n","https://global.oup.com/us/companion.websites/9780195377927/book/\n","\n","Inductive arguments come in several forms, including enumerative, analogical, and causal.\n","\n","Nonmonotonic logic is not deductive. Building cannons for nonmonotonic logic is for induction.\n","An enumerative induction can fail to be strong by having a sample that's too small or not representative. When we draw a conclusion about a target group based on an inadequate sample size, we're said to commit the error of hasty generalization.\n","Opinion polls are enumerative inductive arguments, or the basis of enumerative inductive arguments, and must be judged by the same general criteria used to judge any other enumerative induction.\n",".\n","In analogical induction, or argument by analogy, we reason that because two or more things are similar in several respects, they must be similar in some further respect. We evaluate arguments by analogy according to several criteria: (1) the number of relevant similarities between things being compared, (2) the number of relevant dissimilarities, (3) the number of instances (or cases) of similarities or dissimilarities, and (4) the diversity among the cases.\n","A causal argument is an inductive argument whose conclusion contains a causal claim. There are several inductive patterns of reasoning used to assess causal connections. These include the Method of Agreement, the Method of Difference, the Method of Agreement and Difference, and the Method of Concomitant Variation.\n","Errors in cause-and-effect reasoning are common. They include misidentifying relevant factors in a causal process, overlooking relevant factors, confusing cause with coincidence, confusing cause with temporal order, and mixing up cause and effect.\n","Crucial to an understanding of cause-and-effect relationships are the notions of necessary and sufficient conditions. A necessary condition for the occurrence of an event is one without which the event cannot occur. A sufficient condition for the occurrence of an event is one that guarantees that the event occurs.\n","Even though an explanation is not an argument, an explanation can be part of an argument—a powerful inductive argument known as inference to the best explanation.\n","We use the criteria of adequacy to judge the plausibility of a theory in relation to competing theories. The best theory is the one that meets the criteria of adequacy better than any of its competitors.\n"]},{"cell_type":"markdown","metadata":{"id":"C5GIl4YWkVSR","colab_type":"text"},"source":["https://en.wikipedia.org/wiki/Differential_entropy\n","\n","https://en.wikipedia.org/wiki/Rate%E2%80%93distortion_theory\n","\n","Rate–distortion theory is a major branch of information theory which provides the theoretical foundations for lossy data compression; it addresses the problem of determining the minimal number of bits per symbol, as measured by the rate R, that should be communicated over a channel, so that the source (input signal) can be approximately reconstructed at the receiver (output signal) without exceeding an expected distortion D."]},{"cell_type":"markdown","metadata":{"id":"kgbzGVz0kRgQ","colab_type":"text"},"source":["https://plato.stanford.edu/entries/logic-nonmonotonic/\n","\n","uncertain inference, ranging from probability to inductive logic to nonmonotonic logic\n","Coping with uncertainty is a necessary part of ordinary life and is crucial to an understanding of how the mind works. It is a vital element in developing artificial intelligence that will not be undermined by its own rigidities.\n","This book seeks to provide a clear exposition of these approaches within a unified framework\n","\n","An argument form is valid if and only if whenever the premises are all true, then conclusion is true. An argument is valid if its argument form is valid. For a sound argument, An argument is sound if and only if it is valid and all its premises are true.\n","\n","Kolmogorov Complexity - In algorithmic information theory (a subfield of computer science and mathematics), the Kolmogorov complexity of an object, such as a piece of text, is the length of the shortest computer program (in a predetermined programming language) that produces the object as output. It is a measure of the computational resources needed to specify the object, and is also known as algorithmic complexity, Solomonoff–Kolmogorov–Chaitin complexity, program-size complexity, descriptive complexity, or algorithmic entropy. It is named after Andrey Kolmogorov, who first published on the subject in 1963.[1][2]\n","The notion of Kolmogorov complexity can be used to state and prove impossibility results akin to Cantor's diagonal argument, Gödel's incompleteness theorem, and Turing's halting problem. In particular, for almost all objects, it is not possible to compute even a lower bound for its Kolmogorov complexity (Chaitin 1964), let alone its exact value.\n"]},{"cell_type":"markdown","metadata":{"id":"gaOLkKid4lup","colab_type":"text"},"source":["Rices Theorem"]},{"cell_type":"markdown","metadata":{"id":"ikIIiCGJeqC3","colab_type":"text"},"source":["Clustering: \n","- Hierarchal \n","- Kmeans (Euclidean, Mikowski, Manhattan, #Clusters) - super/unsuper - sort by centroid\n","- anomoly-detection - outliers, super/unsuper"]},{"cell_type":"markdown","metadata":{"id":"IdmmCClCerQh","colab_type":"text"},"source":["Confidence intervals on scatter plots/ pearson coefficients/ linear regression\n","\n","properties of estimators (bias, consistency, efficiency, sufficiency, robustness). \n","Testing: Type I and II errors, power, likelihood ratios\n","\n","https://en.wikipedia.org/wiki/Gini_coefficient\n","\n","https://en.wikipedia.org/wiki/Coefficient_of_variation"]},{"cell_type":"markdown","metadata":{"id":"1fIu0EpA2XnQ","colab_type":"text"},"source":["## erp"]},{"cell_type":"markdown","metadata":{"id":"HnV6DLQTHBeo","colab_type":"text"},"source":["https://en.wikipedia.org/wiki/Test_statistic\n","\n","https://arxiv.org/abs/1712.00646\n","\n","\n","activation function\n","nonlinear vs function\n","derivative vs monotonicity\n","sigmoid/logic -> softmax <  tanh < relu < leaky relu\n","\n","anisotropic\n","dyn.time.warp. hmm\n","\n","spatial inequality\n","40 segregation measures\n","speghetti - networks, topology, inference | graphs\n","\n","\n","pearson -> continuous\n","corr-> redudency\n","random forest features selection tuning tree depth\n","dtw frequency\n","\n","pointsPatterns - basic struc, centrography, viz/marks\n","distance measures -> nearest neigh, mean, event->event, point->event\n"]},{"cell_type":"code","metadata":{"id":"hm4AEco-_Yhe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5GSlFg3_YfU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFD2tc_6_YdE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztDk02AMALx8","colab_type":"text"},"source":["domain analysis\n","moores law - transistors\n","gustafsons law - parallelism and function latency\n","amdahls law - optimization diminishing returns\n","\n","critical path method - program evaluation and review technique\n","\n","Research back then concentrated on the idea that creating an intelligent machine has something to do with formal reasoning. This gave birth to languages such as Prolog and expert systems. The intuition behind that idea was that humans are using symbols and rules in order to navigate the world. Therefore, in order to mimic human intelligence, machines should follow the same process. This way of thinking failed spectacularly leading to what is known as the AI winter, a period in AI during which no-one was willing to invest in AI ventures after the extremely high expectations about the success of AI to pretty much anything failed to materialise.\n","\n","\"winter\" of the 1970s\n","\n","So, the approach in classic AI was “top-down“: hand craft the rules and the knowledge into the system and then intelligent behaviour will ensue. However, in the 80s and the 90s two things took place. First, an improvement in machine learning algorithms, which started with the discovery of backpropagation with neural networks and followed on by the discovery of algorithms such as Support Vector Machines and Random Forests. Secondly, an increased volume of data. This made machine learning and the “bottom-up” approach to AI the standard paradigm. Instead of creating countless rules, create a system that can learn from data.\n","\n","This approach is interesting, but obviously it has failed to create true artificial intelligence. The success of systems like Watson and deep neural nets might have tricked many people into thinking that general AI is near, but we are still far. These systems have indeed been very successful in a variety of problems, but they are missing an important component: They can’t reason the way humans do.\n","\n","So, for example, deep neural nets can learn various representations hidden in data, but it can’t reason formally over these representations. A network might be able to caption an image but it does not have a concept, of let’s say, a girl. It’s missing the equivalent of a semantic network, as well as formal rules to reason over those concepts or perform logic inference.\n","\n","model driven:\n","- infinit complexity\n","- deep understanding\n","- noisy data\n","- non included vars\n","- complexity\n","- mission critical\n","- dynamic adaptive\n","- verify explain\n","- high risk\n","- deductive reasoning\n","- logical inference\n","- bounded logics/reasoning\n","- contraint solving\n","- decision trees->expert systems\n","- np hard or worse\n","uncertainty/risk\n","only works on artificial restrictions\n","- branch and bound - opper and lower bound optimizations\n","- meta heuristics -> evolutionary alg/ local search solve computationally hard optimization problems\n","- heuristic search / relaxation\n","\n","\n","automated data exploration necessitates reasoning over the data.\n","the method of reasoning is a symoblic one more than a connectionist one.\n","\n","connection driven:\n","model infered statistically\n","features require careful selection\n","normalization and scaling required to not have features overpower eachother\n","feature engineering - overfit/undefitting\n","curse of dimensionallity\n","data driven algorithms assume universal uniformity/ world is relatively stable (changes at a manageble rate)\n","\n","overlaying symbolic constraints ensures obvious logic is still enfoardcedx\n","\n","rational vs empirical paradigm\n","classical AI to data-driven AI\n","\n","One of the main stumbling blocks of symbolic AI, or GOFAI, was the difficulty of revising beliefs once they were encoded in a rules engine. Expert systems are monotonic; that is, the more rules you add, the more knowledge is encoded in the system, but additional rules can’t undo old knowledge\n","\n","A second flaw in symbolic reasoning is that the computer itself doesn’t know what the symbols mean; i.e. they are not necessarily linked to any other representations of the world in a non-symbolic way. Again, this stands in contrast to neural nets, which can link symbols to vectorized representations of the data, which are in turn just translations of raw sensory data. So the main challenge, when we think about GOFAI and neural nets, is how to ground symbols, or relate them to other forms of meaning that would allow computers to map the changing raw sensations of the world to symbols and then reason about them.\n","\n","Supervised learning -> Hybrid ai\n","\n","rule based(flat) vs tree based (hiearchial) \n","\n","topics from the same domains:\n","Quantitative, qualitative (= types of inquiry)\n","Empirical, sensory-based, a posteriori, speculative (= inference basis) "]},{"cell_type":"code","metadata":{"id":"VZTcfDojAOKV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sCxQvuvAOEx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RdzwBREBAOCN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GB8LFr2G-m6z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3etaYejA_7z8","colab_type":"text"},"source":["Empirical relationships and associations are also frequently studied by using some form of general linear model, non-linear model, or by using factor analysis. A fundamental principle in quantitative research is that correlation does not imply causation, although some such as Clive Granger suggest that a series of correlations can imply a degree of causality. This principle follows from the fact that it is always possible a spurious relationship exists for variables between which covariance is found in some degree. Associations may be examined between any combination of continuous and categorical variables using methods of statistics.\n","\n","David Hume argued that beliefs about causality are based on experience, and experience similarly based on the assumption that the future models the past, which in turn can only be based on experience – leading to circular logic. In conclusion, he asserted that causality is not based on actual reasoning: only correlation can actually be perceived.[17] Immanuel Kant, according to Beebee, Hitchcock & Menzies (2009), held that \"a causal principle according to which every event has a cause, or follows according to a causal law, cannot be established through induction as a purely empirical claim, since it would then lack strict universality, or necessity\".\n"," \n","From the point of view of thermodynamics, universal properties of causes as compared to effects have been identified through the Second law of thermodynamics, confirming the ancient, medieval and Cartesian[18] view that \"the cause is greater than the effect\" for the particular case of thermodynamic free energy. This, in turn, is challenged[dubious – discuss] by popular interpretations of the concepts of nonlinear systems and the butterfly effect, in which small events cause large effects due to, respectively, unpredictability and an unlikely triggering of large amounts of potential energy.\n","\n","Intuitively, causation seems to require not just a correlation, but a counterfactual dependence.\n","\n","A major goal of scientific experiments and statistical methods is to approximate as best possible the counterfactual state of the world."]},{"cell_type":"code","metadata":{"id":"AqCCU8Bn_7rV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v_mEnqSxzq2y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"soGxOuS7_7LF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"11ksg2ZX_7I3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5RjpAts_7GV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mtR3FuNFzq04","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"McxRtLBOzqyT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yX3dHUUzZcJ7","colab_type":"text"},"source":["peers need to work on the same thing so they can recognize importance. but the importance is not practically significant. \n","\n","active learning not trendy. Lex friedman likes it.\n","\n","eric shmidt - look at scalability. growth/optimization is shaped by its realm of possiblities. \n","\n","overestimate a year. underestimate what will be done in 10. think 5 years ahead by having and a model for whats going to happen under the underlying platforms: shroud of uncertainty\n","\n","understand improvements to understand changes. a dreamer is a dissident of the zeitgeist.  \n","\n","brain development is speciated. humans take 25 years. develop according to chemical release and physical enviornmental stimuli. embryonic development starts with a homogeneous multi-potent stem cells. later they become heterogenous and specialized. neurons made first then glia. assembled in specific ways. a brain cant be made in a pitri dish. mylin sheets are barely developed after many years post birth.\n","brain plasticity is key for learning.\n","\n","meaning of life - \n","plato - knowledge\n","niche - power\n","earnest becker - escape death\n","darwin propogate genes\n","nihilist - none\n","modernist - fufillment, life health stimulation access to living cultural social world. \n","\n","supervised learning approach to ml means that the ai will never perform better.\n","self supervised learning is learning from itself using manipulations of itself.\n","\n","reinforcement learning requires an objective function that serves as a reward to be served after every action so that policy gradients can update after thousands of simulations. requires temporal memory and is suffers from by a credit assignment problem at the end of each episode. reward happens at end of each episode. very inefficient. random exploration may never yield a reward. reward shaping is a custom process where intermittent rewards are included but suffers from alignment.\n","\n","active learning - train on sliver of annotated data then predict on rest. show person machine labeled data with low confidence and retrain the dataset.\n","\n","\n","raw data VS labels. \n","\n","\n","\n","Ian Goodfellow - GANS\n","Jan Le Cun - Deep Learning - Self Supervised learning (not unsupervised)"]},{"cell_type":"markdown","metadata":{"id":"GROuoUrqUUjq","colab_type":"text"},"source":["New AI Winter? - of 18 top recML only 7 are reproducable. 6 of those could be beat by simple ML heuristics (nearest neigh/graph based techniques). last was not consistent enough to test. are we really making progress?\n","\n","Survey vs Administrative\n","Composite Indicators/ Ratio/ Merged/ Hierarchy/ foreign relationships"]},{"cell_type":"code","metadata":{"id":"F_OUodMh-nbS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"63nyT_tBdUb_","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fJK4OslKdUfN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"thhosIW9816t","colab_type":"text"},"source":["The median tempo of the tracks was 128 beats per minute. After this, I extracted 1-bar, 1.827-second loops from each track\n","\n","Since sound is a wave, it cannot be stored directly in bits. Instead, the height of the sound wave at regular intervals is stored. The sampling frequency is the number of times the samples are extracted each second. This is usually 44100 times per second, so one second of audio will usually be represented by 44100 numbers.\n","The number of samples per second is called the sampling rate or sampling frequency.\n","Suppose the highest frequency component, in hertz, for a given analog signal is fmax. According to the Nyquist Theorem, the sampling rate must be at least 2fmax, or twice the highest analog frequency component.\n","\n","Since 22050 is above the human hearing limit, 44100 times per second is a good choice, and, assuming the samples have high precision, we cannot hear the loss of information caused by (non-compressed) digital audio sampled at 44100Hz."]},{"cell_type":"code","metadata":{"id":"s5webnhodSrS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ff70fzMMdU_g","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0kVNTaJdSvJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uqVthvQS3JX","colab_type":"text"},"source":["https://plato.stanford.edu/entries/law-limits/\n","I think, therefore, that it is not possible to set theoretical limits to the power of the State to legislate against immorality. It is not possible to settle in advance exceptions to the general rule or to define inflexibly areas of morality into which the law is in no circumstances to be allowed to enter.\n","—Lord Devlin, The Enforcement of Morals (pp.12–13)\n","\n","Though they seek the best means of reaching their goals, they might fail and the failure could be dramatic.\n","These are familiar stories in skeletal form and illustrate the commonplace that the methods the law might use can simply misfire. There are limits to what the law can achieve because some of its tools are blunt. Some tools do not work, others are counter-productive; some exacerbate the problem they were supposed to resolve. Knowing what works and what does not and what will be counterproductive is important knowledge indeed. Again, enforcement of a desired policy may be prohibitively expensive and divert resources away from still more important goals a state may wish to pursue. A state may also need to consider in some contexts the psychology of its citizens. Perhaps there is something in the Freudian notion of ‘pale criminality’: ‘the condition of one who commits a crime because of, rather than in spite of, its forbidden status’ (Scheffler 1992, pp. 70-71).[1] There may also be what David Lewis calls a ‘mixture problem.’ Lewis had in mind in particular John Stuart Mill's point that truth and error may be found combined in one package deal, so that there is no way of suppressing the error without suppressing truth as well (Lewis 2000, p. 164). But the point can be made more general: there may be no way for a state to suppress a greatly undesired activity without also disturbing a greatly desired activity.[2] The law in short is limited by the tools it has at its disposal and the effects that these tools will have. We might call these ‘means-ends limits’ or ‘practical limits’. Law can coerce, it can make rules, it can adjudicate, but one can only go so far with these tools (Fuller 1978). Law must seek to do the best possible with the tools available.\n","Law does have limits. It is important to bear such practical limits in mind, since one possible way to delineate the limits of the law is that such practical limits are the only limits that States must negotiate in its legislative and more broadly legal behaviour, beyond the platitude that it must act in a morally acceptable way. \n","\n","In this sense the immorality of an action or value of the goal to be achieved are none of them sufficient of themselves for state coercion. The controversy begins when the question of principled limits is raised.\n","\n","Must the state abstain from considering and acting upon certain kinds of consideration in order to rise above the sectarian adherence or invocation of one controversial understanding of what makes for a good life?\n","\n","Disagreement can be widespread and intractable. So what should a state do in the here-and-now where there is no consensus, even among reasonable people, about what ought to be done? Can it simply enforce what it takes, controversially, to be the right solution? On the other hand if one tries to restrain in principle the State's recourse to moral argument, ruling out of consideration certain kinds of argument based on moral truth, the challenge is to do this on a satisfying basis that is not merely ad hoc.\n","\n","Far and away the best known proposal for a principled limit to the law is the ‘harm principle’ of John Stuart Mill:\n","The sole end for which mankind are warranted, individually or collectively, in interfering with the liberty of action of any of their number is self-protection. That the only purpose for which power can rightfully be exercised over any member of a civilised community against his will is to prevent harm to others. His own good, whether physical or moral, is not a sufficient warrant. (Mill 1993, ch. 1, para 9)\n","He did not think the principle applied to persons living in communities that had not yet progressed to the point of ‘civilisation’ (Mill 1993, p.79). In communities in which there had been sufficient progress towards civilisation, it is of great importance to protect and promote liberty of action for all.\n","\n","Interference with liberty of action, especially by the use of power or coercion, required a special sort of justification: that it was needed to prevent harm to others. To coerce on the basis that one wishes to avoid harm to others is of course to coerce on a moral ground. Mill thought that no other moral ground would be good enough.\n","\n","It is possible to extract from Plato's Republic and Laws, and perhaps from Aristotle's Ethics and Politics, the following thesis about the role of law in relation to the enforcement of morality: the law of the city state exists not merely to secure that men have the opportunity to lead a morally good life, but to see that they do. According to this thesis not only may the law be used to punish men for doing what morally it is wrong for them to do, but it should be so used; for the promotion of moral virtue by these means and by others is one of the ends or purposes of a society complex enough to have developed a legal system. This theory is strongly associated with a specific conception of morality as a uniquely true or correct set of principles—not man-made, but either awaiting man's discovery by the use of his reason or (in a theological setting) awaiting its disclosure by revelation. I shall call this theory “the classical thesis” and not discuss it further. (Hart 1983, p. 248)\n","\n","Having gone to the trouble to state the thesis in question—that the State should see to it that people live good lives—and to cite two heavyweights in its support, Hart's final sentence comes as something of a surprise. He took the view, it would seem, that there was little to be said for a view of morality according to which it awaited discovery by reason or disclosure through revelation. So much so that it was not worthy of serious discussion. It is contrasted with ‘man-made’ morality which Hart does consider worth discussing in the present context.\n","\n","‘Self protection,’ for him, stretches to the idea of self-protection on the part of the state. In Devlin's view a society is in part constituted by its morality and it therefore has a right to defend itself against any attack on that morality.\n","\n","For society is not something that is kept together physically; it is held by the invisible bonds of common thought. If the bonds were too far relaxed the members would drift apart. A common morality is part of the bondage. The bondage is part of the price of society; and mankind, which needs society, must pay its price. (Devlin 1965, p. 10)\n","\n","But it is this very aspect of his thought which makes his view untenable. Bernard Williams has shown that the tempting line of thought of the sort adopted by Devlin is often underlain by an unstable amalgam of relative and non-relative views.\n","\n","‘Activity X is wrong’\n","‘Activity X is wrong in the functional sense, i.e. for the persistence of that society’\n","Therefore ‘Society S has the right to do what is necessary to preserve its own existence; it may do what is necessary to suppress Activity X’ \n","\n","Raz does not follow Mill's utilitarian path to the defence of the harm principle. Adopting a value-pluralist notion of morality, he argues in short that even though:\n","There are no principled limits to the pursuit of moral goals on the part of the state.\n","There are (nevertheless) limits to the means that can legitimately be adopted in promoting the well-being of people and in the pursuit of moral ideals (Raz 1986, p. 420; George 1993, pp. 161-188).\n","\n","For present purposes the essential steps of the argument seem to be these:\n","‘Coercion/manipulation tend to reduce options or distort normal processes; this is a natural fact.\n","This natural fact has become the basis of a social convention which loads acts of coercion/manipulation with symbolic meaning expressing disregard, even where there is no significant diminution in the adequacy of valuable options.\n","\n","Criminalizing the smoking would express disrespect or contempt for the smoker, not because his options are in fact left inadequate, but because a convention has formed giving coercion this sort of meaning.\n","\n","Not all coercion is a global assault on autonomy—it is true—but there is ample support for a principled limit to the law based on coercion, because a social convention takes up the slack in cases in which coercion is not a serious threat to autonomy.\n","\n","‘Once an action-type has acquired a symbolic significance by virtue of the disrespect it typically displays, its tokens will possess that significance and communicate the same content even if the reason does not apply to them.’ (Dan-Cohen 2002, p. 162).\n","\n","According to the asymmetry argument: coercing to prevent harm leads to autonomy-gain, coercing to prevent (harmless) immorality leads to autonomy-loss; and that explains why legal coercion should be limited by harm-based considerations. It is for the sake of autonomy.\n","\n","The argument depends on a particular understanding of harm as autonomy. Coercing persons out of harmful behaviour, viz. autonomy-damaging, is at least for the sake of autonomy in the end. But coercing persons out of behaviour that is (harmlessly) worthless gives one no autonomy-gain. There is no autonomy-loss to be sure, in doing away with worthless behaviour, but that is not the point: one must factor in the autonomy-loss involved in the coercion itself. So coercing against harmful behaviour, if done properly, leaves one with an autonomy-gain on balance. But coercing against (harmless) immorality gives one an autonomy-loss, due to the coercion itself, which puts the account in debit, with no positive gain in autonomy to counterbalance the loss.\n","\n","A moral theory which values autonomy highly can justify restricting the autonomy of one person for the sake of the greater autonomy of others or even of that person himself in the future. That is why it can justify coercion to prevent harm, for harm interferes with autonomy. But it will not tolerate coercion for other reasons. The availability of repugnant options, and even their free pursuit by individuals, does not detract from their autonomy. Undesirable as those conditions are they may not be curbed by coercion. (Raz 1986, pp. 418-419)\n","\n","Could it not be that the availability of some repugnant options does detract from the autonomy of some people? The image of the tree surgeon comes to mind. Some branches are lopped off by the tree surgeon for the health of the tree. Taking off a branch gives the tree a better chance to flourish. Could there not be some worthless options in society that are like one of the branches on the tree? If one assumes for the sake of argument that gambling for non-trivial amounts is a worthless option and that some who pursue this option will do so to the detriment of what is valuable and what they care about most, their families, jobs and long-term hobbies. Might it not be that the existence of the option detracts from the chances of many to achieve success in these valuable pursuits? I actually suspect, to be sure, that any attempt to coerce gambling along these lines would have many negative side-effects and for this reason should not be pursued in practice, but this would largely be due to practical and means-ends limits rather than any matter of principle. Serious gambling probably does get in the way of valuable options of many and does not enhance the value of the life of anyone. Perhaps this judgement is wrong. But it would in any case be a surprising empirical result to discover that autonomy could never be enhanced by the societal equivalent of tree surgery in this case or in any other. It is not implausible to think that the availability of some repugnant options just makes the autonomous life harder.[9] If this is the case, the asymmetry argument seems not to work. Perhaps coercion to prevent harmless immorality may lead to an autonomy gain, just as it does, all going correctly, when the aim is to prevent harm.\n","\n","Raz's account I think succeeds in establishing the very great significance of autonomy in political morality. As far as the limits of the law is concerned, it establishes that very great caution is in order in the use of imprisonment, given what this can do to the adequacy of the prisoner's valuable options. Caution, too is important over lesser degrees of coercion. It does not, however, seem able to support the harm principle for the coercion based considerations do not neatly settle only on harm-based considerations.\n","\n","This argument is slightly different from the argument of neutrality, though they are close cousins.[10] If we assume:\n","A state believes X is wrong for various reasons\n","It can coerce persons out of X without violating means-ends or practical limits.\n","\n","It implies that if you force someone to serve an end that he cannot be given adequate reason to share, you are treating him as a mere means—even if the end is his own good, as you see it but he doesn't. In view of the coercive character of the state, the requirement becomes a condition of political legitimacy. (Nagel 1991, p. 159)\n","\n","It has been pointed out many times by Kantians that treating someone as a means only is not the same as treating someone as a means. One can take a taxi even though that involves treating the taxi-driver as a means to one's ends, but the driver must not be treated as a means only. However:\n","\n","It implies that if you force someone to serve an end that he cannot be given adequate reason to share, you are treating him as a mere means—even if the end is his own good, as you see it but he doesn't\n","\n","On his view it might be permissible to force someone to serve an end if that person can be given adequate reason to share the end, even if he does not accept it. Giving someone adequate reason then is not a matter of simply deferring to the views of others.\n","\n"," Take for example a lawmaker, perhaps religious, who adopts the view of a small minority that personhood begins from the moment of conception and makes a law declaring abortion illegal on this basis. This is precisely the sort of move that Nagel and Rawls want to rule out. A controversial view such as this one has, for them, no place in making law for the public backed up by coercion. Irrespective of whether or not it is true metaphysically that personhood begins from the moment of conception, a view of this sort should be firmly locked out.\n"," \n","Robert George for one spends some time arguing this, claiming that from the point of conception there is ‘a genetically complete organism directed towards its own functioning.’ (George 1999, pp. 209-213). As for the second point, the argument about abortion also shows the difficulty of trying to separate out arguments about ‘the good’ from arguments about ‘the right.’ For if George is right that abortion is murder, it cannot be relegated to a question of the right and excluded from political justification. As we saw when discussing neutrality, no neutralist argues the law need be neutral about what is right. A group, call them the ‘evolutionary exterminators,’ could not be heard by the neutralist to argue that their desire to kill all homeless people should be treated in the same way as the desires of bird-watchers. Bird watchers, the neutralist would say, do not violate rights; ‘evolutionary exterminators’ do, or would if allowed their way. This still leaves open the question of what counts as a rights violation. If abortion is murder that would\n"," \n"," is the better view that law-makers should, as a matter of principle, be denied recourse to certain moral premises based on the good life, not because the premises are false, but in an attempt to dissipate the feeling that partisan conceptions of the good, held by some only, are being especially favoured? Here one soon runs into the problem that in eschewing full recourse to the truth in political argument, one is apt to come up against some awkward opponents, espousing sometimes unpalatable views, who are happy to render their arguments public, happy to make them subject to ‘reasonable rejectability’ and happiest of all to assert that their principles cannot be reasonably rejected. The debate is set to continue for some time yet.\n","  \n","it will be difficult to dispel the notion that law-makers are being cut too much slack and that some persons are being specially blessed by the law in comparison to others: for disagreement on matters of what is genuinely demanded by truth and morality is showing no sign of going away. This may merely be a facet of the human condition and in fighting it we may be tilting at windmills.\n","\n","On the other hand, is the better view that law-makers should, as a matter of principle, be denied recourse to certain moral premises based on the good life, not because the premises are false, but in an attempt to dissipate the feeling that partisan conceptions of the good, held by some only, are being especially favoured? Here one soon runs into the problem that in eschewing full recourse to the truth in political argument, one is apt to come up against some awkward opponents, espousing sometimes unpalatable views, who are happy to render their arguments public, happy to make them subject to ‘reasonable rejectability’ and happiest of all to assert that their principles cannot be reasonably rejected. The debate is set to continue for some time yet."]},{"cell_type":"markdown","metadata":{"id":"xvYPoSKHfvn3","colab_type":"text"},"source":["https://plato.stanford.edu/entries/grounds-moral-status/\n","there are two ways of understanding moral status, or what others sometimes call “moral standing” or “moral considerability.” On the utilitarian approach (see the entry on the history of utilitarianism), moral considerability (their preferred term) is a matter of having one’s interests (e.g., the intensity, duration, etc. of one’s pleasure or pain) factored into the calculus that determines which action brings about the greatest utility. On the non-utilitarian approach, to have moral status is for there to be reasons to act for the sake of the entity or its interest, reasons which are prior to, and may clash with, what the calculation of the overall best consequences would dictate. The non-utilitarian approach is necessarily coupled with two further ideas: acting unjustifiably against such reasons as well as failing to give these reasons their proper weight in deliberation is not only wrong but wrongs the entity and one owes it to the entity to avoid acting in this way. Note that utilitarians could incorporate these two ideas by claiming that it is owed to entities with moral status to properly incorporate their interests into the utilitarian calculus, and that one wrongs an entity when this is not done. But these two ideas are inessential to the utilitarian approach.\n","Some non-utilitarian philosophers allow for the possibility that moral status comes in degrees, and introduce the notion of a highest degree of status: full moral status (FMS). After reviewing which entities have been thought to have moral status and what is involved in having FMS, as opposed to a lesser degree of moral status, this article will survey different views of the grounds of moral status, focusing especially on FMS, as well as the justification for treating these as grounds of moral status.\n","    \n","It is usually taken for granted that all adult cognitively unimpaired human beings have FMS. Of course, historically the moral status of people falling into a group perceived as “other,” such as foreigners, racial minorities, women, the physically disabled, etc. has been routinely denied. Either they were not seen as having any moral status, or if they were granted some status, it was not FMS. However, accounting for their status does not pose much of a theoretical challenge (see section 5.1) and nowadays their status is rarely explicitly and directly denied on principled moral grounds.\n","\n","By contrast, constructing plausible theories that account for the moral status of other human beings – not only the degree of their status, but in some cases also whether they have it at all – is more challenging (see section 5). Debates about disability rights and the permissibility of eugenics rest in part on theoretical disagreements about the moral status of cognitively impaired humans. These issues include controversies regarding the treatment of cognitively disabled infants, such as the past U.S. practice of allowing infants with Down syndrome to die. Debates concerning abortion, stem cell research (see the entry on the ethics of stem cell research), and the question of what to do with unused frozen embryos from in vitro fertilization also rest on the theoretical question of the moral status of extremely underdeveloped human beings at various stages of development: zygote, embryo, and fetus (see section 5.2). The moral status of both underdeveloped and cognitively impaired human beings is often taken to be at issue when it comes to the use of pre-implantation genetic diagnosis and amniocentesis. In addition, medical advances that prolong life, as well as debates about euthanasia, have led people to question the moral status of humans incapable of consciousness, such as those in a persistent vegetative state and anencephalic babies (born without the higher brain).\n"]},{"cell_type":"markdown","metadata":{"id":"ciGAWycRulnK","colab_type":"text"},"source":["https://plato.stanford.edu/entries/concept-evil/\n","Nietzsche argues that the concept of evil arose from the negative emotions of envy, hatred, and resentment (he uses the French term ressentiment to capture an attitude that combines these elements). He contends that the powerless and weak created the concept of evil to take revenge against their oppressors. Nietzsche believes that the concepts of good and evil contribute to an unhealthy view of life which judges relief from suffering as more valuable than creative self-expression and accomplishment.\n","\n","Some people believe that we should not abandon the concept of evil because only the concept of evil can capture the moral significance of acts, characters, and events such as sadistic torture, serial killers, Hitler, and the Holocaust. As Daniel Haybron puts it “Prefix your adjectives [such as ‘wrong’ or ‘bad’] with as many ‘very’s as you like; you still fall short. Only ‘evil’, it seems, will do” (Haybron 2002b, 260). According to this line of argument, it is hard to deny that evil exists; and if evil exists, we need a concept to capture this immoral extreme.\n","\n","2.2 Kant’s Theory of Evil\n","Immanuel Kant, in his Religion Within the Limits of Reason Alone, was the first to offer a purely secular theory of evil, i.e., a theory that does not make reference to supernatural or divine entities and which is not developed as a response to the problem of evil. Kant’s concern is to make sense of three apparently conflicting truths about human nature: (1) we are radically free, (2) we are by nature inclined toward goodness, (3) we are by nature inclined toward evil.\n","\n","Kant’s thoughts on evil and morality have had an important influence on subsequent philosophers writing about the nature of evil such as Hanna Arendt, Claudia Card, and Richard Bernstein. However, most theorists acknowledge that Kant’s theory is disappointing as a theory of evil in the narrow sense since it does not pick out only the morally worst sorts of actions and characters. (See, e.g., Card 2010, 37). Instead, Kant equates evil with having a will that is not fully good.\n","\n","According to Kant, we have a morally good will only if we choose to perform morally right actions because they are morally right (Kant 1785, 4: 393–4:397; Kant 1793, Bk I). On Kant’s view, anyone who does not have a morally good will has an evil will. There are three grades of evil which can be seen as increasingly more evil stages of corruption in the will. First there is frailty. A person with a frail will attempts to perform morally right actions because these actions are morally right, but she is too weak to follow through with her plans. Instead, she ends up doing wrong due to a weakness of will (Kant 1793, Bk I, 24–25).\n","\n","The next stage of corruption is impurity. A person with an impure will does not attempt to perform morally right actions just because these actions are morally right. Instead, she performs morally right actions partly because these actions are morally right and partly because of some other incentive, e.g., self-interest. Someone with an impure will performs morally right actions, but only partly for the right reason. Kant believes that this form of defect in the will is worse than frailty even though the frail person does wrong while the impure person does right. Impurity is worse than frailty because an impure person has allowed an incentive other than the moral law to guide her actions while the frail person tries, but fails, to do the right thing for the right reason (Kant 1793, Bk I, 25–26).\n","\n","The final stage of corruption is perversity, or wickedness. Someone with a perverse will inverts the proper order of the incentives. Instead of prioritizing the moral law over all other incentives, she prioritizes self-love over the moral law. Thus, her actions conform to the moral law only if they are in her self-interest. Someone with a perverse will need not do anything wrong because actions which best promote her self-interest may conform to the moral law. But since the reason she performs morally right actions is self-love and not because these actions are morally right, her actions have no moral worth and, according to Kant, her will manifests the worst form of evil possible for a human being. Kant considers someone with a perverse will an evil person (Kant 1793, Bk I, 25).\n","\n","For Kant, human beings always have either the moral law or self-love as their incentive for acting. Only a devil could do what is wrong just because it is wrong.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yiXYl4IE3BWT","colab_type":"text"},"source":["https://plato.stanford.edu/entries/ethics-belief/\n","(Clifford's Principle) “It is wrong always, everywhere, and for anyone to believe anything on insufficient evidence.”\n","(Clifford's Other Principle) “It is wrong always, everywhere, and for anyone to ignore evidence that is relevant to his beliefs, or to dismiss relevant evidence in a facile way.” (Van Inwagen 1996, 145)\n","\n","\n","He that believes without having any Reason for believing, may be in love with his own Fancies; but neither seeks Truth as he ought, nor pays the Obedience due to his Maker, who would have him use those discerning Faculties he has given him, to keep him out of Mistake and Errour. (1690, 687)\n","\n","Descartes maintains, we have the obligation to withhold assent from all propositions whose truth we do not clearly and distinctly perceive (clear and distinct perceptions themselves, by contrast, will produce belief ineluctably). In other contexts, it may be both permissible and prudent to form a mere “opinion” (opinio) whose truth we do not clearly and distinctly perceive. Even then, however, we are obliged to have some sort of evidence before giving our assent.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6N5Xbq1ef2k_","colab_type":"text"},"source":["https://plato.stanford.edu/entries/induction-problem/\n","https://plato.stanford.edu/entries/scientific-unity/\n","https://plato.stanford.edu/entries/logic-conditionals/\n","https://plato.stanford.edu/entries/neuroscience/\n","https://plato.stanford.edu/entries/consciousness-neuroscience/\n","https://plato.stanford.edu/entries/causation-metaphysics/\n","https://plato.stanford.edu/entries/consciousness-unity/\n","https://plato.stanford.edu/entries/perception-contents/\n","https://plato.stanford.edu/entries/problem-of-many/\n","https://plato.stanford.edu/entries/free-rider/\n","https://plato.stanford.edu/entries/frame-problem/\n","https://plato.stanford.edu/entries/nonidentity-problem/\n","https://plato.stanford.edu/entries/logic-action/\n","https://plato.stanford.edu/entries/knowledge-value/\n","https://plato.stanford.edu/entries/knowledge-analysis/\n","https://plato.stanford.edu/entries/modality-epistemology/\n","https://plato.stanford.edu/entries/paradox-suspense/\n","https://plato.stanford.edu/entries/art-ontology-history/\n","https://plato.stanford.edu/entries/music/\n","https://plato.stanford.edu/entries/dance/\n","https://plato.stanford.edu/entries/death-definition/\n","https://plato.stanford.edu/entries/life-meaning/\n","https://plato.stanford.edu/entries/axiom-choice/\n","https://plato.stanford.edu/entries/lawphil-nature/\n","https://plato.stanford.edu/entries/utilitarianism-history/\n","https://plato.stanford.edu/entries/truth-coherence/\n","https://plato.stanford.edu/entries/morality-definition/"]},{"cell_type":"markdown","metadata":{"id":"dzcdKkeG2-BV","colab_type":"text"},"source":["\n","https://plato.stanford.edu/entries/ethics-manipulation/\n","\n","manipulation, unlike coercion, does not interfere with a person’s options. Instead it perverts the way that person reaches decisions, forms preference, or adopts goals. (Raz 1988: 377)\n","\n","manipulation is directly influencing someone’s beliefs, desires, or emotions such that she falls short of ideals for belief, desire, or emotion in ways typically not in her self-interest or likely not in her self-interest in the present context. (Barnhill 2014: 73, emphasis original; for a similar view, see Hanna 2015)\n","\n","Buss’s argument has two parts. First, she claims that manipulation does not, in fact, deprive its victim of the ability to make choices; indeed, it typically presupposes that the target will make her own choice. But if the manipulation does not take away the target’s choice, Buss maintains, it does not undermine her autonomy. (For a similar argument, see Long 2014).\n","\n","Second, Buss argues that it is false to claim that an autonomous agent would rationally reject being subjected to manipulative influences. To support this claim, Buss argues that manipulation and deception are “pervasive forms of human interaction which are often quite benign and even valuable” (S. Buss 2005: 224). Her most notable example is the cultivation of romantic love, which often involves—and may even require—significant amounts of behavior that is aptly described as manipulation.\n"," \n","Even though false beliefs about how to achieve one’s ends may not compromise one’s authentic values or one’s powers of practical reasoning, they do seem to compromise one’s ability to achieve one’s autonomously-chosen ends, and it is plausible to regard this as a diminishment of (some form of) autonomy. \n","\n","As Claudia Mills puts it,\n","a manipulator is interested in reasons not as logical justifiers but as causal levers. For the manipulator, reasons are tools, and bad reasons can work as well as, or better than, a good one. (Mills 1995: 100–101)\n","The point here is that a manipulator treats his target not as a fellow rational agent, for that would require giving good reasons for doing as the manipulator proposes. Instead, the manipulator treats his target as a being whose behavior is to be elicited by pressing the most effective “causal levers”.\n","\n","Of course, the idea that treating a person as a mere object is immoral is a prominent feature of Kant’s account of respect for persons (see entry on respect). Thus, it would be natural to appeal to Kantian ideas to help elaborate the idea that manipulation is wrong because of the way that it treats its target. Thus, for example, Thomas E. Hill writes,\n","The idea that one should try to reason with others rather than to manipulate them by nonrational techniques is manifest in Kant's discussion of the duty to respect others. (Hill 1980: 96)\n","\n","Kant’s notion of rational agency appears to be of the hyper-cognitive, hyper-intellectual variety. Hence, if it is unethical to fail to treat someone as that kind of rational agent, we might be pushed toward the conclusion that the only acceptable basis for human interaction is the kind of coldly intellectual rational persuasion that excludes any appeal to emotions. But as we saw earlier, there are good reasons for regarding such a conclusion as implausible.\n","\n","3.5 Other Suggestions\n","Although harm, autonomy, and treating persons as things are the most prominent suggestions about what makes manipulation wrong when it is wrong, one can find other suggestions in the literature. For example, Marcia Baron’s virtue-theoretic account of manipulativeness suggests that we might account for what is wrong about manipulation in terms of the character of the manipulator (Baron 2003). Patricia Greenspan suggests that when manipulation is immoral, it is because it violates the terms of the relationship between the manipulator and his target—terms that will vary according to the nature of the relationship between them (Greenspan 2003). Such a view suggests—plausibly—that the moral status of a given instance of manipulation will depend at least in part on the nature of the relationship between the influencer and the target of the influence.\n","\n","However, it may also be true that manipulation is a tempting tool for use by the vulnerable against the powerful. As Patricia Greenspan notes,\n","\n","manipulation is often recommended as a strategy particularly for women, or simply is treated as characteristic of women, at least in a world where women cannot act openly to achieve their ends. A further argument for manipulation in these cases appeal to the limits on what is possible in a position of subordination. (Greenspan 2003: 156)\n","\n","Similarly, Len Bowers observes that \"it is possible to interpret manipulation as a normal response to incarceration, rather than as being a pathological style of behavior\", and that \"manipulative strategies may be viewed as a low-key way of fighting back at a system which has deprived the prisoner of normal freedom.\" (Bowers 2003: 330) Finally, it seems likely that one reason why children often resort to manipulative tactics is that they often lack any other (or any other equally effective) way to get what they want.\n","\n","Even if we accept that manipulation undermines autonomous choice, we must be careful not to use that as a reason to suspect that people who make different choices from what we think are best must therefore be victims of manipulation. It would be ironic—and unjust—to use the idea that manipulation is a wrongful interference with autonomy as a weapon to delegitimize the autonomous choices of people with whom we disagree or whose situations, needs, and values we do not understand."]},{"cell_type":"code","metadata":{"id":"pEQPLg3TzvVA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6CZ-geizvSK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hX7rEvBzvLS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_LeXb5XzvI7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cc646bJnzvGi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uL8OoY5VjE8p","colab_type":"text"},"source":["The study of computability theory dates back to the early 20th century, before the first electronic computers were developed. The theory in part addresses the question of which problems are solvable by an algorithm. On the other hand, the modern theory of algorithms limits attention to the solvable problems, and investigates the design (or lack there of) of efficient algorithms for solving these problems. As we’ll see in this lecture, not all problems can be solved by means of an algorithm. Perhaps the most famous of these probems is the Halting problem, which is discussed below.\n"]},{"cell_type":"markdown","metadata":{"id":"0PtlY-96jGr4","colab_type":"text"},"source":["Formally, a partial order is any binary relation that is reflexive (each element is comparable to itself), antisymmetric (no two different elements precede each other), and transitive (the start of a chain of precedence relations must precede the end of the chain)"]},{"cell_type":"markdown","metadata":{"id":"SUvL4IeWibF0","colab_type":"text"},"source":["https://en.wikipedia.org/wiki/Decision_problem\n"," a decision problem is a problem that can be posed as a yes-no question of the input values.\n","The answer is either 'yes' or 'no' depending upon the values of x and y. A method for solving a decision problem, given in the form of an algorithm, is called a decision procedure for that problem.\n","A decision problem which can be solved by an algorithm is called decidable.\n","\n","Decision problems typically appear in mathematical questions of decidability, that is, the question of the existence of an effective method to determine the existence of some object or its membership in a set; some of the most important problems in mathematics are undecidable.\n","\n","The field of computational complexity categorizes decidable decision problems by how difficult they are to solve. \"Difficult\", in this sense, is described in terms of the computational resources needed by the most efficient algorithm for a certain problem. The field of recursion theory, meanwhile, categorizes undecidable decision problems by Turing degree, which is a measure of the noncomputability inherent in any solution.\n","\n","The importance of Gödel numbering is that you can prove the rules of string manipulation can be expressed arithmetically, so that integer arithmetic is just as powerful\n"]},{"cell_type":"code","metadata":{"id":"UPtIIlqOZShk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipqNM-q5eBFA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Qno1HWqeBOY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EiE3SjzleBVe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbtNeWDUeBSm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ShxAGaAMlF6v","colab_type":"text"},"source":["One of the most important open problems in theoretical computer science is the **P vs. NP problem**, which concerns the question of **how difficult it is to simulate non-deterministic computation with a deterministic computer**. It asks whether every problem whose solution can be quickly verified (technically, verified in polynomial time) can also be solved quickly (again, in polynomial time). The informal term quickly, used above, means the existence of an algorithm solving the task that runs in polynomial time, such that the time to complete the task varies as a polynomial function on the size of the input to the algorithm (as opposed to, say, exponential time). **The general class of questions for which some algorithm can provide an answer in polynomial time is called \"class P\"** or just \"P\". For some questions, there is no known way to find an answer quickly, but if one is provided with information showing what the answer is, it is possible to verify the answer quickly. **The class of questions for which an answer can be verified in polynomial time is called (NP) \"nondeterministic polynomial time\"**\n","\n","In computational complexity theory, **a problem is NP-complete when it can be solved by a restricted class of brute force search algorithms** and it can be used to simulate any other problem with a similar algorithm. More precisely, each input to the problem should be associated with a set of solutions of polynomial length, whose validity can be tested quickly (in polynomial time), such that the output for any input is \"yes\" if the solution set is non-empty and \"no\" if it is empty. The complexity class of problems of this form is called NP, an abbreviation for \"nondeterministic polynomial time\". (NP)\n","\n","An answer to the P = NP question would determine whether problems that can be verified in polynomial time can also be solved in polynomial time. If it turned out that P ≠ NP, it would mean that there are problems in NP that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time. To attack the P = NP question, the concept of NP-completeness is very useful. **NP-complete problems are a set of problems to each of which any other NP-problem can be reduced in polynomial time and whose solution may still be verified in polynomial time**. That is, any NP problem can be transformed into any of the NP-complete problems. If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems have been shown to be NP-complete, and no fast algorithm for any of them is known.\n","\n","In computer science, the **Boolean satisfiability problem** is the problem of determining if there exists an interpretation that satisfies a given Boolean formula. In other words, it **asks whether the variables of a given Boolean formula can be consistently replaced by the values TRUE or FALSE in such a way that the formula evaluates to TRUE**. If this is the case, the formula is called satisfiable. On the other hand, if no such assignment exists, the function expressed by the formula is FALSE for all possible variable assignments and the formula is unsatisfiable. For example, the formula \"a AND NOT b\" is satisfiable because one can find the values a = TRUE and b = FALSE, which make = TRUE. In contrast, \"a AND NOT a\" is unsatisfiable.\n","\n","In computational complexity theory, the Cook–Levin theorem, also known as Cook's theorem, states that the **Boolean satisfiability problem is NP-complete**. That is, any problem in NP can be reduced in polynomial time by a deterministic Turing machine to the problem of determining whether a Boolean formula is satisfiable. So any instance of any problem in NP can be transformed mechanically into an instance of the Boolean satisfiability problem in polynomial time.\n","\n","An important consequence of this theorem is that if there exists a deterministic polynomial time algorithm for solving Boolean satisfiability, then every NP problem can be solved by a deterministic polynomial time algorithm. The question of whether such an algorithm for **Boolean satisfiability exists is thus equivalent to the P versus NP problem**, which is widely considered the most important unsolved problem in theoretical computer science.\n","\n","In essence, a Turing machine is imagined to be a simple computer that reads and writes symbols one at a time on an endless tape by strictly following a set of rules. It determines what action it should perform next according to its internal state and what symbol it currently sees\n","\n","NP-complete problems are in NP, the set of all decision problems whose solutions can be verified in polynomial time; \n","\n","NP may be equivalently defined as the set of decision problems that can be solved in polynomial time on a non-deterministic Turing machine\n","\n","in a **non-deterministic Turing machine (NTM)**, the set of rules may prescribe more than one action to be performed for any given situation\n","\n","In a **deterministic Turing machine (DTM)**, the set of rules prescribes at most one action to be performed for any given situation.\n","\n","NP-complete problems are often addressed by using heuristic methods and approximation algorithms.\n","\n","It is not known whether every problem in NP can be quickly solved—this is called the P versus NP problem. But if any NP-complete problem can be solved quickly, then every problem in NP can, because the definition of an NP-complete problem states that every problem in NP must be quickly reducible to every NP-complete problem (that is, it can be reduced in polynomial time). Because of this, it is often said that NP-complete problems are harder or more difficult than NP problems in general.\n","\n","__IE, in polynomial time non deterministic functions can have their satisfiability assessed __\n"]},{"cell_type":"markdown","metadata":{"id":"2cw3AugUvL8s","colab_type":"text"},"source":["The easiest way to prove that some new problem is NP-complete is first to prove that it is in NP, and then to reduce some known NP-complete problem to it. Therefore, it is useful to know a variety of NP-complete problems. The list below contains some well-known problems that are NP-complete when expressed as decision problems.\n","\n","Boolean satisfiability problem (SAT)\n","Knapsack problem\n","Hamiltonian path problem\n","Travelling salesman problem (decision version)\n","Subgraph isomorphism problem\n","Subset sum problem\n","Clique problem\n","Vertex cover problem\n","Independent set problem\n","Dominating set problem\n","Graph coloring problem\n","\n","There is often only a small difference between a problem in P and an NP-complete problem. For example, the 3-satisfiability problem, a restriction of the boolean satisfiability problem, remains NP-complete, whereas the slightly more restricted 2-satisfiability problem is in P (specifically, NL-complete), and the slightly more general max. 2-sat. problem is again NP-complete. Determining whether a graph can be colored with 2 colors is in P, but with 3 colors is NP-complete, even when restricted to planar graphs. Determining if a graph is a cycle or is bipartite is very easy (in L), but finding a maximum bipartite or a maximum cycle subgraph is NP-complete. A solution of the knapsack problem within any fixed percentage of the optimal solution can be computed in polynomial time, but finding the optimal solution is NP-complete.\n","\n","At present, all known algorithms for NP-complete problems require time that is superpolynomial in the input size, and it is unknown whether there are any faster algorithms.\n","\n","The following techniques can be applied to solve computational problems in general, and they often give rise to substantially faster algorithms:\n","\n","- Approximation: Instead of searching for an optimal solution, search for a solution that is at most a factor from an optimal one.\n","- Randomization: Use randomness to get a faster average running time, and allow the algorithm to fail with some small probability. Note: The Monte Carlo method -is not an example of an efficient algorithm in this specific sense, although evolutionary approaches like Genetic algorithms may be.\n","- Restriction: By restricting the structure of the input (e.g., to planar graphs), faster algorithms are usually possible.\n","- Parameterization: Often there are fast algorithms if certain parameters of the input are fixed.\n","- Heuristic: An algorithm that works \"reasonably well\" in many cases, but for which there is no proof that it is both always fast and always produces a good result. Metaheuristic approaches are often used.\n","\n","In graph theory, a planar graph is a graph that can be embedded in the plane, i.e., it can be drawn on the plane in such a way that its edges intersect only at their endpoints. In other words, it can be drawn in such a way that no edges cross each other."]},{"cell_type":"code","metadata":{"id":"s1AqBo9ueNi9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YF-_V8dWeNq1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8f8jDqOeNvH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gY0iAsw3xfuE","colab_type":"text"},"source":["In computer science and mathematical optimization, a metaheuristic is a higher-level procedure or heuristic designed to find, generate, or select a heuristic (partial search algorithm) that may provide a sufficiently good solution to an optimization problem, especially with incomplete or imperfect information or limited computation capacity.[1][2] Metaheuristics sample a set of solutions which is too large to be completely sampled. Metaheuristics may make few assumptions about the optimization problem being solved, and so they may be usable for a variety of problems.[3]\n","\n","Compared to optimization algorithms and iterative methods, metaheuristics do not guarantee that a globally optimal solution can be found on some class of problems.\n","\n","Most literature on metaheuristics is experimental in nature, describing empirical results based on computer experiments with the algorithms. But some formal theoretical results are also available, often on convergence and the possibility of finding the global optimum.[3] Many metaheuristic methods have been published with claims of novelty and practical efficacy.\n","\n","The founders of this subject are Leonid Kantorovich, a Russian mathematician who developed linear programming problems in 1939, Dantzig, who published the simplex method in 1947, and John von Neumann, who developed the theory of the duality in the same year.\n","\n","Convex optimization is a subfield of mathematical optimization that studies the problem of minimizing convex functions over convex sets. Many classes of convex optimization problems admit polynomial-time algorithms,[1] whereas mathematical optimization is in general NP-hard.[2][3][4]\n","\n"," the knapsack problem was the 19th most popular and the third most needed after suffix trees and the bin packing problem.[3]\n"," \n"," In computer science, a suffix tree (also called PAT tree or, in an earlier form, position tree) is a compressed trie containing all the suffixes of the given text as their keys and positions in the text as their values. Suffix trees allow particularly fast implementations of many important string operations.\n"," \n","A problem that can be solved in theory (e.g. given large but finite resources, especially time), but for which in practice any solution takes too many resources to be useful, is known as an intractable problem.[14] Conversely, a problem that can be solved in practice is called a tractable problem, literally \"a problem that can be handled\". The term infeasible (literally \"cannot be done\") is sometimes used interchangeably with intractable,[15] though this risks confusion with a feasible solution in mathematical optimization.\n"," \n","In computer science, artificial intelligence, and mathematical optimization, a heuristic (from Greek εὑρίσκω \"I find, discover\") is a technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail to find any exact solution. This is achieved by trading optimality, completeness, accuracy, or precision for speed. In a way, it can be considered a shortcut.\n","\n","A heuristic function, also called simply a heuristic, is a function that ranks alternatives in search algorithms at each branching step based on available information to decide which branch to follow. For example, it may approximate the exact solution.[1]\n","\n","The trade-off criteria for deciding whether to use a heuristic for solving a given problem include the following:\n","\n","- Optimality: When several solutions exist for a given problem, does the heuristic guarantee that the best solution will be found? Is it actually necessary to find the best solution?\n","- Completeness: When several solutions exist for a given problem, can the heuristic find them all? Do we actually need all solutions? Many heuristics are only meant to find one solution.\n","- Accuracy and precision: Can the heuristic provide a confidence interval for the purported solution? Is the error bar on the solution unreasonably large?\n","- Execution time: Is this the best known heuristic for solving this type of problem? Some heuristics converge faster than others. Some heuristics are only marginally quicker than classic methods.\n","\n","The greedy algorithm heuristic says to pick whatever is currently the best next step regardless of whether that prevents (or even makes impossible) good steps later. It is a heuristic in that practice says it is a good enough solution, theory says there are better solutions (and even can tell how much better in some cases).[3]\n","\n","Some heuristics have a strong underlying theory; they are either derived in a top-down manner from the theory or are arrived at based on either experimental or real world data. Others are just rules of thumb based on real-world observation or experience without even a glimpse of theory. The latter are exposed to a larger number of pitfalls.\n","\n"," Local search algorithms move from solution to solution in the space of candidate solutions (the search space) by applying local changes, until a solution deemed optimal is found or a time bound is elapsed.\n"," \n","hill climbing is a mathematical optimization technique which belongs to the family of local search. It is an iterative algorithm that starts with an arbitrary solution to a problem, then attempts to find a better solution by making an incremental change to the solution. If the change produces a better solution, another incremental change is made to the new solution, and so on until no further improvements can be found.\n","\n"," I will outline a list published in an article by Peter Voss in October 2016, outlining a more comprehensive list on the limitations of AI. Whilst current mainstream techniques can be very powerful in narrow domains, they will typically have some or all of a list of constraints that he sets out and which I’ll quote in full here:\n","- Each narrow application needs to be specially trained\n","- Require large amounts of hand-crafted, structured training data\n","- Learning must generally be supervised: Training data must be tagged\n","- Require lengthy offline/ batch training\n","- Do not learn incrementally or interactively, in real-time\n","- Poor transfer learning ability, reusability of modules, and integration\n","- Systems are opaque, making them very hard to debug\n","- Performance cannot be audited or guaranteed at the ‘long tail’\n","- They encode correlation, not causation or ontological relationships\n","- Do not encode entities or spatial relationships between entities\n","- Only handle very narrow aspects of natural language\n","- Not well suited for high-level, symbolic reasoning or planning\n","\n","https://towardsdatascience.com/lessons-from-how-to-lie-with-statistics-57060c0d2f19"]},{"cell_type":"code","metadata":{"id":"CaftLt_reKob","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SjSM6Rxs9VM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vA6UTVvBMUbl","colab_type":"text"},"source":["the different aspects of an algorithm that require analysis.\n","\n","- Correctness It must be established that the algorithm performs as advertised. In other words, for each legal input, called a problem instance, the algorithm produces the desired output.\n","- Complexity Bounds must be provided on either the amount of time required to execute the algorithm, or the amount of space (e.g., memory) that is consumed by the algorithm as a function of the size of an input instance.\n","- Implementation Appropriate data structures must be identified that allow for the algorithm to achieve a desired time or space complexity.\n","\n","The correctness of an algorithm is sometimes immediate from its description, while the correctness\n","of others may require clever mathematical proofs\n","\n","A Greedy algorithm is characterized by the following two properties:\n","\n","1. the algorithm works in stages, and during each stage a choice is made which is locally optimal;\n","2. the sum totality of all the locally optimal choices produces a globally optimal solution."]},{"cell_type":"markdown","metadata":{"id":"Kf1W1MyQMoNf","colab_type":"text"},"source":["Note that if a greedy procedure does not always lead to a globally optimal solution, then we will refer\n","to it as a heuristic, or a greedy heuristic. Heuristics often provide a “short cut” to a solution,\n","but not necessarily to an optimal solution. Hencefore, we will use the term “algorithm” for a method\n","that always produces a correct/optimal solution, and “heuristic” to describe a procedure that may\n","not always produce the correct or optimal solution.\n","The following are some problems that that can be solved using a greedy algorithm. Their algorithms\n","can be found in this lecture, and in the exercises.\n","Minimum Spanning Tree finding a spanning tree for a graph whose weight edges sum to a minimum value\n","Fractional Knapsack selecting a subset of items to load in a container in order to maximize profit\n","Task Selection finding a maximum set of non-overlapping tasks (each with a fixed start and finish\n","time) that can be completed by a single processor\n","Huffman Coding finding a code for a set of items that minimizes the expected code-length\n","\n","Linear programming represents a general approach to solving constraint optimization problems. Such problems involve optimizing (i.e. maximizing or minimizing) an objective function f\n","that is defined over a set of variables whose values must satisfy a set of constraints. Linear programming models such problems by assuming that the objective function is linear, and that the variable\n","constraints are linear inequalities.\n","Linear-programming is often used to model and solve resource allocation problems."]},{"cell_type":"markdown","metadata":{"id":"pzlVSJDAUDUf","colab_type":"text"},"source":["https://en.wikipedia.org/wiki/Effective_method\n","\n","an effective method[1] or effective procedure is a procedure for solving a problem from a specific class. An effective method is sometimes also called a mechanical method or procedure.\n","\n","A method is formally called effective for a class of problems when it satisfies these criteria:\n","\n","- It consists of a finite number of exact, finite instructions.\n","- When it is applied to a problem from its class:\n","- It always finishes (terminates) after a finite number of steps.\n","- It always produces a correct answer.\n","- In principle, it can be done by a human without any aids except writing materials.\n","- Its instructions need only to be followed rigorously to succeed. In other words, it requires no ingenuity to succeed.[3]"]},{"cell_type":"markdown","metadata":{"id":"yy0wz3FFVg5k","colab_type":"text"},"source":["In algorithmic information theory (a subfield of computer science and mathematics), the Kolmogorov complexity of an object, such as a piece of text, is the length of the shortest computer program (in a predetermined programming language) that produces the object as output. It is a measure of the computational resources needed to specify the object, and is also known as algorithmic complexity, Solomonoff-Kolmogorov–Chaitin complexity, program-size complexity, descriptive complexity, or algorithmic entropy. It is named after Andrey Kolmogorov, who first published on the subject in 1963.[1][2]\n","\n","The notion of Kolmogorov complexity can be used to state and prove impossibility results akin to Cantor's diagonal argument, Gödel's incompleteness theorem, and Turing's halting problem. In particular, for almost all objects, it is not possible to compute even a lower bound for its Kolmogorov complexity (Chaitin 1964), let alone its exact value."]},{"cell_type":"markdown","metadata":{"id":"1Wnlq479MUOm","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"N9UNNlQ8jt11","colab_type":"text"},"source":["http://web.csulb.edu/~tebert/teaching/lectures/528/turing/turing.pdf\n","Sets of words over a finite alphabet play a central role in the theory of computation. The following is a brief outline of the language-machine paradigm of computation.\n","\n","1. Decision Problems. Every computational problem of interest can be framed in terms of some decision problem in which the answer to the problem is either “yes” or “no”.\n","\n","2. Languages. To further simplify the computational landscape, given a decision problem P, every instance of P can be encoded as a unique word over some finite alphabet Σ, and thus we may think of P as a language over Σ\n","\n","3. Machines. By a machine it is meant some computational device that has the ability\n","to take as input words over some alphabet, and define a computational process that\n","either leads to the word being accepted or rejected. Machines tend to be defined for\n","the purpose of solving some decision problem and thus we may think of the set of\n","words accepted by the machine as being those problem-instance encodings for which\n","the problem decision is “yes”. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"KFzjvoqWh-lS","colab_type":"text"},"source":["http://web.csulb.edu/~tebert/teaching/lectures/528/turing/turing.pdf\n","\n","Entropy as a Measure of Information Content\n","\n","Example 1. calculate the amount of information contained in a weather forecast if the possibilities include\n","{normal, rain, fog, hot, windy} if there respective probabilities are .8, .10, .04, .03, and .03.\n","Example 2. Calculate the entropy of the probability distribution (1/2, 1/4, 1/8, 1/16, 1/16).\n","Example 3. Verify that independently tossing a fair coin n times imparts n bits of information\n","Suppose now the instructor notices that, for all questions, the correct\n","answer was marked 67% of the time, while the second-best response was 20%, third best 10%, and\n","worst 3%. On average, how much information can be found in the average exam?\n","\n","Claude Shannon (1912-2001). Pioneer in\n","• applying Boolean logic to electronic circuit design\n","• studying the complexity of Boolean circuits\n","• signal processing: determined lower bounds on the amount of samples needed to achieve a desired\n","estimation accuracy\n","• game theory: inventor of minimax algorithm\n","• information theory: first to give a precise definition for the concept of information\n","• coding theory: Channel Coding Theorem, Optimal Coding Theorem\n","\n"," to minimize the size of the file it follows that we must find an encoding φ for which\n","Lφ is minimized. We call such encodings length-optimal, or, in the case of files, size-optimal.\n","\n","Huffman’s Algorithm provide a greedy algorithm due to D.A. Huffman (1952) which will always find an encoding having\n","minimum average length."]},{"cell_type":"markdown","metadata":{"id":"UKohFzVNvMg5","colab_type":"text"},"source":["Employing a diagonal argument, Gödel's incompleteness theorems were the first of several closely related theorems on the limitations of formal systems. They were followed by Tarski's undefinability theorem on the formal undefinability of truth, Church's proof that Hilbert's Entscheidungsproblem is unsolvable, and Turing's theorem that there is no algorithm to solve the halting problem.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NXiIsuJRugOc","colab_type":"text"},"source":["Most modern CPUs are so fast that for most program workloads, the bottleneck is the locality of reference of memory accesses and the efficiency of the caching and memory transfer between different levels of the hierarchy[citation needed]. As a result, the CPU spends much of its time idling, waiting for memory I/O to complete. This is sometimes called the space cost, as a larger memory object is more likely to overflow a small/fast level and require use of a larger/slower level. The resulting load on memory use is known as pressure (respectively register pressure, cache pressure, and (main) memory pressure). "]},{"cell_type":"markdown","metadata":{"id":"KaX03o9fHn6-","colab_type":"text"},"source":["Central Limit Theorem Properties: the samplind distribution of the mean will be less than the sampling distribution of the population from which it is drawn\n","the sampling distribution will be well modeled by a normal distribution\n","the spread of the sample is related to the spread of the pop\n","bigger samples lead to smaller spread to sample distribution\n","\n"]},{"cell_type":"code","metadata":{"id":"r8R3T63TKfPE","colab_type":"code","colab":{}},"source":["github python real time stock"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5x1IPC4duhJJ","colab_type":"text"},"source":["Modern programming languages mainly assume two levels of memory, main memory and disk storage, though in assembly language and inline assemblers in languages such as C, registers can be directly accessed. Taking optimal advantage of the memory hierarchy requires the cooperation of programmers, hardware, and compilers (as well as underlying support from the operating system):\n","\n","Programmers are responsible for moving data between disk and memory through file I/O.\n","Hardware is responsible for moving data between memory and caches.\n","Optimizing compilers are responsible for generating code that, when executed, will cause the hardware to use caches and registers efficiently."]},{"cell_type":"markdown","metadata":{"id":"bjyvjw4jvNXT","colab_type":"text"},"source":["Registers usually consist of a small amount of fast storage, although some registers have specific hardware functions\n","\n","Registers are normally measured by the number of bits they can hold, for example, an \"8-bit register\", \"32-bit register\" or a \"64-bit register\" or even more. In some instruction sets, the registers can operate in various modes breaking down its storage memory into smaller ones (32-bit into four 8-bit one for instance) to which multiple data (vector, or one dimensional array of data) can be loaded and operated upon at the same time. Typically it is implemented by adding extra registers that map their memory into bigger one. Processors that have the ability to execute single instruction on multiple data are called vector processors."]}]}