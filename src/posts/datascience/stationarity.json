{"meta":{"title":"Stationarity","summary":"Assorted notes on the topic. Near entirly quotes from other sources.","tab":"Stationarity","keywords":"['data']","hide_sitemap":"false","hide_toc":"true","hide_breadcrumbs":"false","filename":"stationarity"},"content":" <p><a href=\"https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322</a>\t\t\t\t\n     Stationarity in time series analysis (stochastic processes)</p><br>\n<pre class='prettyprint'> In the most intuitive sense, stationarity means that the statistical properties of a process generating a time series do not change over time.\t\t\t\n t does not mean that the series does not change over time, just that the way it changes does not itself change over time.\t\t\t\n he value of a linear function changes as ùíô grows, but the way it changes remains constant\t\t\t\n ‚Äî it has a constant slope; one value that captures that rate of change.\t\t\t\n             \n Why is this important?\t\t\t\n     stationary processes are a sub-class of a wider family of possible models of reality\t\t\n     his sub-class is much easier to model and investigate.\t\t\n     common assumption for\t\t\n         trend estimation\t\n         forecasting\t\n         causal inference\t\n         other\t\n A formal definition for stochastic processes\t\t\t\n Stochastic Processes\t\t\tconsider the observed time series as part of a realization of a stochastic proces\n Definitions of stationarity\t\t\t\n     statistical properties of the process do not change over time\t\t\n     several different notions of stationarity have been suggested in econometric literature over the years\t\t\n     stationarity ‚Äî of any kind ‚Äî is a property of a stochastic process\t\t\n     Strong stationarity\t\t\n         This is the most common definition of stationarity, and it is commonly referred to simply as stationarity\t\n         t is sometimes also referred to as strict-sense stationarity or strong-sense stationarity.\t\n         a variables distribution in a sub-sequence within the stochastic process will be shift invarient. \t\n         i.e. a variables distribution requires shift invariance\t\n     Weak stationarity\t\t\n         This means the process has the same mean at all time points, and that the covariance between the values at any two time points depend only on the difference between the two times, and not on the location of the points along the time axis.\t\n         Can have, stationary mean or stationary variance. if it has both it is strong, if it has neither it is neither\t\n     N-th order stationarity\t\t\n         demands the shift-invariance (in time) of the distribution of any n samples of the stochastic process\t\n     First-order stationarity\t\t\n         The term first-order stationarity is sometimes used to describe a series that has means that never changes with time\t\n         but for which any other moment (like variance) can change.[Boshnakov, 2011]\t\n     Cyclostationarity\t\t\n         if the joint distribution of any set of samples is invariant over a time shift of mP\t\n     Trend stationarity\t\t\n         if an underlying trend (function solely of time) can be removed, leaving a stationary process\t\n     Joint stationarity\t\t\n         Intuitive extensions exist of all of the above types of stationarity for pairs of stochastic processes.\t\n     Locally stationary stochastic processes\t\t\n         An important class of non-stationary processes are locally stationary (LS) processes\t\n         their statistical properties change slowly over time.\t\n         gradually changing in an unspecific way as time evolves\t\n         LS processes are of importance because they somewhat bridge the gap between\t\n             the thoroughly explored sub-class of parametric non-stationary processes (see the following section)\n             and the uncharted waters of the wider family of non-parametric processes\n     Parametric notions of non-stationarity\t\t\n         The definitions of stationarity presented so far have been non-parametric;\t\n         and thus apply to any stochastic process\t\n         WIKI: Parametric tests assume underlying statistical distributions in the data.\t\n         WIKI: Stochastic: randomly determined; having a random probability distribution or pattern that may be analyzed statistically but may not be predicted precisely.\t\n             \n             \n</pre>\n<p> <a href=\"https://towardsdatascience.com/detecting-stationarity-in-time-series-data-d29e0a21e638\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://towardsdatascience.com/detecting-stationarity-in-time-series-data-d29e0a21e638</a>\t\t\t\t\n     Detecting stationarity in time series data\t\t\t\n         Looking at Autocorrelation Function (ACF) plots\t\t\n             Autocorrelation is the correlation of a signal with a delayed copy ‚Äî or a lag ‚Äî of itself as a function of the delay.\t\n             When plotting the value of the ACF for increasing lags (a plot called a correlogram), the values tend to degrade to zero quickly for stationary time series (see figure 1, right), while for non-stationary data the degradation will happen more slowly (see figure 1, left).\t\n             Alternatively, [Nielsen, 2006] suggests that plotting correlograms based on both autocorrelations and scaled autocovariances, and comparing them,\t\n         Parametric tests\t\t\n             more rigorous approac using statistical tests developed to detect specific types of stationarity,\t\n             Unit root tests\t</p>\n<pre class='prettyprint'>         The Dickey-Fuller Test\t\n         The Dickey-Fuller test was the first statistical test developed to test the null hypothesis that a unit root is present in an autoregressive model of a given time series\t\n         The KPSS Test\t\n         Another prominent test for the presence of a unit root is the KPSS test. [Kwiatkowski et al, 1992] Conversely to the Dickey-Fuller family of tests, the null hypothesis assumes stationarity around a mean or a linear trend, while the alternative is the presence of a unit root.\t\n         The Zivot and Andrews Test\t\n         The aforementioned tests do not allow for the possibility of a structural break\t\n         ‚Äî an abrupt change involving a change in the mean or other parameters of the process.\t\n         the power to reject a unit root decreases when the stationary alternative is true and a structural break is ignored.\t\n         [Zivot and Andrews, 1992] propose a unit root test in which they assume that the exact time of the break-point is unknown\t\n         Semi-parametric unit root tests\t\n         Variance Ratio Test\t\n         [Breitung, 2002] suggested a non-parametric test for the presence of a unit root based on a variance ratio statistic.\t\n     Non-parametric tests\t\t\n         limitations of parametric tests\t\n         recognition they cover only a narrow sub-class of possible cases encountered in real data\t\n         no longer have to assume very simple parametric models happen to apply to your data to find out whether it is stationary or not\t\n         A Nonparametric Test for Stationarity in Continuous-Time Markov Processes\t\n         A nonparametric test for stationarity in functional time series\t\n         A nonparametric test for stationarity based on local Fourier analysis\t\n             \n</pre>\n<p> <a href=\"https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://towardsdatascience.com/inferring-causality-in-time-series-data-b8b75fe52c46</a>\t\t\t\t\n     Background: Notions of causality in time series data\t\t\t\n         Granger causality‚Å∏</p><br>\n\n  <script src=\"https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}