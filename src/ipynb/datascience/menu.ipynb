{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"colab":{"name":"menu.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"jRQlmM2udAAo"},"source":["Thesis Data Explorer UI\n","\n"]},{"cell_type":"markdown","metadata":{"id":"x4q99OfsdAAr"},"source":["# Outline\n","\n","0) ACS Download and Explore\n","1) Import Tool- Geoson used early requires GeoImports\n","2) Merge Tool\n","3) GIS Imports and Transforms - Geocoding, Filter, Pinp, Centroid, CSVGeoJ, Etc\n","4) Visualizationas - Transsformations, GifMap\n","5) Exploration\n"]},{"cell_type":"markdown","metadata":{"id":"7J3ohy53dAAr"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"fK_fkfn0dAAs"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"BCYn3988dAAs"},"source":["What would you like to do today?\n","\n","Is this correct? \n","Describe\n","Edit\n","\n","\n","__Settup Env__\n","- Import Dataset\n","- Display Col Names\n","- Parse Dtypes\n","- Show Sample Records\n","- Shape, Dtypes\n","\n","__Main Menu__\n","- ImportMenu() => import, replace, merge, join, settings\n","- - Settings() => Nulls, missing, incorrect, duplicates, fuzzy match\n","- DescribeMenu() => FOL, AGG, OPS, Settings\n","- CompareMenu() => Settings\n","- LearnMenu() => StatisticalTesting -> Uni Multi Predict\n","- Exit()\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cP-7ZtlVdAAs"},"source":["__inferTypes__ \n","( string->date/ percent/ currency/ temp/ txt )\n","( Int - Float Ratio | Coords - point geom line )\n","\n","For col in cols{\n","  bin?\n","  rollingWindow?\n","  if (colname or top 10 rows )include ['$', '%', 'indx', '[', '{' ]\n","  inspect for ( viztypes, map/ boxplot / hist/ density/ numline)"]},{"cell_type":"markdown","metadata":{"id":"1ycDtWrHdAAt"},"source":["__Config__\n","- DatasetFileName - CSV GeoJson\n","- GeomFilename - GeoJson\n","DS/GeomInfo: { Merge Info:{}, Assumptions:{} }\n","Visualizations: {}\n","Operations: {Viz-Display, Cli/Server, LoadData}\n","\n","Dataset (Source, age, spatial, feed/stream/ continuous/ dbsize/ samplesize\n","records ( # cols, date-time, coords)\n","column (type value title and tags)\n"]},{"cell_type":"code","metadata":{"id":"HrCNUWjfdAAt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RJZUwbL3dAAu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9DyisS-adAAu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g2tVamU1dAAv"},"source":["Analysis | UI -> From Terminal Browswer Python\n","\n","Jupyter -> ( Php, Python, JS or c++ )\n","\n","C++ -> Cyber Phys\n","\n","Php Python JS -> Dev and Website"]},{"cell_type":"code","metadata":{"id":"ND6VNXW8dAAv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9b1Vj-2jdAAw"},"source":["# Intro"]},{"cell_type":"markdown","metadata":{"id":"QCJ6viT3dAAx"},"source":["- Intro\n","- - Diagrams\n","- - Setup\n","- acs download and explore\n","- import tool\n","- - gis import\n","- merge tool\n","- gis transform\n","- visualizations\n","- exploration\n"]},{"cell_type":"markdown","metadata":{"id":"miyKSEzPdAAx"},"source":["## Diagrams"]},{"cell_type":"code","metadata":{"id":"6mjVX23tdAAx","outputId":"356a4933-780f-4775-894d-37ebfc034a7c"},"source":["#@title Run This Cell: createIndicator() Diagram\n","%%html\n","<script src=\"https://code.jquery.com/jquery-1.10.2.js\"></script>\n","<script src=\"https://unpkg.com/mermaid@7.1.0/dist/mermaid.min.js\"> </script>\n","<script> window.mermaid.init() </script>\n","\n","<h1> createIndicator() Variables and Methods </h1>\n","<div class=\"mermaid\" style='width:400px'>\n","  classDiagram\n","    MergeDatasets --* MergeDatasets\n","  \n","    MergeDatasets : main()\n","    MergeDatasets : checkColumns()\n","    MergeDatasets : coerceDtypes()\n","    MergeDatasets : mergeOrPull()\n","    MergeDatasets : filterEmpties()\n","    MergeDatasets : saveCrosswalk()\n","    MergeDatasets : getMergeParams()\n","  \n","    MergeDatasets : df/text df\n","    MergeDatasets : df/text cw\n","    MergeDatasets : col left_on\n","    MergeDatasets : col right_on\n","    MergeDatasets : col/text how\n","    MergeDatasets : bool save\n","    MergeDatasets : text name\n","</div>\n","\n","<div class=\"mermaid\" style='width:400px'>\n","  classDiagram\n","    readInGeometryData --* readInGeometryData\n","  \n","    readInGeometryData : main()\n","    readInGeometryData : reverseGeoCode()\n","    readInGeometryData : readFile()\n","    readInGeometryData : getGeoParams()\n","    readInGeometryData : main()\n","  \n","    readInGeometryData : df/text url\n","    readInGeometryData : text porg\n","    readInGeometryData : col geom\n","    readInGeometryData : col lat\n","    readInGeometryData : col lng\n","    readInGeometryData : bool save\n","    readInGeometryData : bool revgeocode\n","    readInGeometryData : text in_crs\n","    readInGeometryData : text out_crs\n","</div>\n","\n","<div class=\"mermaid\" style='width:400px'>\n","  classDiagram\n","    workWithGeometryData --* workWithGeometryData\n","  \n","    workWithGeometryData : main()\n","    workWithGeometryData : geomSummary()\n","    workWithGeometryData : getCentroid()\n","    workWithGeometryData : getPointsInPolygons()\n","    workWithGeometryData : mapPointsandPolygons()\n","  \n","    workWithGeometryData : df/url df\n","    workWithGeometryData : df/url polys\n","    workWithGeometryData : text pntsClr\n","    workWithGeometryData : text polysClr\n","    workWithGeometryData : text method\n","</div>"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<script src=\"https://code.jquery.com/jquery-1.10.2.js\"></script>\n","<script src=\"https://unpkg.com/mermaid@7.1.0/dist/mermaid.min.js\"> </script>\n","<script> window.mermaid.init() </script>\n","\n","<h1> createIndicator() Variables and Methods </h1>\n","<div class=\"mermaid\" style='width:400px'>\n","  classDiagram\n","    MergeDatasets --* MergeDatasets\n","  \n","    MergeDatasets : main()\n","    MergeDatasets : checkColumns()\n","    MergeDatasets : coerceDtypes()\n","    MergeDatasets : mergeOrPull()\n","    MergeDatasets : filterEmpties()\n","    MergeDatasets : saveCrosswalk()\n","    MergeDatasets : getMergeParams()\n","  \n","    MergeDatasets : df/text df\n","    MergeDatasets : df/text cw\n","    MergeDatasets : col left_on\n","    MergeDatasets : col right_on\n","    MergeDatasets : col/text how\n","    MergeDatasets : bool save\n","    MergeDatasets : text name\n","</div>\n","\n","<div class=\"mermaid\" style='width:400px'>\n","  classDiagram\n","    readInGeometryData --* readInGeometryData\n","  \n","    readInGeometryData : main()\n","    readInGeometryData : reverseGeoCode()\n","    readInGeometryData : readFile()\n","    readInGeometryData : getGeoParams()\n","    readInGeometryData : main()\n","  \n","    readInGeometryData : df/text url\n","    readInGeometryData : text porg\n","    readInGeometryData : col geom\n","    readInGeometryData : col lat\n","    readInGeometryData : col lng\n","    readInGeometryData : bool save\n","    readInGeometryData : bool revgeocode\n","    readInGeometryData : text in_crs\n","    readInGeometryData : text out_crs\n","</div>\n","\n","<div class=\"mermaid\" style='width:400px'>\n","  classDiagram\n","    workWithGeometryData --* workWithGeometryData\n","  \n","    workWithGeometryData : main()\n","    workWithGeometryData : geomSummary()\n","    workWithGeometryData : getCentroid()\n","    workWithGeometryData : getPointsInPolygons()\n","    workWithGeometryData : mapPointsandPolygons()\n","  \n","    workWithGeometryData : df/url df\n","    workWithGeometryData : df/url polys\n","    workWithGeometryData : text pntsClr\n","    workWithGeometryData : text polysClr\n","    workWithGeometryData : text method\n","</div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"yANtewr3dAAz"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"akUKiDYldAA0"},"source":["This notebook aims to create handler utilities for data operations"]},{"cell_type":"code","metadata":{"id":"wKo5xEFUdAA0"},"source":["# Import needed modules\n","\n","import os, sys, csv, pandas as pd\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovkNsIvkdAA1"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8vQoyqWdAA1"},"source":["cd /gdrive/My Drive/colabs/Exploratory Analysis/utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9Mcci6ldAA1"},"source":["# For relative imports to work in Python 3.6\n","import os, sys; \n","os.path.realpath('./') \n","sys.path.append(os.path.dirname(os.path.realpath('/gdrive/My Drive/colabs/Exploratory Analysis/utils/merge.py')))\n","sys.path.append(os.path.dirname(os.path.realpath('/gdrive/My Drive/colabs/Exploratory Analysis/main.py')))\n","sys.path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ydVXfZ9XdAA2"},"source":["# Merge Module"]},{"cell_type":"code","metadata":{"id":"aBh1ea-adAA2"},"source":["from merge import mergeDatasets as mg\n","from importlib import reload\n","reload(merge) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuT8Mr7qdAA2"},"source":["! python merge.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CdhCwMNHdAA3"},"source":["# vars(mg())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5JN8_9kdAA3"},"source":["cd utils"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fQF-vcAdAA3"},"source":["# 'TRACT2010', 'GEOID2010', 'CSA2010'\n","left_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv'\n","# 'TRACTCE10', 'GEOID10', 'CSA', 'NAME10', 'Tract', 'geometry'\n","right_ds = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTPKW6YOHPFvkw3FM3m5y67-Aa5ZlrM0Ee1Fb57wlGuldr99sEvVWnkej30FXhSb3j8o9gr8izq2ZRP/pub?output=csv'\n","# The Left DS Cols will map to the first three Right DS Cols listed\n","left_col = 'GEOID2010'\n","right_col = 'GEOID10'\n","merge_how = 'geometry'\n","interactive = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PElwaDUxdAA3"},"source":["print('Example: ~/example/path/to/file/FILENAME.csv')\n","print('Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vTPKW6YOHPFvkw3FM3m5y67-Aa5ZlrM0Ee1Fb57wlGuldr99sEvVWnkej30FXhSb3j8o9gr8izq2ZRP/pub?output=csv')\n","print('Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dayd-ggudAA4"},"source":["df = mg( left_ds=left_ds, left_col=left_col, right_ds=right_ds, right_col=right_col, merge_how = merge_how, interactive = interactive )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0YOQHaNkdAA4"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LfC0bqxcdAA5"},"source":["# Data Visualizer"]},{"cell_type":"code","metadata":{"id":"_jOKGGPAdAA6"},"source":["#\n","# Represents Data However Needed\n","#\n","class DataVisualizer():\n","  \n","  # Print Columns\n","  def printCols(df):\n","    print( 'Datasets Available Columns ' + str(df.columns))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IZbnH9mIdAA6"},"source":["# Principle Data Handler > DataWrangler()"]},{"cell_type":"code","metadata":{"id":"Jo18zQSHdAA7"},"source":["#\n","# Principal Data Handler\n","#\n","class dataWrangler():\n","  \n","  # Import the data\n","  def getFile(filename): \n","    return pd.read_csv( filename )\n","    # CCALL THE OTHER FUNCTION PASSING IN GEO SPATIAL PARAMETERS IF it is a geospatial dataset... duh...\n","  \n","  # Save Data\n","  def saveData(df, filename): \n","    df.to_csv(filename+'.csv', quoting=csv.QUOTE_ALL) \n","\n","  def mergeDatasets(self):\n","    print('Option 2');  \n","    # df = df ? retrieveDataset\n","    # crosswalk = retrieveDataset\n","\n","    # Quit if the Columns dont exist\n","    status = checkColumns(crosswalk, df, local_match_col, foreign_match_col, foreign_wanted_col)\n","    if status == False: print('A specified column does not exist'); return False\n","    \n","    # Quit if the foreign key data types wont align nicely\n","    df, crosswalk, status = coerceDtypes(crosswalk, df, local_match_col, foreign_match_col)\n","    if status == False: print('Foreign keys data types do not match'); return False\n","    \n","    # Now create a crosswalk\n","    crswlk = dict(zip(crosswalk[foreign_match_col], crosswalk[foreign_wanted_col]  ) )\n","    \n","    # Perform the merge\n","    df = mergeOrPull(crosswalk, df, local_match_col, foreign_match_col, foreign_wanted_col)    \n","    \n","    # Filter out columns not matched\n","    df = filterEmpties(crosswalk, df, local_match_col, foreign_match_col, foreign_wanted_col)\n","    \n","    # Save this final result\n","    saveCrosswalk(df, local_match_col, foreign_match_col, foreign_wanted_col, save, fileName)\n","                      \n","    return df\n","  \n","  # Check if the columns actually exist\n","  def checkColumns(crosswalk, df, local_match_col, foreign_match_col, foreign_wanted_col): \n","    dfkeyexist = {local_match_col}.issubset(df.columns)\n","    cwkeyexist = {foreign_match_col}.issubset(crosswalk.columns) \n","    cscolexist = ( {foreign_wanted_col}.issubset(crosswalk.columns) or \n","                  foreign_wanted_col in ['left', 'right', 'outer', 'inner'] )\n","    return (dfkeyexist and cwkeyexist and cscolexist)\n","\n","  # Ensure data types are the same\n","  def coerceDtypes(crosswalk, df, local_match_col, foreign_match_col):\n","    status = False\n","    foreignDtype = crosswalk[foreign_match_col].dtype\n","    localDtype = df[local_match_col].dtype  \n","    \n","    # Coerce one way or the other if possible\n","    if localDtype == 'int64' and foreignDtype == 'object':\n","      print('Converting Foreign Key from Object to Int' )\n","      crosswalk[foreign_match_col] = pd.to_numeric(crosswalk[foreign_match_col], errors='coerce')\n","      foreignDtype = crosswalk[foreign_match_col].dtype\n","      \n","    if localDtype == 'object' and foreignDtype == 'int64':\n","      print('Converting Foreign Key from Object to Int' )\n","      df[local_match_col] = pd.to_numeric(df[local_match_col], errors='coerce')\n","      localDtype = df[local_match_col].dtype\n","      \n","    # Return the data and the coerce status\n","    if localDtype == foreignDtype: status = False\n","    return df, crosswalk, status\n","\n","\n","  # Decide to perform a merge or commit a pull\n","  def mergeOrPull(crosswalk, df, local_match_col, foreign_match_col, foreign_wanted_col):  \n","    \n","    def merge(df, crosswalk, left_on, right_on, how):\n","      df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)\n","      return df.drop(left_on, axis=1)\n","\n","    def pull(df, crosswalk, left_on, right_on, foreign_wanted_col, dtype):\n","      if dtype =='object':  df[foreign_wanted_col] = df.apply(lambda row: crswlk.get(str(row[local_match_col]), \"empty\"), axis=1)\n","      elif dtype == 'int64': df[foreign_wanted_col] = df.apply(lambda row: crswlk.get(int(row[local_match_col]), \"empty\"), axis=1)\n","      return df\n","  \n","    merge = foreign_wanted_col in ['left', 'right', 'outer', 'inner']\n","    if merge: return merge(df, crosswalk, left_on, right_on, foreign_wanted_col)\n","    else: return pull(df, crosswalk, left_on, right_on, foreign_wanted_col, df[local_match_col].dtype)\n","\n","  \n","  # Filter between matched records and not.\n","  def filterEmpties(crosswalk, df, local_match_col, foreign_match_col, foreign_wanted_col):\n","    nomatch = df.loc[df[foreign_wanted_col] == 'empty']\n","    nomatch = nomatch.sort_values(by=local_match_col, ascending=True)\n","\n","    if nomatch.shape[0] > 0:\n","      # Do the same thing with our foreign tracts\n","      print('Local Column Values Not Matched ')\n","      print(nomatch[local_match_col].unique() )\n","      print(len(nomatch[local_match_col]))\n","      print('')\n","      print('Crosswalk Unique Column Values')\n","      print(crosswalk[foreign_match_col].unique() )\n","    \n","    # Create a new column with the tracts value mapped to its corresponding value from the crossswalk\n","    df[foreign_wanted_col].replace('empty', np.nan, inplace=True)\n","    df.dropna(subset=[foreign_wanted_col], inplace=True)\n","    # crosswalk = crosswalk.sort_values(by=foreign_wanted_col, ascending=True)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_AkiL5_8dAA9"},"source":["# View / Controller > UserHandler()"]},{"cell_type":"code","metadata":{"id":"0Gb4oK0IdAA-"},"source":["#\n","# View/ Controller \n","#\n","class UserHandler():\n","  def __init__(self, df=False, cswlk=False):\n","    self.df = df\n","\n","  # get filepath : get_dataset\n","  def get_FilePath(adj=False):\n","    print('\\n FILEPATH: (Leave Blank if NA)')\n","    print('Example: ~/example/path/to/file/FILENAME.csv')\n","    print('Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vTPKW6YOHPFvkw3FM3m5y67-Aa5ZlrM0Ee1Fb57wlGuldr99sEvVWnkej30FXhSb3j8o9gr8izq2ZRP/pub?output=csv')\n","    print('Example: https://docs.google.com/spreadsheets/d/e/2PACX-1vREwwa_s8Ix39OYGnnS_wA8flOoEkU7reIV4o3ZhlwYhLXhpNEvnOia_uHUDBvnFptkLLHHlaQNvsQE/pub?output=csv')\n","    filepath = input(f\"{adj} Filepath: \\n\")\n","    return filepath\n","  \n","  # get a user supplied filename: save_dataset\n","  def get_FileName(adj=''):\n","    print('\\n Retrieving Filename')\n","    return input(f\"{adj} FILENAME: (Leave Blank if NA) \\n (Do not include the file extension): \\n\")\n","  \n","  # get_FilePath -> dataWrangler.getFile\n","  def get_dataset(filepath=False, adj=''):\n","    if not filepath: filepath = UserHandler.get_FilePath(adj) \n","    return dataWrangler.getFile( filepath )\n","  \n","  # Set the focal df of this class\n","  def set_dataset(self, df=False):\n","    if df: self.df = df\n","    else: self.df = UserHandler.get_dataset()\n","    \n","  def save_dataset(self, df=False, filename=False):\n","    print('Saving Dataset \\n')\n","    if not df: \n","      if isinstance(self.df, pd.DataFrame): df = self.df\n","      else: df = UserHandler.get_dataset(); self.df = df;\n","    if not filename: filename = UserHandler.get_FileName()    \n","    if not filename: filename = 'NoNameGiven'\n","    print(f'returned {filename}')\n","    dataWrangler.saveData( df, filename )\n","    print(f'\\n Saved Dataset: {filename}')\n","  \n","  # Get merging information. Call Data Wrangler to Merge Data      \n","  def merg_datasets(df=False, cw=False, left_on=False, right_on=False, how=False):\n","    # Get our dataset\n","    if not isinstance(df, pd.DataFrame): df = UserHandler.get_dataset(adj='\\n Path to left dataset:')\n","    if  not isinstance(cw, pd.DataFrame): cw = UserHandler.get_dataset(adj='Path to right dataset:')\n","    DataVisualizer.printCols(cw)\n","    # Get our options\n","    DataVisualizer.printCols(df)\n","    if not left_on: left_on = input(\"Left on: \" )\n","    if not right_on: right_on = input(\"Right on: \" )\n","    if not how: how = input(\"How: ['left','right','outer','inner','columnName']\" )\n","    print('Starting Merge');\n","    return dataWrangler.mergeDatasets(df, cw, left_on, right_on, how)\n","    \n","  # ensure we have a df, pass it to our merge_datasets handler\n","  def set_merg_datasets(self):\n","    if not isinstance(self.df, pd.DataFrame): self.set_dataset(self)\n","    self.set_dataset(UserHandler.merg_datasets(df = self.df))\n","\n","  def show_dataset(self): print('Start Showin');\n","  def explore_dataset(self): print('START ESPLORIN');\n","    \n","  # mainMenu\n","  def userOptions(self):\n","    quitVal = '20'\n","    methods =\t{\n","      \"1\": { \"label\": 'Set Dataset', \"value\": self.set_dataset },\n","      \"2\": { \"label\": 'Merge Datasets', \"value\": self.set_merg_datasets },\n","      \"3\": { \"label\": 'Explore Datasets', \"value\": self.explore_dataset },\n","      \"4\": { \"label\": 'Save Dataset', \"value\": self.save_dataset },\n","      quitVal: { \"label\": 'Exit', \"value\": False },\n","    }\n","    print('\\n ~~~~~~~~~~~~~~~~~~~ Main Menu ~~~~~~~~~~~~~~~~~~~ \\n');\n","    print('Welcome! \\n \\n Please enter a number from the menu \\n');\n","    for key, value in methods.items():\n","      print(f\"{key}. {value['label'] }\" )\n","\n","    choice = input(f\" \\n Your Choice: \")\n","    clear_output() \n","    if choice == quitVal: print('Goodbye!')\n","    else:\n","      if choice in methods:\n","        print(f'\\n ~~~~~~~~~~~~~~~~~~~ Performing Task: {methods[choice][\"label\"]} ~~~~~~~~~~~~~~~~~~~');\n","        methods[choice]['value']()\n","      self.userOptions()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"diIbMKmTdAA-"},"source":["newExperience = UserHandler()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lViLvM7odAA_"},"source":["newExperience.userOptions()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I50amsOZdAA_"},"source":[""],"execution_count":null,"outputs":[]}]}