{"meta":{"filename":"01_scooter_exploration","title":"Scooter Exploration","summary":"In this chapter Scooter data is explored ","prettify":"true"},"content":"<details open>\n <summary> <h2 id=\"introduction\">Introduction</h2>\n </summary> <p><a href=\"https://mybinder.org/v2/gh/bnia/datalabs/main?filepath=%2Fnotebooks%2F01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Binder\"></a>\n <a href=\"https://colab.research.google.com/github/bnia/datalabs/blob/main/notebooks/01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/colab.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/bnia/datalabs/tree/main/notebooks/01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/github.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/ellerbrock/open-source-badges/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://badges.frapsoft.com/os/v3/open-source.svg?v=103\" alt=\"Open Source Love svg3\"></a></p>\n<p> <a href=\"https://github.com/bnia/datalabs/blob/main/LICENSE\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/npm/l/all-contributors.svg?style=flat\" alt=\"NPM License\"></a>\n <a href=\"https://bnia.github.io\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"http://img.shields.io/badge/Status-Active-green.svg\" alt=\"Active\"></a> \n <a href=\"\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/last-commit/bnia/datalabs.svg?style=flat\" alt=\"GitHub last commit\"></a>  </p>\n<p> <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/stars/bnia/datalabs.svg?style=social&label=Star\" alt=\"GitHub stars\"></a> \n <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/watchers/bnia/datalabs.svg?style=social&label=Watch\" alt=\"GitHub watchers\"></a> \n <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/forks/bnia/datalabs.svg?style=social&label=Fork\" alt=\"GitHub forks\"></a> \n <a href=\"https://github.com/bnia/datalabs\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/followers/bnia.svg?style=social&label=Follow\" alt=\"GitHub followers\"></a> </p>\n<p> <a href=\"https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/bnia/datalabs%20%F0%9F%A4%97\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/url/https/github.com/bnia/datalabs.svg?style=social\" alt=\"Tweet\"></a> \n <a href=\"https://twitter.com/bniajfi\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/follow/bniajfi.svg?style=social\" alt=\"Twitter Follow\"></a></p>\n <aside class=\"info\"><p>This notebook was made in part by interns Brian Kelly, Michael Vandi. Read their final article <a href=\"https://bniajfi.org/2021/02/08/social-media-alert-system-for-covid-19-illicit-behavior/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">An Analysis of Baltimore City E-Scooter Distribution</a> </p>\n</aside>\n <p><strong>Dataset:</strong>\n Scooter data: </p>\n<ul>\n<li><p>Routes: 3 months (September to August 2019)</p></li>\n<li><p>Deployment/</p></li>\n<li><p>Routes</p></li>\n<li><p>Trip origins-destinations by month</p></li>\n</ul>\n </details>\n <details>\n <summary> <h2 id=\"local-file-access-optional\">Local File Access (Optional)</h2>\n </summary> <pre class='prettyprint'># (Optional) Run this cell to gain access to Google Drive (Colabs only) \n from google.colab import drive\n \n # Colabs operates in a virtualized enviornment\n # Colabs default directory is at ~/content.\n # We mount Drive into a temporary folder at '~/content/drive' \n \n drive.mount('/content/drive')</pre> <p>File path&#39;s will vary</p>\n <pre class='prettyprint'># cd ./drive/'My Drive'/BNIA/'Scooter Use Data'/BNIA</pre> <pre class='prettyprint'>! ls</pre> <pre class='prettyprint'>!cd ../ && ls</pre> </details>\n <details>\n <summary> <h2 id=\"installs\">Installs</h2>\n </summary> <pre class='prettyprint'>!pip install dexplot\n !pip install folium\n !pip install geopandas\n !pip install ipyleaflet\n !pip install gpdvega\n !pip install dataplay</pre> </details>\n <details>\n <summary> <h2 id=\"imports\"><strong>Imports</strong></h2>\n </summary> <pre class='prettyprint'>import os\n import pandas as pd\n import geopandas as gpd\n import dexplot as dxp\n import folium as fol\n import json\n import altair as alt\n import gpdvega\n import dataplay\n # These imports will handle everything\n import os\n import sys\n import csv\n from IPython.display import clear_output\n import matplotlib.pyplot as plt\n import numpy as np\n import pandas as pd\n import geopandas as gpd\n from geopandas import GeoDataFrame\n import psycopg2\n import pyproj\n from pyproj import Proj, transform\n # conda install -c conda-forge proj4\n from shapely.geometry import Point\n from shapely import wkb\n from shapely.wkt import loads\n # https://pypi.org/project/geopy/\n from geopy.geocoders import Nominatim\n import folium\n from folium import plugins\n \n from dataplay.merge import mergeDatasets \n \n import dexplot as dxp\n \n # In case file is KML, enable support\n import fiona\n fiona.drvsupport.supported_drivers['kml'] = 'rw'\n fiona.drvsupport.supported_drivers['KML'] = 'rw'\n \n #this cell is good to copy\n from shapely.geometry import LineString\n pd.plotting.register_matplotlib_converters()\n \n from dataplay.geoms import readInGeometryData\n from shapely import wkt\n from dataplay.geoms import readInGeometryData\n \n import ipywidgets as widgets\n !jupyter nbextension enable --py widgetsnbextension\n from IPython.core.interactiveshell import InteractiveShell\n InteractiveShell.ast_node_interactivity = 'all'\n import ipywidgets as widgets\n from ipywidgets import interact, interact_manual\n alt.data_transformers.enable('default', max_rows=None)</pre> </details>\n <details>\n <summary> <h2 id=\"convenience-functions\">Convenience Functions</h2>\n </summary> <pre class='prettyprint'>def getPointsInPolygons(pts, polygons, ptsCoordCol, polygonsCoordCol): \n     count = 0 \n     total = pts.size / len(pts.columns)\n     # We're going to keep a list of how many points we find.\n     pts_in_polys = []\n \n     # Loop over polygons with index i.\n     for i, poly in polygons.iterrows():\n         # print('Searching for point within Geom:', poly )\n         # Keep a list of points in this poly\n         pts_in_this_poly = []\n \n         # Now loop over all points with index j.\n         for j, pt in pts.iterrows():\n           if poly[polygonsCoordCol].contains(pt[ptsCoordCol]):\n             # Then it's a hit! Add it to the list,\n             # and drop it so we have less hunting.\n             pts_in_this_poly.append(pt[ptsCoordCol])\n             pts = pts.drop([j])\n \n         # We could do all sorts, like grab a property of the\n         # points, but let's just append the number of them.\n         pts_in_polys.append(len(pts_in_this_poly))\n         print('Found this many points within the Geom:', len(pts_in_this_poly) ) \n         count = count + len(pts_in_this_poly) \n         clear_output(wait=True)\n \n     # Add the number of points for each poly to the dataframe.\n     polygons['pointsinpolygon'] = gpd.GeoSeries(pts_in_polys)\n     print( 'Total Points: ', total )\n     print( 'Total Points in Polygons: ', count )\n     print( 'Prcnt Points in Polygons: ', count / total )\n     return polygons</pre> </details>\n <details>\n <summary> <h2 id=\"file-access-convenience-functions\">File Access Convenience Functions</h2>\n </summary> <pre class='prettyprint'>def findFile(root, file):\n     for d, subD, f in os.walk(root):\n         if file in f:\n             return \"{1}/{0}\".format(file, d)\n             break \n \n # To 'import' a script you wrote, map its filepath into the sys\n def addPath(root, file): sys.path.append(os.path.abspath( findFile( './', file) ))</pre> </details>\n <details>\n <summary> <h2 id=\"inspect-deployment-data\">Inspect Deployment Data</h2>\n </summary> <pre class='prettyprint'>#@markdown Forms support many types of fields.\n fileName = \"Trip Origins by block September 2019.geojson\"  #@param ['Daily Deployment average by block August 2019.csv', 'Daily Deployment average by block December 2019.csv', 'Daily Deployment average by block November 2019.csv', 'Daily Deployment average by block October 2019.csv', 'Daily Deployment average by block September 2019.csv', 'Trip Destinations by block August 2019.geojson','Trip Destinations by block December 2019.geojson','Trip Destinations by block November 2019.geojson', 'Trip Destinations by block October 2019.geojson', 'Trip Destinations by block September 2019.geojson', 'Trip Origins by block August 2019.geojson','Trip Origins by block December 2019.geojson','Trip Origins by block November 2019.geojson','Trip Origins by block October 2019.geojson','Trip Origins by block September 2019.geojson']\n #@markdown ---</pre> <pre class='prettyprint'>gdf.head()</pre> <pre class='prettyprint'>point_df['centroids'] = df.centroid\n point_df = point_df.drop(columns = 'geometry')\n point_df = point_df.set_geometry('centroids')\n point_df.head(1)\n point_df.plot(marker='o', color='red', markersize='value')</pre> <pre class='prettyprint'>                                     polygonsCoordCol = 'geometry', polygonsLabel = 'CSA2010')\n pointsInPolys.plot(column='value', legend=True, markersize = 1)</pre> <pre class='prettyprint'>gdf.shape\n \n #DataFrame.size\tReturn an int representing the number of elements in this object.\n gdf.size\n \n # DataFrame.ndim\tReturn an integer representing the number of axes/array dimensions.\n gdf.ndim\n \n # Note Used : \n # DataFrame.axes\tReturn a list representing the axes of the DataFrame.\n \n gdf.dtypes\n \n # Return unbiased kurtosis over requested axis using Fisherâ€™s definition of kurtosis (kurtosis of normal == 0.0).\n gdf.kurtosis()</pre> </details>\n <details>\n <summary> <h2 id=\"load-tracts\">Load Tracts</h2>\n </summary> <pre class='prettyprint'>\n pd.set_option('display.expand_frame_repr', False)\n pd.set_option('display.precision', 2)\n from IPython.core.interactiveshell import InteractiveShell\n InteractiveShell.ast_node_interactivity = \"all\"\n \n pd.set_option('max_colwidth', 20)</pre> <pre class='prettyprint'>in_crs = 2248 # The CRS we recieve our data.\n out_crs = 4326 # The CRS we would like to have our data represented as.\n geom = 'geometry' # The column where our spatial information lives.\n \n # A Url to load\n boundariesBaltimoreTractsNoWater2010 = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ8xXdUaT17jkdK0MWTJpg3GOy6jMWeaXTlguXNjCSb8Vr_FanSZQRaTU-m811fQz4kyMFK5wcahMNY/pub?gid=886223646&single=true&output=csv\"\n \n # Read in the dataframe\n gdf = pd.read_csv(boundariesBaltimoreTractsNoWater2010)\n \n # Convert the geometry column datatype from a string of text into a coordinate datatype.\n gdf['geometry'] = gdf['geometry'].apply(lambda x: loads( str(x) ))\n \n # Process the dataframe as a geodataframe with a known CRS and geom column.\n gdf = GeoDataFrame(gdf, crs=in_crs, geometry='geometry')</pre> <p>Ensure merge is on consistent datatypes</p>\n <pre class='prettyprint'>scooterdf['nameChange2'] = scooterdf['nameChange2'].astype(str)</pre> <p>Perform the merge</p>\n <pre class='prettyprint'># gdf.drop(columns='geometry').to_csv('./boundsdf.csv', index=False)</pre> </details>\n <details>\n <summary> <h2 id=\"inspect-routes-data\">Inspect Routes Data</h2>\n </summary> <pre class='prettyprint'>columnName = \"streetname\"  #@param ['id', 'color', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent']\n gdf = gpd.read_file( findFile('./', fileName) )\n gdf.head()</pre> <pre class='prettyprint'>    stroke='white',\n     strokeWidth=2\n ).encode(\n     color=alt.value('#eee'),\n ).properties(\n     width=700,\n     height=500\n )\"\"\"\n \n # GeoDataFrame could be passed as usual pd.DataFrame\n city = alt.Chart(baltimore).mark_geoshape(\n ).project(\n ).encode(\n     color='tpop10', # shorthand infer types as for regular pd.DataFrame\n     tooltip='CSA2010' # GeoDataFrame.index is accessible as id\n ).properties(\n     width=500,\n     height=300\n )\n \n routes = alt.Chart(gdf).mark_geoshape(\n     filled=False,\n     strokeWidth=2\n )\n \n city + routes</pre> <p>Clean the gdf of empties.</p>\n <pre class='prettyprint'>gdf = gdf[~gdf.is_empty]</pre> <p>Now get the extremities; this will take a minute.</p>\n <pre class='prettyprint'>gdf['lefty'], gdf['leftx'],gdf['righty'], gdf['rightx'] = zip(*gdf[\"geometry\"].map(split))</pre> <p>Split the gdf into a left and right dataset</p>\n <pre class='prettyprint'>gdf_left = gdf_left.drop(columns = ['geometry','rightx', 'righty'])\n \n gdf_right= gdf.copy()\n gdf_right = gdf_right.drop(columns = ['geometry','leftx', 'lefty', 'streetname', 'trip_count_sum', 'trip_count_average', 'trip_count_percent', 'color' ])</pre> <p>The coordinate variables of object type will cause problems.</p>\n <p>Let&#39;s go ahead and coerce a correction.</p>\n <pre class='prettyprint'>gdf_left['lefty']=pd.to_numeric(gdf_left['lefty'], errors='coerce')\n \n gdf_right['rightx']=pd.to_numeric(gdf_right['rightx'], errors='coerce')\n gdf_left['leftx']=pd.to_numeric(gdf_left['leftx'], errors='coerce')</pre> <p>Now we can view the results</p>\n <p>Save these csv&#39;s because it took a minute to get to where we are now.</p>\n <pre class='prettyprint'>gdf_left.to_csv('leftRouts.csv')</pre> <p>Convert the datasets to geodataframes for further exploration!</p>\n <pre class='prettyprint'>#temp_gdf = gpd.GeoDataFrame( gdf_right, geometry=gpd.points_from_xy(gdf_right.rightx, gdf_right.righty) )\n #temp_gdf.head()\n \n # Alternately this could work.. unfinished.. but wkt.loads can make a Point from text\n # gdf_right['strCol']=gdf_right['rightx'].astype(str)\n # gdf_right['geometry'] = gdf_right['strCol'].apply(wkt.loads)</pre> <pre class='prettyprint'>left_csaMap = readInGeometryData(url=gdf_left, porg='p', geom= False, lat= 'leftx', lng= 'lefty', revgeocode=False, save=False, in_crs=4268, out_crs=4268)</pre> <pre class='prettyprint'>right_csaMap = readInGeometryData(url=gdf_right, porg='p', geom= False, lat= 'rightx', lng= 'righty', revgeocode=False, save=False, in_crs=4268, out_crs=4268)</pre> <pre class='prettyprint'>right_points_in_poly = getPointsInPolygons(right_csaMap, baltimore, 'geometry', 'geometry')</pre> <pre class='prettyprint'>import geopandas as gpd\n import gpdvega\n # GeoDataFrame could be passed as usual pd.DataFrame\n chart = alt.Chart(right_points_in_poly).mark_geoshape(\n ).project(\n ).encode(\n     color='pointsinpolygon', # shorthand infer types as for regular pd.DataFrame\n     tooltip=['CSA2010','pointsinpolygon'] # GeoDataFrame.index is accessible as id\n ).properties(\n     width=500,\n     height=300\n ) \n \n routes = alt.Chart(gdf).mark_geoshape(\n     filled=False,\n     strokeWidth=2\n )\n \n chart + routes\n \n chart.save(fileName[:-8]+'.html', embed_options={'renderer':'svg'})\n chart.save(fileName[:-8]+'.json')</pre> </details>\n <details>\n <summary> <h2 id=\"inspect-origins-destinations-data\">Inspect Origins-Destinations Data</h2>\n </summary> <pre class='prettyprint'>#@markdown Forms support many types of fields.\n fileName = 'Trip Destinations by block August 2019.geojson'  #@param ['Trip Destinations by block August 2019.geojson', 'Trip Destinations by block December 2019.geojson', 'Trip Destinations by block November 2019.geojson', 'Trip Destinations by block October 2019.geojson', 'Trip Destinations by block September 2019.geojson', 'Trip Origins by block August 2019.geojson', 'Trip Origins by block December 2019.geojson', 'Trip Origins by block November 2019.geojson', 'Trip Origins by block October 2019.geojson', 'Trip Origins by block September 2019.geojson']\n columnName = \"name\"  #@param ['name', 'value', 'color', 'radius']\n \n #@markdown ---\n \n gdf = gpd.read_file( findFile('./', fileName) )\n \n gdf.plot( column = columnName)\n gdf.columns\n gdf[['id','name', 'value', 'color', 'radius']].head(5)</pre> </details>\n  <script src=\"https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}