{"meta":{"title":"Looking at Data","summary":"Multiple ways to look at data ","prettify":"true","filename":"09_looking_at_data"},"content":"<p><a href=\"https://mybinder.org/v2/gh/karpatic/karpatic/main?filepath=src%2Fipynb%2Fdatalabs%2F01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Binder\"></a>\n <a href=\"https://colab.research.google.com/github/karpatic/karpatic/blob/main/src/ipynb/datalabs/01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/colab.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/karpatic/karpatic/blob/main/src/ipynb/datalabs/01_scooter_exploration.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/github.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/ellerbrock/open-source-badges/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://badges.frapsoft.com/os/v3/open-source.svg?v=103\" alt=\"Open Source Love svg3\"></a></p>\n<p> <a href=\"https://github.com/karpatic/karpatic/blob/main/LICENSE\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/npm/l/all-contributors.svg?style=flat\" alt=\"NPM License\"></a>\n <a href=\"https://karpatic.github.io\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"http://img.shields.io/badge/Status-Active-green.svg\" alt=\"Active\"></a> \n <a href=\"\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/last-commit/karpatic/karpatic.svg?style=flat\" alt=\"GitHub last commit\"></a>  </p>\n<p> <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/stars/karpatic/karpatic.svg?style=social&label=Star\" alt=\"GitHub stars\"></a> \n <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/watchers/karpatic/karpatic.svg?style=social&label=Watch\" alt=\"GitHub watchers\"></a> \n <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/forks/karpatic/karpatic.svg?style=social&label=Fork\" alt=\"GitHub forks\"></a> \n <a href=\"https://github.com/karpatic/karpatic\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/followers/karpatic.svg?style=social&label=Follow\" alt=\"GitHub followers\"></a>  </p>\n <p>Today we will run through a few experiments to work with data</p>\n <p>We will be using a library created by bnia among others</p>\n  <pre class='prettyprint'>import numpy as np\n import pandas as pd\n import geopandas as gpd\n import matplotlib.pyplot as plt\n import networkx as nx\n import warnings\n warnings.filterwarnings('ignore')</pre> <p>Lets start from where we left off last time</p>\n <pre class='prettyprint'>shortname = 'libcard'</pre> <pre class='prettyprint'># Create the url we will use to query the data from the ESRI api endpoint.\n baseurl = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/\"\n slug = \"/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n url = baseurl+shortname+slug </pre> <pre class='prettyprint'># Use the geopandas library to read it in and immediately set it's index and drop an undesired column.\n gdf = gpd.read_file(url).set_index('CSA2010').drop(axis='1', columns=['OBJECTID','Shape__Area','Shape__Length'])</pre> <pre class='prettyprint'>import csv\n gdf.drop(axis='1', columns=['geometry']).to_csv(shortname+'.csv', quoting=csv.QUOTE_ALL) </pre> <pre class='prettyprint'>df = gdf.drop(axis='1', columns=['geometry'])</pre> <pre class='prettyprint'>df.head()</pre> <pre class='prettyprint'>test = df.transpose().reset_index()\n test.head(1)</pre> <pre class='prettyprint'>test = pd.melt(test, id_vars=['index'], value_vars=test.columns[1:].values, ignore_index=False)</pre> <p><a href=\"https://seaborn.pydata.org/examples/horizontal_boxplot.html\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://seaborn.pydata.org/examples/horizontal_boxplot.html</a></p>\n <pre class='prettyprint'>import seaborn as sns\n import matplotlib.pyplot as plt\n \n sns.set_theme(style=\"ticks\")\n \n # Initialize the figure with a logarithmic x axis\n f, ax = plt.subplots(figsize=(7, 6))\n ax.set_xscale(\"log\")\n \n # Load the example planets dataset\n planets = sns.load_dataset(\"planets\")\n \n # Plot the orbital period with horizontal boxes\n sns.boxplot(x=\"value\", y=\"index\", data=test,\n             whis=[0, 100], width=.6, palette=\"vlag\")\n \n # Add in points to show each observation\n sns.stripplot(x=\"value\", y=\"index\", data=test,\n               size=4, color=\".3\", linewidth=0)\n \n # Tweak the visual presentation\n ax.xaxis.grid(True)\n ax.set(ylabel=\"\")\n sns.despine(trim=True, left=True)</pre> <pre class='prettyprint'>import seaborn as sns\n sns.set_theme(style=\"ticks\")\n \n sns.pairplot(df.reset_index(), hue=\"CSA2010\")</pre> <pre class='prettyprint'>import matplotlib.pyplot as plt\n import numpy as np \n from pandas import DataFrame\n import seaborn as sns\n %matplotlib inline\n # We can change the size of our images like this:\n plt.figure(figsize=(10,10))\n \n # And heatmaps are as simple as this:\n sorted_df = df.sort_values(by=['libcard19'], ascending = False)\n sns.heatmap(sorted_df)</pre> <pre class='prettyprint'>df.plot.line()</pre> <pre class='prettyprint'>import geopandas as gpd\n import numpy as np\n import pandas as pd\n from branca.colormap import linear\n from dataplay import intaker \n # conditionally loaded ->  from dataplay import geoms\n \n u = intaker.Intake\n rdf = u.getData('https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Biz1_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson')\n # rdf.set_index('CSA2010', drop=True, inplace=True)\n rdf.drop(labels=['OBJECTID_1', 'Shape__Area', 'Shape__Length'], axis=1, inplace=True)\n \n ndf = rdf.filter(regex='biz1|CSA2010', axis=1)\n \n # Calculate number of years available\n n_periods = len(ndf.columns) - 1\n # Get starting year.\n startAt = \"20\"+ndf.columns[1][-2:]\n \n # Create a 'YEAR' index with the assumption that all following years exist\n datetime_index = pd.date_range(startAt, periods=n_periods, freq=\"Y\")\n dt_index_epochs = datetime_index.astype(int) // 10 ** 9\n dt_index = dt_index_epochs.astype(\"U10\")\n \n styledata = {}\n # For the Index of each CSA\n for idx, csa in rdf.iterrows():\n     df = pd.DataFrame( { \"color\": csa.values[1:-1] }, index=dt_index, )\n     styledata[idx] = df\n \n max_color, min_color = 0, 0\n for country, data in styledata.items():\n     max_color = max(max_color, data[\"color\"].max())\n     min_color = min(max_color, data[\"color\"].min())\n \n cmap = linear.PuRd_09.scale(min_color, max_color)\n def norm(x): return (x - x.min()) / (x.max() - x.min())\n for country, data in styledata.items():\n     data[\"color\"] = data[\"color\"].apply(cmap)\n     data[\"opacity\"] = 1\n \n styledict = { str(country): data.to_dict(orient=\"index\") for country, data in styledata.items() }\n \n # { CSA : { timestamp: {color: value, opacity:value } }, \n #    CSA : { timestamp: {color: value, opacity:value } }, \n #    ... \n # }\n \n import folium\n from folium.plugins import TimeSliderChoropleth\n \n m = folium.Map([39.28759453969165, -76.61278931706487], width='75%', height='75%', zoom_start=12)\n g = TimeSliderChoropleth( rdf.to_json(), styledict=styledict, ).add_to(m)\n m.save(outfile= \"test.html\")\n m</pre> <pre class='prettyprint'>u = intaker.Intake\n rdf = u.getData('https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Biz1_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson')\n # rdf.set_index('CSA2010', drop=True, inplace=True)\n rdf.head()\n rdf.drop(labels=['OBJECTID_1', 'Shape__Area', 'Shape__Length'], axis=1, inplace=True)\n rdf.sort_values(by=['biz1_19'], ascending = False, inplace=True)\n \n vs10to19Ind = rdf.filter(regex='biz1|CSA2010', axis=1)</pre> <p>What we want is 1 record for every year and every CSA as a column. To do this, transpose the dataset. Set the CSA labels (first row) as our columns, relabel the index (for clarity) and cast our datatypes.</p>\n <p>What we want is 1 record for every year and every CSA as a column. To do this, transpose the dataset. Set the CSA labels (first row) as our columns, relabel the index (for clarity) and cast our datatypes.</p>\n <pre class='prettyprint'>vs10to19Indt = vs10to19Ind.T\n vs10to19Indt.columns = vs10to19Indt.iloc[0]\n vs10to19Indt = vs10to19Indt[1:]\n vs10to19Indt.index.name = 'variable'\n vs10to19Indt = vs10to19Indt.astype('float64')</pre> <pre class='prettyprint'>#craetes a correlation matrix\n cor_matrix = vs10to19Indt.iloc[:,:].corr()\n #shows the first 5 rows\n cor_matrix.head(5)</pre> <pre class='prettyprint'>df = vs10to19Indt.copy()\n import matplotlib.pyplot as plt\n f = plt.figure(figsize=(19, 15))\n plt.matshow(df.corr(), fignum=f.number)\n irange = range(df.select_dtypes(['number']).shape[1])\n labels = df.select_dtypes(['number']).columns\n # plt.xticks(irange, labels, fontsize=14, rotation=45)\n plt.yticks(irange, labels, fontsize=14)\n cb = plt.colorbar()\n cb.ax.tick_params(labelsize=14)\n plt.title('Correlation Matrix', fontsize=16);</pre> <pre class='prettyprint'>#craetes a correlation matrix\n cor_matrix = vs10to19Indt.iloc[:,:].corr()\n #shows the first 5 rows\n cor_matrix.head(5)</pre> <pre class='prettyprint'>#extracts the indices from the correlation matrix\n lblVals = cor_matrix.index.values</pre> <pre class='prettyprint'>#Changes from dataframe to matrix, so it is easier to create a graph with networkx\n cor_matrix = np.asmatrix(cor_matrix)\n #Crates graph using the data of the correlation matrix\n G = nx.from_numpy_matrix(cor_matrix)\n \n #relabels the nodes to match the  stocks names\n G = nx.relabel_nodes(G,lambda x: lblVals[x])\n \n #Shows the first 5 edges with their corresponding edges\n # OLD: G.edges(data=True)[:5]\n list(G.edges(data=True))[0:5]</pre> <pre class='prettyprint'>!pip install VitalSigns</pre> <pre class='prettyprint'>import VitalSigns</pre> <pre class='prettyprint'>from dataplay import corr</pre> <pre class='prettyprint'>corr.create_corr_network_5(G, corr_direction=\"positive\",min_correlation=0.7)</pre> <pre class='prettyprint'>corr.create_corr_network_5(G, corr_direction=\"negative\",min_correlation=-0.7)</pre> <p>We want to create a linear regression for each CSA using {X: year, Y: value} for a given indicator</p>\n <pre class='prettyprint'>import numpy as np\n import matplotlib.pyplot as plt\n import pandas as pd\n from sklearn.linear_model import LinearRegression\n \n # Create 3 columns: CSA2010\tvariable value\n wdf = vs10to19Ind.melt(id_vars='CSA2010', value_vars=vs10to19Ind.columns[1:])\n \n # Convert indicator labels into our X (Year) column \n wdf['variable'] = wdf['variable'].apply(lambda x: int(x.replace('biz1_','') ) )\n \n findf = {'CSA':[], 'B':[], 'M':[] }\n # For each CSA \n for csa in wdf.CSA2010.unique():\n   CsaData = wdf[ wdf['CSA2010']==csa]\n   X = CsaData[['variable']] #.values # returns: [10 11 12 13 14 15 16 17 18 19]\n   y = CsaData[['value']] #.values\n   regressor = LinearRegression()\n   regressor.fit(X, y)\n   y_pred = regressor.predict(X)\n   plt.scatter(X, y, color = 'red')\n   plt.plot(X, regressor.predict(X), color = 'blue')\n   plt.title('biz1: '+ csa)\n   plt.xlabel('YEAR')\n   plt.ylabel('VALUE')\n   display( plt.show() )\n   display( print('B: ', regressor.coef_, 'Y: ', regressor.intercept_) ) \n   findf['CSA'].append(csa)\n   findf['B'].append(regressor.intercept_[0])\n   findf['M'].append(regressor.coef_[0][0])</pre> <pre class='prettyprint'>lin_reg_df = pd.DataFrame(data=findf)</pre> <pre class='prettyprint'>lin_reg_df.head()</pre> <pre class='prettyprint'>lin_reg_dft = lin_reg_df.T\n lin_reg_dft.columns = lin_reg_dft.iloc[0]\n lin_reg_dft = lin_reg_dft[1:]\n lin_reg_dft.index.name = 'variable'\n lin_reg_dft = lin_reg_dft.astype('float64')</pre> <pre class='prettyprint'>lin_reg_dft</pre> <p>We may need to normalize the data for this to be useable</p>\n <pre class='prettyprint'>df = lin_reg_dft.copy()\n import matplotlib.pyplot as plt\n f = plt.figure(figsize=(19, 15))\n plt.matshow(df.corr(), fignum=f.number)\n irange = range(df.select_dtypes(['number']).shape[1])\n labels = df.select_dtypes(['number']).columns\n # plt.xticks(irange, labels, fontsize=14, rotation=45)\n plt.yticks(irange, labels, fontsize=14)\n cb = plt.colorbar()\n cb.ax.tick_params(labelsize=14)\n plt.title('Correlation Matrix', fontsize=16);</pre> <pre class='prettyprint'># This dataset is taken from the public database provided by BNIAJFI hosted by Esri / ArcGIS\n # BNIA ArcGIS Homepage: https://data-bniajfi.opendata.arcgis.com/\n final = u.getData('https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Biz1_/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson')\n final.head(1)</pre> <pre class='prettyprint'>final['centroid'] = final['geometry'].representative_point()</pre> <pre class='prettyprint'>pd.set_option('precision', 0)\n fileNames = []\n labelBounds = True\n specialLabelCol = False # Labels on GEOM Centroids\n saveGifAs = './test.gif'\n label = 'Household Poverty'\n annotation = 'Source: Maryland Vital Statistics; Analysis by: Baltimore Neighborhood Indicators Alliance' \n fontsize='22'</pre> <pre class='prettyprint'># Get only the results tab\n td = final.copy()\n td = td.reindex(sorted(td.columns), axis=1)</pre> <pre class='prettyprint'># Coerce columns stored as floats into integers. \n # This will ensure numbers are rounded to whole digits when displaying the reults\n regexMatchingColumnsToMakeTheGifWith = 'biz1'\n gifCols = td.filter(regex=regexMatchingColumnsToMakeTheGifWith).columns.values\n \n td[gifCols] = td[gifCols].fillna(-1)\n td[gifCols] = td[gifCols].astype('int32')\n td.head()</pre> <p><a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.hist.html</a></p>\n <pre class='prettyprint'>final.filter(regex=regexMatchingColumnsToMakeTheGifWith).hist(figsize=(20, 10), bins=10)</pre> <pre class='prettyprint'>saveGifAs = './test.gif'\n labelBounds = False # 'CSA2010'\n annotation = 'Source: Baltimore Neighborhood Indicators Alliance' \n title = 'Indicator Name' \n fontsize='22'</pre> <pre class='prettyprint'>from dataplay import gifmap\n from dataplay.gifmap import getAbsMinMax</pre> <pre class='prettyprint'>import re \n td = td.rename(columns=lambda x: re.sub('biz1_','final',x))</pre> <pre class='prettyprint'>gifmap.createGifMap(td, saveGifAs, labelBounds, title, annotation, fontsize)</pre>\n  <script src=\"https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}