{"meta":{"title":"Retrieve ACS Data","summary":"Creating and Retrieve ACS Data.","toc":"true","prettify":"true","default_exp":"acs","audio":"https://charleskarpati.com/audio/07_retrieve_acs_Data.mp3","filename":"07_retrieve_acs_data"},"content":"<p><a href=\"https://mybinder.org/v2/gh/bnia/dataplay/main?filepath=%2Fnotebooks%2F01_Download_and_Load.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Binder\"></a>\n <a href=\"https://colab.research.google.com/github/bnia/dataplay/blob/main/notebooks/01_Download_and_Load.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/colab.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/bnia/dataplay/tree/main/notebooks/01_Download_and_Load.ipynb\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://pete88b.github.io/fastpages/assets/badges/github.svg\" alt=\"Binder\"></a>\n <a href=\"https://github.com/ellerbrock/open-source-badges/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://badges.frapsoft.com/os/v3/open-source.svg?v=103\" alt=\"Open Source Love svg3\"></a>\n <br>\n <a href=\"https://github.com/bnia/dataplay/blob/main/LICENSE\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/npm/l/all-contributors.svg?style=flat\" alt=\"NPM License\"></a>\n <a href=\"https://bnia.github.io\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"http://img.shields.io/badge/Status-Active-green.svg\" alt=\"Active\"></a> \n <a href=\"https://pypi.python.org/pypi/dataplay/\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/pypi/pyversions/dataplay.svg\" alt=\"Python Versions\"></a>\n <a href=\"\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/last-commit/bnia/dataplay.svg?style=flat\" alt=\"GitHub last commit\"></a><br> <br>\n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/stars/bnia/dataplay.svg?style=social&label=Star\" alt=\"GitHub stars\"></a> \n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/watchers/bnia/dataplay.svg?style=social&label=Watch\" alt=\"GitHub watchers\"></a> \n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/forks/bnia/dataplay.svg?style=social&label=Fork\" alt=\"GitHub forks\"></a> \n <a href=\"https://github.com/bnia/dataplay\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/github/followers/bnia.svg?style=social&label=Follow\" alt=\"GitHub followers\"></a> \n <br>\n <a href=\"https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/bnia/dataplay%20%F0%9F%A4%97\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/url/https/github.com/bnia/dataplay.svg?style=social\" alt=\"Tweet\"></a> \n <a href=\"https://twitter.com/bniajfi\" onclick=\"window.pingServer(this)\" target=\"_blank\" rel=\"noopener noreferrer nofollow\"><img src=\"https://img.shields.io/twitter/follow/bniajfi.svg?style=social\" alt=\"Twitter Follow\"></a></p>\n <details open>\n <summary> <h2 id=\"about\">About:</h2>\n </summary> <h3 id=\"whats-inside\">Whats inside?</h3>\n <p>In this notebook, we build and test a basic retrieve ACS function.</p>\n<ul>\n<li><p>A ACS dataset will be loaded into pandas</p></li>\n</ul>\n </details>\n <details>\n <summary> <h2 id=\"the-function\">The Function</h2>\n </summary>    <pre class='prettyprint'>import pandas as pd\n from urllib.parse import urlencode\n import csv # quoting=csv.QUOTE_ALL</pre> <pre class='prettyprint'>\n #File: retrieve_acs_data.py\n #Author: Charles Karpati\n #Date: 1/9/19\n #Section: Bnia\n #Email: karpati1@umbc.edu\n #Description:\n #This file returns ACS data given an ID and Year\n # The county total is given a tract of '010000'\n \n #def retrieve_acs_data():\n #purpose: Retrieves ACS data from the web\n #input:\n # state (required)\n # county (required)\n # tract (required)\n # tableId (required)\n # year (required)\n # includeCountyAgg (True)(todo)\n # replaceColumnNames (False)(todo)\n # save (required)\n #output:\n # Acs Data.\n # Prints to ../../data/2_cleaned/acs/\n def retrieveAcsData(state, county, tract, tableId, year):\n     dictionary = ''\n     keys = []\n     vals = []\n     header = []\n     keys1=keys2=keys3=keys4=keys5=keys6=keys7=keys8=''\n     keyCount = 0\n \n     # Called in addKeys(), Will create the final URL for readIn()\n     # These are parameters used in the API URL Query\n     # This query will retrieve the census tracts\n     def getParams(keys): return {\n         'get': 'NAME'+keys,\n         'for': 'tract:'+tract,\n         'in': 'state:'+state+' county:'+county,\n         'key': '829bf6f2e037372acbba32ba5731647c5127fdb0'\n       }\n     # Aggregate City data is best retrieved seperatly rather than as an aggregate of its constituent tracts\n     def getCityParams(keys): return {\n         'get': 'NAME'+keys,\n         'for': 'county:'+county,\n         'in': 'state:'+state,\n         'key': '829bf6f2e037372acbba32ba5731647c5127fdb0'\n       }\n     # Called in AddKeys(). Requests data by url and preformats it.\n     def readIn( url ):\n         tbl = pd.read_json(url, orient='records')\n         tbl.columns = tbl.iloc[0]\n         return tbl\n \n     # Called by retrieveAcsData.\n     # Creates a url and retrieve the data\n     # Then appends the city values as tract '010000'\n     # Finaly it merges and returns the tract and city totals.\n     def addKeys( table, params):\n         # Get Tract and City Records For Specific Columns\n         table2 = readIn( base+urlencode(getParams(params)) )\n         table3 = readIn( base+urlencode(getCityParams(params)) )\n         table3['tract'] = '010000'\n         # Concatenate the Records\n         table2.append([table2, table3], sort=False)\n         table2 = pd.concat([table2, table3], ignore_index=True)\n         # Merge to Master Table\n         table = pd.merge(table, table2,  how='left',\n                          left_on=[\"NAME\",\"state\",\"county\",\"tract\"],\n                          right_on = [\"NAME\",\"state\",\"county\",\"tract\"])\n         return table\n \n     #~~~~~~~~~~~~~~~\n     # Step 1)\n     # Retrieve a Meta Data Table Describing the Content of the Table\n     #~~~~~~~~~~~~~~~\n     url = 'https://api.census.gov/data/20'+year+'/acs/acs5/groups/'+tableId+'.json'\n     metaDataTable = pd.read_json(url, orient='records')\n \n     #~~~~~~~~~~~~~~~\n     # Step 2)\n     # Createa a Dictionary using the Meta Data Table\n     #~~~~~~~~~~~~~~~\n     # Multiple Queries may be Required.\n     # Max columns returned from any given query is 50.\n     # For that reasons bin the Columns into Groups of 50.\n     for key in metaDataTable['variables'].keys():\n       if key[-1:] == 'E':\n         keyCount = keyCount + 1\n         if keyCount < 40 : keys1 = keys1+','+key\n         elif keyCount < 80 : keys2 = keys2+','+key\n         elif keyCount < 120 : keys3 = keys3+','+key\n         elif keyCount < 160 : keys4 = keys4+','+key\n         elif keyCount < 200 : keys5 = keys5+','+key\n         elif keyCount < 240 : keys6 = keys6+','+key\n         elif keyCount < 280 : keys7 = keys7+','+key\n         elif keyCount < 320 : keys8 = keys8+','+key\n         keys.append(key)\n         val = metaDataTable['variables'][key]['label']\n         # Column name formatting\n         val = key+'_'+val.replace('Estimate!!', '').replace('!!', '_').replace(' ', '_')\n         vals.append(val)\n     dictionary = dict(zip(keys, vals))\n \n     #~~~~~~~~~~~~~~~\n     # Step 2)\n     # Get the actual Table with the data we want using\n     #~~~~~~~~~~~~~~~\n \n     # The URL we call is contingent on if the Table we want is a Detailed or Subject table\n     url1 = 'https://api.census.gov/data/20'+year+'/acs/acs5?'\n     url2 = 'https://api.census.gov/data/20'+year+'/acs/acs5/subject?'\n     base = ''\n     if tableId[:1] == 'B': base = url1\n     if tableId[:1] == 'S': base = url2\n \n     # The addKey function only works after the first set of columns has been downloaded\n     # Download First set of Tract columns\n     url = base+urlencode(getParams(keys1) )\n     table = pd.read_json(url, orient='records')\n     table.columns = table.iloc[0]\n     table = table.iloc[1:]\n     # Download First set of Aggregate City data\n     url = base+urlencode(getCityParams(keys1))\n     table2 = pd.read_json(url, orient='records')\n     table2.columns = table2.iloc[0]\n     table2 = table2[1:]\n     table2['tract'] = '010000'\n \n     # Merge EM\n     #table = pd.concat([table, table2], keys=[\"NAME\",\"state\",\"county\",], axis=0)\n     table = pd.concat([table, table2], ignore_index=True, sort=False)\n \n     table = pd.concat([table, table2], ignore_index=True)\n \n     # Now we can repetedly use this function to add as many columns as there are keys listed from the meta data table\n     if keys2 != '' : table = addKeys(table, keys2)\n     if keys3 != '' : table = addKeys(table, keys3)\n     if keys4 != '' : table = addKeys(table, keys4)\n     if keys5 != '' : table = addKeys(table, keys5)\n     if keys6 != '' : table = addKeys(table, keys6)\n     if keys7 != '' : table = addKeys(table, keys7)\n     if keys8 != '' : table = addKeys(table, keys8)\n \n     #~~~~~~~~~~~~~~~\n     # Step 3)\n     # Prepare Column Names using the meta data table. The raw data has columnsNames in the first row, as well.\n     # Replace column ID's with labels from the dictionary where applicable (should be always)\n     #~~~~~~~~~~~~~~~\n     # print('Number of Columns', len(dictionary) )\n \n     header = []\n     for column in table.columns:\n         if column in keys: header.append(dictionary[column])\n         else: header.append(column)\n     table.columns = header\n \n     # Prettify Names. Only happens with Baltimore...\n     table['NAME'] = table['NAME'].str.replace(', Baltimore city, Maryland', '')\n     table['NAME'][table['NAME'] == 'Baltimore city, Maryland'] = 'Baltimore City'\n \n     # Convert to Integers Columns from Strings where Applicable\n     table = table.apply(pd.to_numeric, errors='ignore')\n \n     # Set the 'NAME' Column as the index dropping the default increment\n     table.set_index(\"NAME\", inplace = True)\n     '''\n     if save:\n \n       # Save the raw data as 'TABLEID_5yYEAR.csv'\n       table.to_csv('./'+state+county+'_'+tableId+'_5y'+year+'_est_Original.csv', quoting=csv.QUOTE_ALL)\n \n       # Remove the id in the column names & Save the data as 'TABLEID_5yYEAR_est.csv'\n       saveThis = table.rename( columns = lambda x : ( str(x)[:] if str(x) in [\n         \"NAME\",\"state\",\"county\",\"tract\"] else str(x)[12:] )  )\n       saveThis.to_csv('./'+state+county+'_'+tableId+'_5y'+year+'_est.csv', quoting=csv.QUOTE_ALL)\n \n     '''\n     return table</pre> </details>\n  <script src=\"https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js\"></script>\n  <link rel=\"stylesheet\" href=\"https://cdn.rawgit.com/google/code-prettify/master/styles/desert.css\"/>\n  "}